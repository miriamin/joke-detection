
@phdthesis{aminComputationalHumorAutomatic2019,
  title = {Computational Humor - {{Automatic}} Generation of Jokes},
  author = {Amin, Miriam},
  year = {2019},
  school = {Leipzig University},
  type = {Bachelor {{Thesis}}}
}

@inproceedings{blinovLargeDatasetLanguage2019,
  title = {Large {{Dataset}} and {{Language Model Fun}}-{{Tuning}} for {{Humor Recognition}}},
  booktitle = {Proceedings of the 57th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Blinov, Vladislav and {Bolotova-Baranova}, Valeria and Braslavski, Pavel},
  year = {2019},
  month = jul,
  pages = {4027--4032},
  publisher = {{Association for Computational Linguistics}},
  address = {{Florence, Italy}},
  doi = {10.18653/v1/P19-1394},
  abstract = {The task of humor recognition has attracted a lot of attention recently due to the urge to process large amounts of user-generated texts and rise of conversational agents. We collected a dataset of jokes and funny dialogues in Russian from various online resources and complemented them carefully with unfunny texts with similar lexical properties. The dataset comprises of more than 300,000 short texts, which is significantly larger than any previous humor-related corpus. Manual annotation of 2,000 items proved the reliability of the corpus construction approach. Further, we applied language model fine-tuning for text classification and obtained an F1 score of 0.91 on a test set, which constitutes a considerable gain over baseline methods. The dataset is freely available for research community.},
  file = {/Users/miriamamin/Documents/Zotero/storage/PVV49HPR/Blinov et al. - 2019 - Large Dataset and Language Model Fun-Tuning for Hu.pdf}
}

@inproceedings{chenHumorRecognitionUsing2018,
  title = {Humor {{Recognition Using Deep Learning}}},
  booktitle = {Proceedings of the 2018 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}},
  author = {Chen, Peng-Yu and Soo, Von-Wun},
  year = {2018},
  volume = {2},
  pages = {113--117},
  doi = {10.18653/v1/N18-2018},
  copyright = {RECOG},
  file = {/Users/miriamamin/Documents/Zotero/storage/KAHAFJPZ/Chen_Soo_2018_Humor Recognition Using Deep Learning.pdf;/Users/miriamamin/Documents/Zotero/storage/24ISU5LZ/N18-2018.html},
  language = {en-us},
  series = {Short {{Paper}}}
}

@misc{maheshwariReportTextClassification2018,
  title = {Report on {{Text Classification}} Using {{CNN}}, {{RNN}} \& {{HAN}}},
  author = {Maheshwari, Akshat},
  year = {2018},
  month = jul,
  abstract = {Experimenting with various neural networks architectures.},
  file = {/Users/miriamamin/Documents/Zotero/storage/2A34DT26/report-on-text-classification-using-cnn-rnn-han-f0e887214d5f.html},
  howpublished = {https://medium.com/jatana/report-on-text-classification-using-cnn-rnn-han-f0e887214d5f},
  journal = {Medium},
  language = {en}
}

@article{moudgilPythonScriptsBuilding2017,
  title = {Python Scripts for Building '{{Short Jokes}}' Dataset, Featured on {{Kaggle}}},
  shorttitle = {Python Scripts for Building '{{Short Jokes}}' Dataset, Featured on {{Kaggle}}},
  author = {Moudgil, Abhinav},
  year = {2017},
  copyright = {GPL-2.0},
  journal = {GitHub repository}
}

@inproceedings{oliveiraHumorDetectionYelp2015,
  title = {Humor {{Detection}} in {{Yelp}} Reviews},
  author = {de Oliveira, Luke and Rodrigo, Alfredo L{\'a}inez},
  year = {2015},
  abstract = {We utilize the state-of-the-art in deep learning to show that we can learn by example what constitutes humor in the context of a Yelp review. To the best of the authors knowledge, no systematic study of deep learning for humor exists \textendash{} thus, we construct a scaffolded study. First, we use ``shallow'' methods such as Random Forests and Linear Discriminants built on top of bag-of-words and word vector features. Then, we build deep feedforward networks on top of these features \textendash{} in some sense, measuring how much of an effect basic feedforward nets help. Then, we use recurrent neural networks and convolutional neural networks to more accurately model the sequential nature of a review.},
  file = {/Users/miriamamin/Documents/Zotero/storage/8P5BKY6N/Oliveira_Rodrigo_2015_Humor Detection in Yelp reviews.pdf},
  keywords = {Artificial neural network,Bag-of-words model,Convolutional neural network,Deep learning,Feed forward (control),Feedforward neural network,Neural Network Simulation,Random forest,Recurrent neural network,Review [Publication Type],Word embedding}
}

@misc{PracticalTextClassification,
  title = {Practical {{Text Classification With Python}} and {{Keras}} \textendash{} {{Real Python}}},
  file = {/Users/miriamamin/Documents/Zotero/storage/8HULSRTK/python-keras-text-classification.html},
  howpublished = {https://realpython.com/python-keras-text-classification/}
}

@article{pungasDatasetEnglishPlaintext2017,
  title = {A Dataset of {{English}} Plaintext Jokes.},
  author = {Pungas, Taivo},
  year = {2017},
  journal = {GitHub repository},
  note = {https://github.com/taivop/joke-dataset}
}

@misc{revanthStoriesAmericanMovies2018,
  title = {Stories of {{American}} Movies | {{Kaggle}}},
  author = {Revanth, G},
  year = {2018},
  file = {/Users/miriamamin/Documents/Zotero/storage/SBZJ39IL/wikipediaplotdata.html},
  howpublished = {https://www.kaggle.com/revanth9/wikipediaplotdata}
}

@unpublished{spacy2,
  title = {{{spaCy}} 2: {{Natural}} Language Understanding with {{Bloom}} Embeddings, Convolutional Neural Networks and Incremental Parsing},
  author = {Honnibal, Matthew and Montani, Ines},
  year = {2017},
  annote = {To appear}
}

@misc{WordVectorsSemantic,
  title = {Word {{Vectors}} and {{Semantic Similarity}} {$\cdot$} {{spaCy Usage Documentation}}},
  abstract = {spaCy is a free open-source library for Natural Language Processing in Python. It features NER, POS tagging, dependency parsing, word vectors and more.},
  howpublished = {https://spacy.io/usage/vectors-similarity},
  journal = {Word Vectors and Semantic Similarity},
  language = {en}
}


