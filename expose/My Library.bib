
@inproceedings{kawanoPrototypeAttentionSimulator2011,
  title = {A {{Prototype}} of {{Attention Simulator}} on {{Twitter}}},
  abstract = {According to the concept of the attention economy, the attention is the only thing that is valuable. Twitter is suitable for the simulation of trade of the attention, because Twitter field has many similarities to the attention economy. However, Twitter is inadequate for the visualization of the trade of the attention. The attention on the Twitter can be represented only by the action of the follow. Additionally, the allowable number of the follow is beyond the capacity of the human's attention, whereas the human's attention's being finite. This research studies the environment for visualization of the attention trade on Twitter and simulates the attention economy approaching the real world. As a result, this simulation is expected to motivate the economic activity with the concept of the attention economy and to develop its analytical method.},
  booktitle = {2011 14th {{International Conference}} on {{Network}}-{{Based Information Systems}}},
  doi = {10.1109/NBiS.2011.51},
  author = {Kawano, Y. and Kishimoto, Y. and Yonekura, T.},
  month = sep,
  year = {2011},
  keywords = {Attention,attention economy,Attention Economy,Attention Simulator,attention simulator prototype,attention trade visualization,data visualisation,Economics,Educational institutions,Google,History,social networking (online),Twitter,Upper bound,Visualization},
  pages = {173-177},
  file = {/Users/miriamamin/Documents/Zotero/storage/KX85QA4W/Kawano et al. - 2011 - A Prototype of Attention Simulator on Twitter.pdf;/Users/miriamamin/Documents/Zotero/storage/SUJHSN6R/6041919.html},
  annote = {\textbf{Anmerkungen herauskopieren (20.12.2017, 11:37:17)}

"A. What is Attention? In this section, we propose a new concept of the attention. It is an addition of some features to the attention on which Iskold proposed [4]. - Property You own your attention and can store it wherever you wish. You have control [4]. - Mobility You can securely move your attention wherever" (\href{zotero://open-pdf/0_KX85QA4W/1}{Kawano et al 2011:173})

"you want, whenever you want to. You have the ability to transfer your attention [4]. - Economy You can pay attention to whomever you wish and receive value in return. Your attention has worth [4]. - Transparency You can see exactly how your attention is being used [4]. - Finitude The attention that a person can pay to a specific object per unit time is finiteness. - Privacy You do not know the attention that others pay. Concretely, it is an object of the attention that others pay and the strength. However, the attention that oneself pays can be revealed to specific others. - Continuity Strength of the attention paid to a specific object changes attended with the temporal continuity." (\href{zotero://open-pdf/0_KX85QA4W/2}{Kawano et al 2011:174})

"Reason for unfollow" (\href{zotero://open-pdf/0_KX85QA4W/3}{Kawano et al 2011:175})

\emph{{\"y}{\th}reasons to unfollow (absteigend)\\
*trivial tweets\\
*too many tweets\\
*who is this?\\
*other\\
*few tweets\\
 (\href{zotero://open-pdf/0_KX85QA4W/3}{note on p.175})}

\textbf{Anmerkungen herauskopieren (24.12.2017, 11:43:02)}

"A. What is Attention? In this section, we propose a new concept of the attention. It is an addition of some features to the attention on which Iskold proposed [4]. - Property You own your attention and can store it wherever you wish. You have control [4]. - Mobility You can securely move your attention wherever" (\href{zotero://open-pdf/0_KX85QA4W/1}{Kawano et al 2011:173})

"you want, whenever you want to. You have the ability to transfer your attention [4]. - Economy You can pay attention to whomever you wish and receive value in return. Your attention has worth [4]. - Transparency You can see exactly how your attention is being used [4]. - Finitude The attention that a person can pay to a specific object per unit time is finiteness. - Privacy You do not know the attention that others pay. Concretely, it is an object of the attention that others pay and the strength. However, the attention that oneself pays can be revealed to specific others. - Continuity Strength of the attention paid to a specific object changes attended with the temporal continuity." (\href{zotero://open-pdf/0_KX85QA4W/2}{Kawano et al 2011:174})

"Reason for unfollow" (\href{zotero://open-pdf/0_KX85QA4W/3}{Kawano et al 2011:175})

\emph{{\"y}{\th}reasons to unfollow (absteigend)\\
*trivial tweets\\
*too many tweets\\
*who is this?\\
*other\\
*few tweets\\
 (\href{zotero://open-pdf/0_KX85QA4W/3}{note on p.175})}

"On the other hand, there is Favotter [9] as an immediate payment of attention on Twitter. Favotter is a summary site of Twitter made from the remark registered in the favorite. It is an act of paying attention to the other user's tweets. However, favotter is service that pays attention to the tweet, and user's noteworthy level is not appreciable." (\href{zotero://open-pdf/0_KX85QA4W/3}{Kawano et al 2011:175})}
}

@book{parmeleePoliticsTwitterRevolution2012,
  address = {{Lanham, Md.  [u.a.]}},
  series = {Lexington Studies in Political Communication},
  title = {Politics and the {{Twitter}} Revolution: How Tweets Influence the Relationship between Political Leaders and the Public},
  isbn = {978-0-7391-6500-3},
  shorttitle = {Politics and the {{Twitter}} Revolution},
  publisher = {{Lexington Books}},
  author = {Parmelee, John H. and Bichard, Shannon L.},
  year = {2012},
  file = {/Users/miriamamin/Documents/Zotero/storage/FL3C3VVI/PPNSET.html}
}

@article{palStudyingPoliticalCommunication2017,
  series = {{{SI}}: 18: {{Big}} Data in the Behavioural Sciences (2017)},
  title = {Studying Political Communication on {{Twitter}}: The Case for Small Data},
  volume = {18},
  issn = {2352-1546},
  shorttitle = {Studying Political Communication on {{Twitter}}},
  abstract = {Big data has dramatically changed the study of political communications online as researchers access massive feeds of data on social media behavior, networks, and language. However, the nature political communication remains inherently message-driven, where the composition, timing, and metaphor are necessary components of the overall message. This article surveys research on political communication on Twitter and classifies it into seven subjective domains of research. The methodological approaches that have been applied toward these domains include quantitative technique studying the size, shape, profile of the networks and their nodes; large-scale data mining techniques applied to study the contents of Twitter messaging; and qualitative methods for in-depth study of messages. Showing that qualitative research methods have extended our understanding of political communications domains, we propose that small data approaches, through interpretive analysis and commentary by human readers, can be coupled with large-scale data analysis for deeper, contextual understanding of political messaging.},
  number = {Supplement C},
  journal = {Current Opinion in Behavioral Sciences},
  doi = {10.1016/j.cobeha.2017.09.009},
  author = {Pal, Joyojeet and Gonawela, A'Ndre},
  month = dec,
  year = {2017},
  pages = {97-102},
  file = {/Users/miriamamin/Documents/Zotero/storage/L3CGINJR/Pal_Gonawela_2017_Studying political communication on Twitter.pdf;/Users/miriamamin/Documents/Zotero/storage/PMNSYHWU/S2352154617301717.html}
}

@article{braccialeDefinePopulistPolitical2017,
  title = {Define the Populist Political Communication Style: The Case of {{Italian}} Political Leaders on {{Twitter}}},
  volume = {20},
  issn = {1369-118X},
  shorttitle = {Define the Populist Political Communication Style},
  abstract = {In the hybrid media system, many processes are reforming political communication: popularisation, disintermediation, personalisation, intimisation and of course populism. This study proposes an empirical definition of political communication style with the aim of identifying characteristics of the populist political communication style. Between 2015 and 2016, the Twitter timelines of the main political leaders in Italy were analysed for 16 months. Applying an MCA allowed us to identify two key factors that characterise the communication styles of leaders: (1) communication mode, comparing negative and positive; and (2) communicative focus, comparing personalisation and political/campaign. The intersection of these two factors resulted in four different political communication styles: `Engaging', `Intimate', `Champion of the people' and `Man of the street'. The latter two were clearly characterised by the presence of populist ideology fragments and traits, but were not strictly related to the leaders' ideological positions. This result supports the hypothesis that populist style is less and less connected to the right/left political cleavage, but rather the result of a varied combination of gradations that mix different individual aspects of the leader's political communication style.},
  number = {9},
  journal = {Information, Communication \& Society},
  doi = {10.1080/1369118X.2017.1328522},
  author = {Bracciale, Roberta and Martella, Antonio},
  month = sep,
  year = {2017},
  keywords = {Twitter,political communication style,political leaders,popularisation,Populism},
  pages = {1310-1329},
  file = {/Users/miriamamin/Documents/Zotero/storage/TR2788YZ/Bracciale_Martella_2017_Define the populist political communication style.pdf;/Users/miriamamin/Documents/Zotero/storage/NIYHSC9I/1369118X.2017.html}
}

@misc{maierTippsMitDenen2014,
  title = {8 {{Tipps}}, Mit Denen Du Deine {{Klickrate}} Bei {{Twitter}} Steigern Kannst},
  abstract = {Tipps, Tricks und Tools, mit denen man die Klickrate bei Twitter steigern kann und via Twitter mehr Traffic f{\"u}r Corporate Blog und Webseite generiert.},
  journal = {SocialHub Blog},
  author = {Maier, Susanne},
  month = apr,
  year = {2014},
  file = {/Users/miriamamin/Documents/Zotero/storage/B556WD24/8-tipps-mit-denen-du-deine-klickrate-bei-twitter-steigern-kannst-2.html}
}

@misc{HowGrabAttention,
  title = {How to {{Grab Attention}} on {{Twitter}}},
  abstract = {As your sphere of influence grows, Twitter becomes more powerful as a marketing tool for a website, product or service. However, on Twitter you are one user among millions, and getting attention can ...},
  howpublished = {http://smallbusiness.chron.com/grab-attention-twitter-29579.html},
  file = {/Users/miriamamin/Documents/Zotero/storage/PAGFRHTJ/grab-attention-twitter-29579.html}
}

@misc{WaysGetYour,
  title = {6 {{Ways}} to {{Get Your Tweets Noticed}} : {{Social Media Examiner}}},
  howpublished = {https://www.socialmediaexaminer.com/get-tweets-noticed/},
  file = {/Users/miriamamin/Documents/Zotero/storage/5GGH5ZPN/get-tweets-noticed.html}
}

@misc{HowBeTwitter,
  title = {How to {{Be}} a {{Twitter Celebrity}}},
  abstract = {Everyone wants to get their thoughts out to the world. Being popular on Twitter can help you market your tweeting, but that doesn't mean you can't climb your way to the top too! Some well-chosen, witty blogging topics and aggressive...},
  journal = {wikiHow},
  howpublished = {https://www.wikihow.com/Be-a-Twitter-Celebrity},
  file = {/Users/miriamamin/Documents/Zotero/storage/EEPNP5C4/Be-a-Twitter-Celebrity.html}
}

@misc{ExploringCelebrityDynamics,
  title = {Exploring Celebrity Dynamics on {{Twitter}}},
  howpublished = {https://dl.acm.org/citation.cfm?id=2528242},
  file = {/Users/miriamamin/Documents/Zotero/storage/23F4XJVF/citation.html}
}

@misc{ExploringCelebrityDynamicsa,
  title = {Exploring Celebrity Dynamics on {{Twitter}}},
  howpublished = {https://dl.acm.org/citation.cfm?id=2528242},
  file = {/Users/miriamamin/Documents/Zotero/storage/KMJGTCFV/citation.html}
}

@misc{ExploringCelebrityDynamicsb,
  title = {Exploring Celebrity Dynamics on {{Twitter}}},
  howpublished = {https://dl.acm.org/citation.cfm?id=2528242},
  file = {/Users/miriamamin/Documents/Zotero/storage/I5UFKHGK/citation.html}
}

@book{loperNaturalLanguageProcessing,
  title = {Natural {{Language Processing}} with {{Python}}},
  isbn = {978-0-596-51649-9},
  abstract = {This book offers a highly accessible introduction to Natural Language Processing, the field that underpins a variety of language technologies ranging from predictive text and email filtering to automatic summarization and translation. You'll learn...},
  language = {en},
  author = {Loper, Ewan Klein, Edward, Steven Bird},
  file = {/Users/miriamamin/Documents/Zotero/storage/KIZ5BBLY/9780596516499.html}
}

@book{loperNaturalLanguageProcessinga,
  title = {Natural {{Language Processing}} with {{Python}}},
  isbn = {978-0-596-51649-9},
  abstract = {This book offers a highly accessible introduction to Natural Language Processing, the field that underpins a variety of language technologies ranging from predictive text and email filtering to automatic summarization and translation. You'll learn...},
  language = {en},
  author = {Loper, Ewan Klein, Edward, Steven Bird},
  file = {/Users/miriamamin/Documents/Zotero/storage/H4ZUYFMR/Loper - Natural Language Processing with Python.pdf;/Users/miriamamin/Documents/Zotero/storage/FZ5CNYXA/9780596516499.html},
  annote = {\textbf{Anmerkungen herauskopieren (26.3.2018, 21:24:42)}

"text1.concordance("monstrous")" (\href{zotero://open-pdf/0_H4ZUYFMR/26}{Loper :26})

\emph{zeigt Wortkontext (\href{zotero://open-pdf/0_H4ZUYFMR/26}{note on p.26})}

~

"text1.similar("monstrous")" (\href{zotero://open-pdf/0_H4ZUYFMR/27}{Loper :27})

\emph{\dbend\dbend{}z (\href{zotero://open-pdf/0_H4ZUYFMR/27}{note on p.27})}

~

"text2.common\_contexts(["monstrous", "very"])" (\href{zotero://open-pdf/0_H4ZUYFMR/27}{Loper :27})

\emph{\dbend\dbend{}z (\href{zotero://open-pdf/0_H4ZUYFMR/27}{note on p.27})}

~

"text4.dispersion\_plot(["citizens", "democracy", "freedom", "duties", "America"])" (\href{zotero://open-pdf/0_H4ZUYFMR/28}{Loper :28})

\emph{\dbend\dbend{}z (\href{zotero://open-pdf/0_H4ZUYFMR/28}{note on p.28})}

~

"text3.generate()" (\href{zotero://open-pdf/0_H4ZUYFMR/29}{Loper :29})

\emph{generiert Zufallstext auf Grundlage des Ausgangstextes (\href{zotero://open-pdf/0_H4ZUYFMR/29}{note on p.29})}

~

"len(text3)" (\href{zotero://open-pdf/0_H4ZUYFMR/29}{Loper :29})

\emph{\dbend\dbend{}A (\href{zotero://open-pdf/0_H4ZUYFMR/29}{note on p.29})}

~

"sorted(set(text3))" (\href{zotero://open-pdf/0_H4ZUYFMR/30}{Loper :30})

"By wrapping sorted() around the Python expression set(text3) , we obtain a sorted list of vocabulary items, beginning with various punctuation symbols and continuing with words starting with A." (\href{zotero://open-pdf/0_H4ZUYFMR/30}{Loper :30})

"text3.count("smote")" (\href{zotero://open-pdf/0_H4ZUYFMR/30}{Loper :30})

"The ... prompt indicates that Python expects an indented code block to appear next." (\href{zotero://open-pdf/0_H4ZUYFMR/31}{Loper :31})

"function, and we define a short name for our function with the keyword def ." (\href{zotero://open-pdf/0_H4ZUYFMR/31}{Loper :31})

"Lists" (\href{zotero://open-pdf/0_H4ZUYFMR/32}{Loper :32})

"A pleasant surprise is that we can use Python's addition operator on lists. Adding two lists creates a new list with everything from the first list, followed by everything from the second list:" (\href{zotero://open-pdf/0_H4ZUYFMR/33}{Loper :33})}
}

@inproceedings{suhWantBeRetweeted2010,
  title = {Want to Be {{Retweeted}}? {{Large Scale Analytics}} on {{Factors Impacting Retweet}} in {{Twitter Network}}},
  shorttitle = {Want to Be {{Retweeted}}?},
  abstract = {Retweeting is the key mechanism for information diffusion in Twitter. It emerged as a simple yet powerful way of disseminating information in the Twitter social network. Even though a lot of information is shared in Twitter, little is known yet about how and why certain information spreads more widely than others. In this paper, we examine a number of features that might affect retweetability of tweets. We gathered content and contextual features from 74M tweets and used this data set to identify factors that are significantly associated with retweet rate. We also built a predictive retweet model. We found that, amongst content features, URLs and hashtags have strong relationships with retweetability. Amongst contextual features, the number of followers and followees as well as the age of the account seem to affect retweetability, while, interestingly, the number of past tweets does not predict retweetability of a user's tweet. We believe that this research would inform the design of sensemaking and analytics tools for social media streams.},
  booktitle = {2010 {{IEEE Second International Conference}} on {{Social Computing}}},
  doi = {10.1109/SocialCom.2010.33},
  author = {Suh, B. and Hong, L. and Pirolli, P. and Chi, E. H.},
  month = aug,
  year = {2010},
  keywords = {social networking (online),Twitter,Correlation,Data analysis,Feature extraction,information diffusion,Mathematical model,media streaming,Principal component analysis,retweet model,social media streams,Twitter network},
  pages = {177-184},
  file = {/Users/miriamamin/Documents/Zotero/storage/P5UFNS3K/Suh et al_2010_Want to be Retweeted.pdf;/Users/miriamamin/Documents/Zotero/storage/PNCEDDRF/5590452.html}
}

@article{grandjeanSocialNetworkAnalysis2016,
  title = {A Social Network Analysis of {{Twitter}}: {{Mapping}} the Digital Humanities Community},
  volume = {3},
  issn = {null},
  shorttitle = {A Social Network Analysis of {{Twitter}}},
  abstract = {Defining digital humanities might be an endless debate if we stick to the discussion about the boundaries of this concept as an academic ``discipline''. In an attempt to concretely identify this field and its actors, this paper shows that it is possible to analyse them through Twitter, a social media widely used by this ``community of practice''. Based on a network analysis of 2,500 users identified as members of this movement, the visualisation of the ``who's following who?'' graph allows us to highlight the structure of the network's relationships, and identify users whose position is particular. Specifically, we show that linguistic groups are key factors to explain clustering within a network whose characteristics look similar to a small world.},
  number = {1},
  journal = {Cogent Arts \& Humanities},
  doi = {10.1080/23311983.2016.1171458},
  author = {Grandjean, Martin},
  editor = {Mauro, Aaron},
  month = dec,
  year = {2016},
  keywords = {data visualisation,Twitter,digital humanities,digital studies,networks,social media,social network analysis,sociometry},
  pages = {1171458},
  file = {/Users/miriamamin/Documents/Zotero/storage/TVKYUV6J/Grandjean_2016_A social network analysis of Twitter.pdf;/Users/miriamamin/Documents/Zotero/storage/B65XUZIX/23311983.2016.html}
}

@misc{161002060Sandy,
  title = {[1610.02060] {{After Sandy Hook Elementary}}: {{A Year}} in the {{Gun Control Debate}} on {{Twitter}}},
  howpublished = {https://arxiv.org/abs/1610.02060},
  file = {/Users/miriamamin/Documents/Zotero/storage/C4X38CEX/[1610.02060] After Sandy Hook Elementary A Year i.pdf;/Users/miriamamin/Documents/Zotero/storage/RRIB7JKJ/1610.html}
}

@article{bentonSandyHookElementary2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1610.02060},
  primaryClass = {cs},
  title = {After {{Sandy Hook Elementary}}: {{A Year}} in the {{Gun Control Debate}} on {{Twitter}}},
  shorttitle = {After {{Sandy Hook Elementary}}},
  abstract = {The mass shooting at Sandy Hook elementary school on December 14, 2012 catalyzed a year of active debate and legislation on gun control in the United States. Social media hosted an active public discussion where people expressed their support and opposition to a variety of issues surrounding gun legislation. In this paper, we show how a content-based analysis of Twitter data can provide insights and understanding into this debate. We estimate the relative support and opposition to gun control measures, along with a topic analysis of each camp by analyzing over 70 million gun-related tweets from 2013. We focus on spikes in conversation surrounding major events related to guns throughout the year. Our general approach can be applied to other important public health and political issues to analyze the prevalence and nature of public opinion.},
  journal = {arXiv:1610.02060 [cs]},
  author = {Benton, Adrian and Hancock, Braden and Coppersmith, Glen and Ayers, John W. and Dredze, Mark},
  month = oct,
  year = {2016},
  keywords = {Computer Science - Computers and Society,Computer Science - Social and Information Networks},
  file = {/Users/miriamamin/Documents/Zotero/storage/VZP3IXNS/Benton et al_2016_After Sandy Hook Elementary.pdf;/Users/miriamamin/Documents/Zotero/storage/3YW32MA2/1610.html},
  annote = {Comment: Presented at the Data For Good Exchange 2016}
}

@misc{danzarrellaScienceReTweets20:49:58UTC,
  type = {Business},
  title = {The {{Science Of ReTweets}}},
  abstract = {A compilation of data about ReTweets that will help you write more contagious},
  author = {Dan Zarrella},
  year = {20:49:58 UTC}
}

@article{liuSentimentAnalysisOpinion,
  title = {Sentiment {{Analysis}} and {{Opinion Mining}}},
  language = {en},
  author = {Liu, Bing},
  pages = {168},
  file = {/Users/miriamamin/Documents/Zotero/storage/274WWVHT/Liu - Sentiment Analysis and Opinion Mining.pdf}
}

@inproceedings{nalisnickExtractingSentimentNetworks2013,
  title = {Extracting {{Sentiment Networks}} from {{Shakespeare}}'s {{Plays}}},
  isbn = {978-0-7695-4999-6},
  abstract = {Automatic methods for analyzing sentiment and its movement through a play's social network are investigated. From structured dialogue we can algorithmically determine who is speaking and guess at who is listening or being directly addressed. Knowing who is speaking to whom allows the flow of sentiment to be tracked between characters and, within plays with clear time-lines, permits tracking the development of emotional relationships. We hypothesize that changing polarities between characters can be modeled as edge weights in a dynamic social network\textendash{} a ``sentiment network''\textendash{}which can be used to distinguish a document's genre (tragedies versus comedies), detect a given character's enemies and allies, and model the overall emotional development of a play. Experiments on Shakespeare's plays are presented along with discussion of improvements and further applications.},
  language = {en},
  publisher = {{IEEE}},
  doi = {10.1109/ICDAR.2013.155},
  author = {Nalisnick, Eric T. and Baird, Henry S.},
  month = aug,
  year = {2013},
  pages = {758-762},
  file = {/Users/miriamamin/Documents/Zotero/storage/VYL8JXSS/Nalisnick und Baird - 2013 - Extracting Sentiment Networks from Shakespeare's P.pdf}
}

@inproceedings{nalisnickCharactertoCharacterSentimentAnalysis2013,
  title = {Character-to-{{Character Sentiment Analysis}} in {{Shakespeare}}'s {{Plays}}},
  abstract = {We present an automatic method for analyzing sentiment dynamics between characters in plays. This literary format's structured dialogue allows us to make assumptions about who is participating in a conversation. Once we have an idea of who a character is speaking to, the sentiment in his or her speech can be attributed accordingly, allowing us to generate lists of a character's enemies and allies as well as pinpoint scenes critical to a character's emotional development. Results of experiments on Shakespeare's plays are presented along with discussion of how this work can be extended to unstructured texts (i.e. novels).},
  language = {en},
  booktitle = {12th {{International Conference}} on {{Document Analysis}} and {{Recognition}}},
  author = {Nalisnick, Eric T and Baird, Henry S},
  year = {2013},
  pages = {479-483},
  file = {/Users/miriamamin/Documents/Zotero/storage/V83Y92VA/Nalisnick und Baird - Character-to-Character Sentiment Analysis in Shake.pdf},
  annote = {\textbf{Anmerkungen herauskopieren (11.6.2018, 22:25:58)}

"We present an automatic method for ana- lyzing sentiment dynamics between char- acters in plays" (\href{zotero://open-pdf/0_V83Y92VA/1}{Nalisnick and Baird :5})

"generate lists of a character's enemies and allies as well as pinpoint scenes critical to a character's emotional development." (\href{zotero://open-pdf/0_V83Y92VA/1}{Nalisnick and Baird :5})

"can computers extract the emotions en- coded in a narrative? For example, can the love Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 479\textendash{}483, gs of the 51st Annual Meeting of the Association for Computational Linguistics, pages Sofia, Bulgaria, August 4-9 2013. c 2013 Association for Computational Linguistics that Shakespeare's Juliet feels for Romeo be com- putationally tracked?" (\href{zotero://open-pdf/0_V83Y92VA/1}{Nalisnick and Baird :5})

"In fact, some humanists believe literary analysis is so closely tied to the human condition that it is impossible for computers to perform." (\href{zotero://open-pdf/0_V83Y92VA/1}{Nalisnick and Baird :5})

"Unfortunately but unsurprisingly, computa- tional modeling of the emotional relationships de- scribed in natural language text remains a daunting technical challenge. The reason this task is so dif- ficult is that emotions are indistinct and often sub- tly conveyed, especially in text with literary merit." (\href{zotero://open-pdf/0_V83Y92VA/1}{Nalisnick and Baird :5})

"Humans typically achieve no greater than 80\% ac- curacy in sentiment classification experiments in- volving product reviews" (\href{zotero://open-pdf/0_V83Y92VA/1}{Nalisnick and Baird :5})

"Similar experiments on fiction texts would presumably yield even higher error rates." (\href{zotero://open-pdf/0_V83Y92VA/1}{Nalisnick and Baird :5})

"Sen- timent analysis (Pang and Lee, 2008) has been successfully applied to mine social media data" (\href{zotero://open-pdf/0_V83Y92VA/1}{Nalisnick and Baird :5})

"by using emotion lexicons\textendash{}lists that map words to polarity values (+1 for positive sentiment, -1 for negative)" (\href{zotero://open-pdf/0_V83Y92VA/1}{Nalisnick and Baird :5})

"In the following paper, we describe our attempts to use modern sentiment lexicons and dialogue structure to algorithmically track and model\textendash{}with no domain-specific customization\textendash{}the emotion dynamics between characters in Shakespeare's plays. 1" (\href{zotero://open-pdf/0_V83Y92VA/1}{Nalisnick and Baird :5})

"Traditional machine learning techniques on n-grams, parts of speech, and other bag of words features can be used when the data is labeled" (\href{zotero://open-pdf/0_V83Y92VA/2}{Nalisnick and Baird :6})

\emph{Man nimmt also an, dass sich die Sprache, die hinter einem 10-Punkte Kommentar steckt, auf irgendeine Weise mit der Bewertung korreliert unf macht daraus ein statistisches Modell (\href{zotero://open-pdf/0_V83Y92VA/2}{note on p.6})}

~

"d (e.g. IMDB's user reviews are labeled with one to ten stars, which are assumed to correlate with the text's polarity" (\href{zotero://open-pdf/0_V83Y92VA/2}{Nalisnick and Baird :6})

"Knowledge-based methods (which also typi- cally rely on crowdsourcing) provide an alter- native to using labeled data (Andreevskaia and Bergler, 2007). These methods are driven by sentiment lexicons, fixed lists associating words with ``valences'' (signed integers representing pos- itive and negative feelings)" (\href{zotero://open-pdf/0_V83Y92VA/2}{Nalisnick and Baird :6})

"Chambers and Jurafsky (2009) described a system that can learn (without supervision) the sequence of events described in a narrative, and Elson and McKeown (2009) created a platform that can symbolically represent and rea- son over narratives." (\href{zotero://open-pdf/0_V83Y92VA/2}{Nalisnick and Baird :6})

"Mut- ton (2004) adapted methods for extracting social networks from Internet Relay Chat (IRC) to mine Shakespeare's plays for their networks." (\href{zotero://open-pdf/0_V83Y92VA/2}{Nalisnick and Baird :6})

"Elson and McKeown (2010) developed a reliable method for speech attribution in unstructured texts, and then used this method to successfully extract social networks from Victorian novels" (\href{zotero://open-pdf/0_V83Y92VA/2}{Nalisnick and Baird :6})

"While structure is undeniably important, we be- lieve analyzing a narrative's emotions is essen- tial to capturing the `reading experience,'" (\href{zotero://open-pdf/0_V83Y92VA/2}{Nalisnick and Baird :6})

"Alm and Sproat (2005) analyzed Brothers Grimm fairy tales for their `emotional trajectories,' finding emotion typ- ically increases as a story progresses." (\href{zotero://open-pdf/0_V83Y92VA/2}{Nalisnick and Baird :6})

"Mohammad (2011) scaled-up their work by using a crowd- sourced emotion lexicon to track emotion dynam- ics over the course of many novels and plays, in- cluding Shakespeare's." (\href{zotero://open-pdf/0_V83Y92VA/2}{Nalisnick and Baird :6})

"Elsner (2012) analyzed emotional trajectories at the character level, showing how Miss Elizabeth Bennet's emotions change over the course of Pride and Prejudice." (\href{zotero://open-pdf/0_V83Y92VA/2}{Nalisnick and Baird :6})

"We attempt to further Elsner's line of work by leveraging text structure (as Mutton and Elson did) and knowlege-based SA to track the emotional tra- jectories of interpersonal relationships rather than of a whole text or an isolated character." (\href{zotero://open-pdf/0_V83Y92VA/2}{Nalisnick and Baird :6})

"Unsurprisingly, methods which, like these, lack deep understanding often work more reliably as the length of the input text increases." (\href{zotero://open-pdf/0_V83Y92VA/2}{Nalisnick and Baird :6})

"To ex- tract these relationships, we mined for character- to-character sentiment by summing the valence values (provided by the AFINN sentiment lexicon (Nielsen, 2011)) over each instance of continuous speech and then assumed that sentiment was di- rected towards the character that spoke immedi- ately before the current speaker." (\href{zotero://open-pdf/0_V83Y92VA/2}{Nalisnick and Baird :6})

"After running this automatic analysis on all of Shakespeare's plays, not all the results examined were as enlightening as the Hamlet vs. Gertrude example." (\href{zotero://open-pdf/0_V83Y92VA/3}{Nalisnick and Baird :7})

"Instead, the majority supported our al- ready held interpretations." (\href{zotero://open-pdf/0_V83Y92VA/3}{Nalisnick and Baird :7})

"Unfortunately, we do not have room in this pa- per to discuss further examples, but a visualization of sentiment dynamics between any pair of char- acters in any of Shakespeare's plays can be seen at www.lehigh.edu/{$\sim$}etn212/ShakespeareExplorer.html" (\href{zotero://open-pdf/0_V83Y92VA/4}{Nalisnick and Baird :8})

"Future Work" (\href{zotero://open-pdf/0_V83Y92VA/4}{Nalisnick and Baird :8})

"The sentiment lexicon we used, AFINN, is designed for modern English; thus, it should only provide better anal- ysis on works written after Shakespeare's" (\href{zotero://open-pdf/0_V83Y92VA/4}{Nalisnick and Baird :8})

"For in- stance, the assumption that the current speaker's sentiment is directed toward the previous speaker is rather naive. A speech could be analyzed for context clues that signal that the character speak- ing is not talking about someone present but about someone out of the scene." (\href{zotero://open-pdf/0_V83Y92VA/4}{Nalisnick and Baird :8})

"The sentiment could then be redirected to the not-present character." (\href{zotero://open-pdf/0_V83Y92VA/4}{Nalisnick and Baird :8})

"Furthermore, detecting subtle rhetorical features such as irony and deceit would markedly improve the accuracy of the analysis on some plays. For ex- ample, our character-to-character analysis fails to detect that Iago hates Othello because Iago gives his commander constant lip service in order to ma- nipulate him\textendash{}only revealing his true feelings at the play's conclusion." (\href{zotero://open-pdf/0_V83Y92VA/4}{Nalisnick and Baird :8})

"Yet, we believe the most noteworthy as- pect of this work lies not in the details of our tech- nique but rather in the demonstration that detailed emotion dynamics can be extracted with simplis- tic approaches\textendash{}which in turn gives promise to the future work of robust analysis of interpersonal re- lationships in short stories and novels." (\href{zotero://open-pdf/0_V83Y92VA/4}{Nalisnick and Baird :8})

"As demonstrated, shallow, un-customized senti- ment analysis can be used in conjunction with text structure to analyze interpersonal relation- ships described within a play and output an inter- pretation that matches reader expectations." (\href{zotero://open-pdf/0_V83Y92VA/4}{Nalisnick and Baird :8})}
}

@inproceedings{pangThumbsSentimentClassification2002,
  title = {Thumbs up?: Sentiment Classification Using Machine Learning Techniques},
  volume = {10},
  shorttitle = {Thumbs Up?},
  abstract = {We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. Using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines. However, the three machine learning methods we employed (Naive Bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization. We conclude by examining factors that make the sentiment classification problem more challenging.},
  language = {en},
  publisher = {{Association for Computational Linguistics}},
  doi = {10.3115/1118693.1118704},
  author = {Pang, Bo and Lee, Lillian and Vaithyanathan, Shivakumar},
  year = {2002},
  pages = {79-86},
  file = {/Users/miriamamin/Documents/Zotero/storage/GZHQL4FE/Pang et al. - 2002 - Thumbs up sentiment classification using machine.pdf}
}

@article{warrinerNormsValenceArousal2013,
  title = {Norms of Valence, Arousal, and Dominance for 13,915 {{English}} Lemmas},
  volume = {45},
  abstract = {Information about the affective meaning of words is used by researchers working on emotions and moods, word recognition and memory, and text-based sentiment analysis. Three components of emotions are traditionally distinguished: valence (the pleasantness of the stimulus), arousal (the intensity of emotion provoked by the stimulus), and dominance (the degree of control exerted by the stimulus). Thus far, nearly all research has been based on the ANEW norms collected by Bradley and Lang (1999) for 1,034 words. We extend the database to nearly 14 thousand English lemmas, providing researchers with a much richer source of information, including information on gender, age and educational differences in emotion norms. As an example of the new possibilities, we included the stimuli from nearly all category norms (types of diseases, occupations, and taboo words) collected by Van Overschelde, Rawson,and Dunlosky (2004), making it possible to include affect in studies on semantic memory.},
  language = {en},
  number = {4},
  journal = {Behavior Research Methods},
  author = {Warriner, Amy Beth and Kuperman, Victor and Brysbaert, Marc},
  year = {2013},
  pages = {1191--1207},
  file = {/Users/miriamamin/Documents/Zotero/storage/BHFKKCBQ/Warriner et al. - Norms of valence, arousal, and dominance for 13,91.pdf}
}

@article{nielsenNewANEWEvaluation2011,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1103.2903},
  primaryClass = {cs},
  title = {A New {{ANEW}}: {{Evaluation}} of a Word List for Sentiment Analysis in Microblogs},
  shorttitle = {A New {{ANEW}}},
  abstract = {Sentiment analysis of microblogs such as Twitter has recently gained a fair amount of attention. One of the simplest sentiment analysis approaches compares the words of a posting against a labeled word list, where each word has been scored for valence, -- a 'sentiment lexicon' or 'affective word lists'. There exist several affective word lists, e.g., ANEW (Affective Norms for English Words) developed before the advent of microblogging and sentiment analysis. I wanted to examine how well ANEW and other word lists performs for the detection of sentiment strength in microblog posts in comparison with a new word list specifically constructed for microblogs. I used manually labeled postings from Twitter scored for sentiment. Using a simple word matching I show that the new word list may perform better than ANEW, though not as good as the more elaborate approach found in SentiStrength.},
  journal = {arXiv:1103.2903 [cs]},
  author = {Nielsen, Finn {\AA}rup},
  month = mar,
  year = {2011},
  keywords = {68M11,Computer Science - Computation and Language,Computer Science - Information Retrieval,H.4.3,J.4},
  file = {/Users/miriamamin/Documents/Zotero/storage/FYMTMMNS/Nielsen_2011_A new ANEW.pdf;/Users/miriamamin/Documents/Zotero/storage/QMJ4MVAV/1103.html},
  annote = {Comment: 6 pages, 4 figures, 1 table, Submitted to "Making Sense of Microposts (\#MSM2011)"}
}

@inproceedings{finnarupnielsenNewANEWEvaluation2011,
  title = {A New {{ANEW}}: {{Evaluation}} of a Word List for Sentiment Analysis in Microblogs},
  booktitle = {Proceedings of the {{ESWC2011 Workshop}} on '{{Making Sense}} of {{Microposts}}': {{Big}} Things Come in Small Packages},
  author = {{Finn {\AA}rup Nielsen}},
  year = {2011},
  pages = {93-98},
  file = {/Users/miriamamin/Documents/Zotero/storage/G672GNN5/imm6006.pdf;/Users/miriamamin/Documents/Zotero/storage/IK6YEKMT/1103.html}
}

@misc{11032903New,
  title = {[1103.2903] {{A}} New {{ANEW}}: {{Evaluation}} of a Word List for Sentiment Analysis in Microblogs},
  howpublished = {https://arxiv.org/abs/1103.2903},
  file = {/Users/miriamamin/Documents/Zotero/storage/42TI2JRY/1103.html}
}

@article{ritchieCurrentDirectionsComputational2001,
  title = {Current {{Directions}} in {{Computational Humour}}},
  volume = {16},
  issn = {1573-7462},
  abstract = {Humour is a valid subject for research in artificial intelligence, as it is one of the more complex of human behaviours. Although philosophers and others have discussed humour for centuries, it is only very recently that computational work has begun in this field, so the state of the art is still rather basic. Much of the research has concentrated on humour expressed verbally, and there has been some emphasis on models based on ``incongruity''. Actual implementations have involved puns of very limited forms. It is not clear that computerised jokes could enhance user interfaces in the near future, but there is a role for computer modelling in testing symbolic accounts of the structure of humorous texts. A major problem is the need for a humour-processing program to have knowledge of the world, and reasoning abilities.},
  language = {en},
  number = {2},
  journal = {Artificial Intelligence Review},
  doi = {10.1023/A:1011610210506},
  author = {Ritchie, Graeme},
  month = oct,
  year = {2001},
  keywords = {affective computing,artificial intelligence,humour,jokes,puns},
  pages = {119-135},
  file = {/Users/miriamamin/Documents/Zotero/storage/5QKNL4EN/Ritchie_2001_Current Directions in Computational Humour.pdf}
}

@article{ritchieCanComputersCreate2009,
  title = {Can {{Computers Create Humor}}?},
  volume = {30},
  copyright = {T},
  abstract = {in what they can cover, there is little doubt that the construction of humor is generally regarded as creative, with the most successful creators of humor sometimes being hailed as ``comic geniuses.'' This suggests that the task of getting a computer to produce humor falls within the area of computational creativity, and any general theory of creativity should have something to say about humor. This article reviews some of the work in computational humor, makes some observations about the more general issues that these projects raise, and considers this work from the viewpoint of creativity, concluding with an outline of some of the challenges ahead.},
  journal = {AI Magazine},
  author = {Ritchie, Graeme},
  year = {2009},
  keywords = {overview},
  pages = {71-81},
  file = {/Users/miriamamin/Documents/Zotero/storage/HZRWW2HU/Ritchie_2009_Can Computers Create Humor.pdf},
  annote = {\textbf{Extracted Annotations (16/01/2019, 18:29:00)}

"One obstacle to progress is the lack of a precise and detailed theory of how humor operates." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=1}{Ritchie 2009:71})

", since the early 1990s, there have been a number of small pro- grams that create simple verbal humor" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=1}{Ritchie 2009:71})

"the task of getting a computer to produce humor falls within the area of computational creativi- ty" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=1}{Ritchie 2009:71})

"This article reviews some of the work in computational humor, makes some observations about the more general issues that these projects raise" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=1}{Ritchie 2009:71})

"the cognitive and emotional processes involved in creating or responding to humor are still unexplained" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=1}{Ritchie 2009:71})

"Emotional aspects of human behavior were not deemed a suit- able matter for AI research until about 1990, and mainstream work in AI completely ignored humor for the first 35 years or so of the field's existence" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=2}{Ritchie 2009:72})

"computational modeling of humor is still at an early stage, with few established precepts or results." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=2}{Ritchie 2009:72})

"Although there are many books and articles on humor from the perspective of philosophy and literature (and\textemdash{} more recently\textemdash{}of psychology), none of that has resulted in agreement about a theory of humor." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=2}{Ritchie 2009:72})

"researchers have applied conventional AI method- ologies to the problem of humor, developing mod- els that are very limited in their scope, but that can at least be implemented. Such programs typically make little or no use of theories of humor." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=2}{Ritchie 2009:72})

"Humor-generating programs are typically designed by examining some extremely small area of humor, abstracting some structural patterns from existing examples (for example, jokes found in joke books), formulating computationally man- ageable rules that describe these patterns, and implementing an algorithm to handle these rules." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=2}{Ritchie 2009:72})

"Data (that is, examples of humor)" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"there are almost no computer programs dealing with non- textual humor" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"Computational humor programs are no exception. They are all based on the assumption that the humorous items under con- sideration can be characterized by a statement of various formal relations between parts of those items or some underlying abstract entities." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"Probably the earliest actual joke generator is that of Lessard and Levison (1992), which built very simple puns such as this one, in which a quoted utterance puns with an adverb: ``This matter is opaque,'' said Tom obscurely." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"next stage of development was punning riddles, which began emerging from computer programs in 1993" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"What kind of animal rides a catamaran? A cat." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"Around the same time, the joke analysis and pro- duction engine (JAPE) program (Binsted 1996; Bin- sted and Ritchie 1994, 1997) was constructed" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"JAPE was a conventional rule-driven program, implemented in Prolog, using a relatively small number of pattern-matching rules to compose the riddle structures and using a conventional diction- ary based on WordNet" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"Venour (1999) built a pun gen- erator that could construct simple two-word phras- es punning on a preceding setup sentence" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"Another small-scale pun generator was that of McKay (2002), whose program could build simple one-line puns" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"the early pun generators were programmed without reference to any general plan of how a punning program should be constructed" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"The architec- ture adopted by the JAPE program, however, has a relatively clean modular structure" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"Bergen and Binsted (2003) examine a sub- class of joke based on exaggerated statements on some scale" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=4}{Ritchie 2009:74})

"Stark, Binsted, and Bergen (2005) describe a pro- gram that can select (from a short list of options) the most suitable punchline for a joke" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=4}{Ritchie 2009:74})

"Tinholt and Nijholt (2007) describe a small pro- totype system for generating jokes in the form of deliberately misunderstood pronoun references" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=4}{Ritchie 2009:74})

"Mihalcea and Strapparava (2006) carried out a number of studies in which various machine-learn- ing and text-classification methods were applied to large quantities of textual data, both humorous and nonhumorous. The aim was to see whether it was possible to evolve classifiers (of various kinds) that distinguish humorous texts from nonhumor- ous." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=4}{Ritchie 2009:74})

"there has also been a non- punning system that may lie on the boundary of verbal and referential humor: the HAHAcronym program (Stock and Strapparava 2003, 2005)" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=4}{Ritchie 2009:74})

"given an existing acronym (for example, DMSO, for defense modeling and simulation office), it computes alternative words with these initials to form a whimsical phrase" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=4}{Ritchie 2009:74})

"computational humor has concen- trated, so far, on verbal humor, although there have been a few small forays into referential humor." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=4}{Ritchie 2009:74})

"Mihalcea and Strapparava (2006) carried out a number of studies in which various machine-learn- ing and text-classification methods were applied to large quantities of textual data, both humorous and nonhumorous. The aim was to see whether it was possible to evolve classifiers (of various kinds) that distinguish humorous texts from nonhumor- ous." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=4}{Ritchie 2009:74})

"The main problem is that the automatic classi- fiers detect correlations (loosely speaking) between certain features and humor but do not determine causality from features to humor." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=5}{Ritchie 2009:75})

"The whole point of developing models of humor, in the general tradition of reductionist science, is to decompose the nature of humor creation into some configuration of other (nonhumorous) processes." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=5}{Ritchie 2009:75})

"This is illustrated in the early pun generators. These systems crucially had to find words that were in a well-defined relationship, such as sounding alike. These items are the core of the pun, but oth- er text must be created around them to set up the pun. Within certain constraints on the internal coherence of the overall text, there could be many such setups for the same central pun. For example, given two core lexical items in which one sounds similar to the start of the other, such as pylon and pa, the answer for a punning riddle can be con-" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=5}{Ritchie 2009:75})

"Strapparava, Valitutti, and Stock (2007) describe some explorations of the possibility of using com- putational pun making in the ``creative'' develop-" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=6}{Ritchie 2009:76})

"structed, ``a pa-lon,'' and the question for the riddle can be framed by asking about some entity that has properties of both the named concepts. This can be done using other words that are semanti- cally related to these two words, such as hyper- nyms or synonyms, but the question can be formed in various ways, such as ``what kind of tow- er is a dad?'' ``what do you get when you cross a tower with a father?'' ``what do you call a tower with a fam- ily?'' and so on." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=6}{Ritchie 2009:76})

"ment of an advertising campaign, but as yet that area is unexploited." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=7}{Ritchie 2009:77})

"Binsted (1995) considered whether a natural lan- guage user interface for a computer system would be more congenial if the system could make use of humor to lessen the impact of inadequacies in its performance" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=7}{Ritchie 2009:77})

"For humans, simply appreciating humor\textemdash{}of which everyone is capable\textemdash{}is not usually regard- ed as creative. Hence, even where a computer pro- gram manages a first step toward appreciation (namely, recognizing that an item is humorous), it is hard to argue that the software is being creative, no matter how effectively it performs this step." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=8}{Ritchie 2009:78})

"Humans who produce novel humor (particular- ly humor of a high standard) are usually deemed to be creative, so perhaps humor-generating pro- grams should have similar status." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=8}{Ritchie 2009:78})

"However, it is difficult to argue now that building another pun generator would, in itself, be a significant step forward, unless it introduced some nontrivial step forward in the direction of wider generality." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=8}{Ritchie 2009:78})

"First, there is the issue of contextual relevance. Although attempts at joke generation have implic- itly been tackling the issue of ``quality''\textemdash{}since the aim is to create jokes that are as good as possible\textemdash{} the joke generators are usually designed to create single texts in isolation. That is, these are ``self-con- tained'' puns, in which the central words or phras- es are directly related to other words in the same text. In none of these cases is an utterance created that somehow links to a realistically complex con- text of use." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=8}{Ritchie 2009:78})

"The second possible improvement would be in the quality of the humor. Although existing pro- grams produce structurally well-formed puns, most of the examples are not at all funny, and some barely qualify as jokes" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=9}{Ritchie 2009:79})

"It has often been argued that incongruity is a vital fac- tor in humor, possibly combined with some resolu- tion of that incongruity (Attardo 1994, Ritchie 2004), but there is still no formal and precise defi- nition of what constitutes incongruity (or resolu- tion)." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=9}{Ritchie 2009:79})

"semantic script theory of humor, or SSTH (Raskin 1985)" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=9}{Ritchie 2009:79})

\textbf{Extracted Annotations (27/11/2018, 16:34:55)}

"One obstacle to progress is the lack of a precise and detailed theory of how humor operates." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=1}{Ritchie 2009:71})

", since the early 1990s, there have been a number of small pro- grams that create simple verbal humor" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=1}{Ritchie 2009:71})

"the task of getting a computer to produce humor falls within the area of computational creativi- ty" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=1}{Ritchie 2009:71})

"This article reviews some of the work in computational humor, makes some observations about the more general issues that these projects raise" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=1}{Ritchie 2009:71})

"the cognitive and emotional processes involved in creating or responding to humor are still unexplained" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=1}{Ritchie 2009:71})

"Emotional aspects of human behavior were not deemed a suit- able matter for AI research until about 1990, and mainstream work in AI completely ignored humor for the first 35 years or so of the field's existence" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=2}{Ritchie 2009:72})

"computational modeling of humor is still at an early stage, with few established precepts or results." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=2}{Ritchie 2009:72})

"Although there are many books and articles on humor from the perspective of philosophy and literature (and\textemdash{} more recently\textemdash{}of psychology), none of that has resulted in agreement about a theory of humor." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=2}{Ritchie 2009:72})

"researchers have applied conventional AI method- ologies to the problem of humor, developing mod- els that are very limited in their scope, but that can at least be implemented. Such programs typically make little or no use of theories of humor." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=2}{Ritchie 2009:72})

"Humor-generating programs are typically designed by examining some extremely small area of humor, abstracting some structural patterns from existing examples (for example, jokes found in joke books), formulating computationally man- ageable rules that describe these patterns, and implementing an algorithm to handle these rules." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=2}{Ritchie 2009:72})

"Data (that is, examples of humor)" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"there are almost no computer programs dealing with non- textual humor" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"Computational humor programs are no exception. They are all based on the assumption that the humorous items under con- sideration can be characterized by a statement of various formal relations between parts of those items or some underlying abstract entities." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"Probably the earliest actual joke generator is that of Lessard and Levison (1992), which built very simple puns such as this one, in which a quoted utterance puns with an adverb: ``This matter is opaque,'' said Tom obscurely." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"next stage of development was punning riddles, which began emerging from computer programs in 1993" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"What kind of animal rides a catamaran? A cat." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"Around the same time, the joke analysis and pro- duction engine (JAPE) program (Binsted 1996; Bin- sted and Ritchie 1994, 1997) was constructed" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"JAPE was a conventional rule-driven program, implemented in Prolog, using a relatively small number of pattern-matching rules to compose the riddle structures and using a conventional diction- ary based on WordNet" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"Venour (1999) built a pun gen- erator that could construct simple two-word phras- es punning on a preceding setup sentence" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"Another small-scale pun generator was that of McKay (2002), whose program could build simple one-line puns" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"the early pun generators were programmed without reference to any general plan of how a punning program should be constructed" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"The architec- ture adopted by the JAPE program, however, has a relatively clean modular structure" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=3}{Ritchie 2009:73})

"there has also been a non- punning system that may lie on the boundary of verbal and referential humor: the HAHAcronym program (Stock and Strapparava 2003, 2005)" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=4}{Ritchie 2009:74})

"given an existing acronym (for example, DMSO, for defense modeling and simulation office), it computes alternative words with these initials to form a whimsical phrase" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=4}{Ritchie 2009:74})

"computational humor has concen- trated, so far, on verbal humor, although there have been a few small forays into referential humor." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=4}{Ritchie 2009:74})

"Bergen and Binsted (2003) examine a sub- class of joke based on exaggerated statements on some scale" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=4}{Ritchie 2009:74})

"Stark, Binsted, and Bergen (2005) describe a pro- gram that can select (from a short list of options) the most suitable punchline for a joke" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=4}{Ritchie 2009:74})

"Tinholt and Nijholt (2007) describe a small pro- totype system for generating jokes in the form of deliberately misunderstood pronoun references" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=4}{Ritchie 2009:74})

"Mihalcea and Strapparava (2006) carried out a number of studies in which various machine-learn- ing and text-classification methods were applied to large quantities of textual data, both humorous and nonhumorous. The aim was to see whether it was possible to evolve classifiers (of various kinds) that distinguish humorous texts from nonhumor- ous." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=4}{Ritchie 2009:74})

"The main problem is that the automatic classi- fiers detect correlations (loosely speaking) between certain features and humor but do not determine causality from features to humor." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=5}{Ritchie 2009:75})

"The whole point of developing models of humor, in the general tradition of reductionist science, is to decompose the nature of humor creation into some configuration of other (nonhumorous) processes." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=5}{Ritchie 2009:75})

"Strapparava, Valitutti, and Stock (2007) describe some explorations of the possibility of using com- putational pun making in the ``creative'' develop-" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=6}{Ritchie 2009:76})

"ment of an advertising campaign, but as yet that area is unexploited." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=7}{Ritchie 2009:77})

"Binsted (1995) considered whether a natural lan- guage user interface for a computer system would be more congenial if the system could make use of humor to lessen the impact of inadequacies in its performance" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=7}{Ritchie 2009:77})

"For humans, simply appreciating humor\textemdash{}of which everyone is capable\textemdash{}is not usually regard- ed as creative. Hence, even where a computer pro- gram manages a first step toward appreciation (namely, recognizing that an item is humorous), it is hard to argue that the software is being creative, no matter how effectively it performs this step." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=8}{Ritchie 2009:78})

"Humans who produce novel humor (particular- ly humor of a high standard) are usually deemed to be creative, so perhaps humor-generating pro- grams should have similar status." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=8}{Ritchie 2009:78})

"However, it is difficult to argue now that building another pun generator would, in itself, be a significant step forward, unless it introduced some nontrivial step forward in the direction of wider generality." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=8}{Ritchie 2009:78})

"First, there is the issue of contextual relevance. Although attempts at joke generation have implic- itly been tackling the issue of ``quality''\textemdash{}since the aim is to create jokes that are as good as possible\textemdash{} the joke generators are usually designed to create single texts in isolation. That is, these are ``self-con- tained'' puns, in which the central words or phras- es are directly related to other words in the same text. In none of these cases is an utterance created that somehow links to a realistically complex con- text of use." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=8}{Ritchie 2009:78})

"The second possible improvement would be in the quality of the humor. Although existing pro- grams produce structurally well-formed puns, most of the examples are not at all funny, and some barely qualify as jokes" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=9}{Ritchie 2009:79})

"It has often been argued that incongruity is a vital fac- tor in humor, possibly combined with some resolu- tion of that incongruity (Attardo 1994, Ritchie 2004), but there is still no formal and precise defi- nition of what constitutes incongruity (or resolu- tion)." (\href{zotero://open-pdf/library/items/HZRWW2HU?page=9}{Ritchie 2009:79})

"semantic script theory of humor, or SSTH (Raskin 1985)" (\href{zotero://open-pdf/library/items/HZRWW2HU?page=9}{Ritchie 2009:79})}
}

@article{mihalceaLearningLaughAutomatically2006,
  title = {Learning to {{Laugh}} (Automatically): {{Computational Models}} for {{Humor Recognition}}},
  volume = {22},
  shorttitle = {Learning to {{Laugh}} (Automatically)},
  abstract = {in what they can cover, there is little doubt that the construction of humor is generally regarded as creative, with the most successful creators of humor sometimes being hailed as ``comic geniuses.'' This suggests that the task of getting a computer to produce humor falls within the area of computational creativity, and any general theory of creativity should have something to say about humor. This article reviews some of the work in computational humor, makes some observations about the more general issues that these projects raise, and considers this work from the viewpoint of creativity, concluding with an outline of some of the challenges ahead.},
  journal = {Computational Intelligence},
  author = {Mihalcea, Rada and Strapparava, Carlo},
  year = {2006},
  keywords = {neural network,humor recognition},
  pages = {126-142},
  file = {/Users/miriamamin/Documents/Zotero/storage/Z4WEFXLF/Mihalcea_Strapparava_2006_Learning to Laugh (automatically).pdf}
}

@inproceedings{yangNeuralJokeGeneration2017,
  title = {Neural {{Joke}}-{{Generation}}},
  copyright = {X},
  abstract = {Humor generation is a very hard problem in the area of computational humor. In this paper, we present a joke generation model based on neural networks. The model can generate a short joke relevant to the topic that the user specifies. Inspired by the architecture of neural machine translation and neural image captioning, we use an encoder for representing user-provided topic information and an RNN decoder for joke generation. We trained the model by short jokes of Conan O'Brien with the help of POS Tagger. We evaluate the performance of our model by human ratings from five English speakers. In terms of the average score, our model outperforms a probabilistic model that puts words into slots in a fixed-structure sentence.},
  author = {Yang, Er Ren and Sheng, Quan},
  year = {2017},
  keywords = {humor generation,neural network},
  file = {/Users/miriamamin/Documents/Zotero/storage/SSDHXCMG/Yang_2017_Neural Joke-Generation.pdf},
  annote = {\textbf{Extracted Annotations (27/11/2018, 17:56:45)}

"In this paper, we present a joke generation model based on neural networks. The model can generate a short joke relevant to the topic that the user specifies." (\href{zotero://open-pdf/library/items/SSDHXCMG?page=1}{Yang 2017:1})

"theorists have believed that incongruity contributes to sensations of humor" (\href{zotero://open-pdf/library/items/SSDHXCMG?page=1}{Yang 2017:1})

"the paper concludes that both ambiguity and distinctiveness are significant predictors of humor." (\href{zotero://open-pdf/library/items/SSDHXCMG?page=1}{Yang 2017:1})

"Motivated by these recent developments, in this paper we use a corpus of thousands of short jokes written by Conan O'Brien, and we want our model to be able to generate a relevant and comprehensible joke given a few topic words." (\href{zotero://open-pdf/library/items/SSDHXCMG?page=1}{Yang 2017:1})

"To extract the topic words from the training data, we use the part-of-speech (POS) tagger [7] to collect the proper nouns in the jokes" (\href{zotero://open-pdf/library/items/SSDHXCMG?page=1}{Yang 2017:1})

"We use Global Vectors (GloVe) [8] to represent input and topic words, and LSTM RNN with attention-mechanism as our neural network decoder architecture." (\href{zotero://open-pdf/library/items/SSDHXCMG?page=1}{Yang 2017:1})

"Joke generation is similar to text generation but a lot harder because there must be certain incongruity in the generated content that makes people laugh." (\href{zotero://open-pdf/library/items/SSDHXCMG?page=2}{Yang 2017:2})

"Our training data consists of data from two different sources. The first source is the 7699 jokes written by Conan O'Brien (downloaded from github.com/brendansudol), all of which are short jokes (many are one-sentence jokes) on different topics such as current affairs, politics and sports." (\href{zotero://open-pdf/library/items/SSDHXCMG?page=2}{Yang 2017:2})

"Another source is the online news data from the Mashable website" (\href{zotero://open-pdf/library/items/SSDHXCMG?page=2}{Yang 2017:2})

"Since the joke data are mainly about current affairs, it would be helpful to incorporate news data to improve the training of language model." (\href{zotero://open-pdf/library/items/SSDHXCMG?page=2}{Yang 2017:2})

"We first used Part-of-Speech Tagger (POS Tagger) to extract proper nouns from each training samples." (\href{zotero://open-pdf/library/items/SSDHXCMG?page=3}{Yang 2017:3})

"Word vector are vector space representations of words that can be used for capturing fine-grained semantic and syntactic regularities." (\href{zotero://open-pdf/library/items/SSDHXCMG?page=3}{Yang 2017:3})

"We use the pre-trained GloVe vectors from Stanford NLP group as embedding because it's been proved to combine advantages from both count-based methods like LSA, Hellinger-PCA, and direct prediction methods like Skip-gram and CBOW, and has very good performance on word similarity / analogy tasks." (\href{zotero://open-pdf/library/items/SSDHXCMG?page=3}{Yang 2017:3})

"We encodes the extracted proper nouns, and then average the bag of words as {$\mathsl{E}\mathsl{n}\mathsl{c}$} {$\mathsl{j}\mathsl{o}\mathsl{k}\mathsl{e}$} = ! ! ({$\mathsl{e}$} ! ! + {$\mathsl{e}$} ! ! + {$\cdots$} + {$\mathsl{e}$} ! ! )." (\href{zotero://open-pdf/library/items/SSDHXCMG?page=3}{Yang 2017:3})

"Moreover, the user can also specify the prime words--what words the joke starts with--by providing a list of words like ``I don't know why but'', ``Donald says yesterday that'' etc." (\href{zotero://open-pdf/library/items/SSDHXCMG?page=4}{Yang 2017:4})

"Based on the model trained on our joke corpus, the RNN can generate new text one word at a time. At each time step, the RNN outputs the probabilities that each word in the vocabulary appear next. We don't want to consistently choose the word with the highest probability," (\href{zotero://open-pdf/library/items/SSDHXCMG?page=4}{Yang 2017:4})

"Weighted-pick search strategies can cause the model to take more chances and increase diversity of results at a cost of more mistakes." (\href{zotero://open-pdf/library/items/SSDHXCMG?page=5}{Yang 2017:5})

"The user might want to specify the exact number of words for the RNN to output. If this number is omitted, the joke generation can automatically stop when an end-of-sentence token is produced." (\href{zotero://open-pdf/library/items/SSDHXCMG?page=5}{Yang 2017:5})

"Firstly, we trained the decoder-only model (a vanilla RNN) and tuned the hyperparameter (hidden state length, number of layers, etc) for the best performance in text generation in terms of syntax" (\href{zotero://open-pdf/library/items/SSDHXCMG?page=5}{Yang 2017:5})

"Our neural joke generator has lower percentage of good jokes than the baseline model" (\href{zotero://open-pdf/library/items/SSDHXCMG?page=7}{Yang 2017:7})

"RNN arbitrarily put together seemingly unrelated concepts, causing incongruity. The generated text could be nonsense, but some of them are funny because of incongruity." (\href{zotero://open-pdf/library/items/SSDHXCMG?page=7}{Yang 2017:7})

"We have proposed a new neural network model for mapping arbitrary topics into corresponding natural language jokes. The model combines ideas from recent neural network architectures for machine translation, factoid question generation, as well as neural image captioning (NIC). The produced jokes are evaluated using human evaluation, and are found to outperform a probabilistic model [3]." (\href{zotero://open-pdf/library/items/SSDHXCMG?page=7}{Yang 2017:7})

". In addition, for this paper we only use jokes from one author for easier learning. For broad joke generation, we'll need to incorporate other sources for greater diversity of styles and topics." (\href{zotero://open-pdf/library/items/SSDHXCMG?page=7}{Yang 2017:7})}
}

@article{yamaneSociologyGunCulture2017,
  title = {The Sociology of {{U}}.{{S}}. Gun Culture},
  volume = {11},
  issn = {17519020},
  abstract = {Despite the fact that a robust culture centered on the legal ownership and use of guns by law-abiding gun owners exists in the United States, there is no sociology of U.S. gun culture. Rather, the social scientific study of guns is dominated by criminological and epidemiological studies of gun violence. As a corrective to this oversight, I outline what a sociology of U.S. gun culture should look like. In the first section, I give a brief history of U.S. gun culture from the founding era through the 1960s. Guns began as tools of necessity in the colonies and on the frontier, but evolved into equipment for sport hunting and shooting, as well as desired commodities for collecting. The second section examines these recreational pursuits which formed the core of U.S. gun culture for most of the 20th century. Although recreation remains an important segment, the central emphasis of U.S. gun culture has gradually shifted to armed self-defense over the course of the past half-century. The third section examines the rise of this culture of armed citizenship, what I call ``Gun Culture 2.0,'' the current iteration of the country's historic gun culture. I conclude by suggesting important avenues for future research.},
  language = {en},
  number = {7},
  journal = {Sociology Compass},
  doi = {10.1111/soc4.12497},
  author = {Yamane, David},
  month = jul,
  year = {2017},
  pages = {e12497},
  file = {/Users/miriamamin/Documents/Zotero/storage/WA8AC4K7/Yamane - 2017 - The sociology of U.S. gun culture.pdf},
  annote = {\textbf{Extracted Annotations (10/12/2018, 15:59:33)}

"The 2015 National Firearms Survey allowed respondents to name multiple primary reasons for firearms ownership and found that 40\% named hunting, 34\% collecting, and 28\% sporting us" (\href{zotero://open-pdf/library/items/WA8AC4K7?page=3}{Yamane 2017:3})

"the primary reason for owning a gun." (\href{zotero://open-pdf/library/items/WA8AC4K7?page=5}{Yamane 2017:5})

"26 percent of respondents cited protection as being the primary reason for owning a gun; by 2013, that proportion had grown to 48 percent (Pew Research Center, 2013). Hunting, target/sport shooting, and gun collecting together declined by a roughly equal" (\href{zotero://open-pdf/library/items/WA8AC4K7?page=5}{Yamane 2017:5})

"This shift toward the liberalization of concealed carry laws (Patrick, 2009)." (\href{zotero://open-pdf/library/items/WA8AC4K7?page=5}{Yamane 2017:5})

"These studies tend to find that the political orientation of a locality matters (more Republican, more permits), as do shifts in racial composition (more racial minorities move in, more permits), and population density (more suburban, more permits) (Costanza \& Kilburn, 2004; Thompson \& Stidham, 2010). Although these studies are suggestive, the names of individual permit holders are not generally matters of public record, leaving scholars to analyze aggregated administrative data on permits. Estab- lishing causality is difficult and the ecological fallacy looms large." (\href{zotero://open-pdf/library/items/WA8AC4K7?page=6}{Yamane 2017:6})

"She understands the decision to carry a gun as a response to a very broad pattern of socio-economic decline, the feelings of economic and physical insecu- rity it produces, and related concerns about crime and police ineffectiveness. Carlson sees gun carrying for men as being strongly connected to their cultural conceptions of masculinity." (\href{zotero://open-pdf/library/items/WA8AC4K7?page=6}{Yamane 2017:6})

"Stroud's female respondents, by contrast, emphasized a need to protect themselves (rather than their families) and felt empowered to do so because guns are ``equalizers'' that compensate for strength differences between women and their male victimizers" (\href{zotero://open-pdf/library/items/WA8AC4K7?page=6}{Yamane 2017:6})

"What both male and female CHL holders have in common, Stroud concludes, is their embrace of a cultural ideal of personal responsibility." (\href{zotero://open-pdf/library/items/WA8AC4K7?page=6}{Yamane 2017:6})

"Significantly, both argue that white male gun carriers in the suburbs are motivated by emasculation (due to economic marginalization for Carlson and physical decline for Stroud), as well as race-based fears of crime." (\href{zotero://open-pdf/library/items/WA8AC4K7?page=6}{Yamane 2017:6})

". But understanding gun culture" (\href{zotero://open-pdf/library/items/WA8AC4K7?page=7}{Yamane 2017:7})

"Gun culture is part of the broader American culture, so obviously reflects some of its dominant themes (Kohn, 2004)." (\href{zotero://open-pdf/library/items/WA8AC4K7?page=7}{Yamane 2017:7})}
}

@book{kohnShootersMythsRealities2004,
  address = {{New York}},
  title = {Shooters: Myths and Realities of {{America}}'s Gun Cultures},
  isbn = {978-0-19-530644-6 978-0-19-515051-3},
  lccn = {HV8059 .K65 2004},
  shorttitle = {Shooters},
  language = {en},
  publisher = {{Oxford University Press}},
  author = {Kohn, Abigail A.},
  year = {2004},
  keywords = {Firearms,Firearms owners,Firearms ownership,Shooting,Social aspects,Subculture,United States},
  file = {/Users/miriamamin/Documents/Zotero/storage/W2GUQ9DQ/Kohn - 2004 - Shooters myths and realities of America's gun cul.pdf},
  annote = {\textbf{Extracted Annotations (10/12/2018, 15:59:12)}

"Gun own\- ership and socialization into gun use are strongly associated with rural areas as opposed to urban ones, and with conservative political values rather than liberal ones." (\href{zotero://open-pdf/library/items/W2GUQ9DQ?page=21}{Kohn 2004:21})

"``What does owning a gun mean to you?'' and ``What does the gun symbolize for you?'' these were the questions that often generated such responses as ``Indepen\- dence'' and ``Freedom.''" (\href{zotero://open-pdf/library/items/W2GUQ9DQ?page=78}{Kohn 2004:78})

\textbf{Extracted Annotations (10/12/2018, 16:10:28)}

"Gun own\- ership and socialization into gun use are strongly associated with rural areas as opposed to urban ones, and with conservative political values rather than liberal ones." (\href{zotero://open-pdf/library/items/W2GUQ9DQ?page=21}{Kohn 2004:21})

"``What does owning a gun mean to you?'' and ``What does the gun symbolize for you?'' these were the questions that often generated such responses as ``Indepen\- dence'' and ``Freedom.''" (\href{zotero://open-pdf/library/items/W2GUQ9DQ?page=78}{Kohn 2004:78})

"One of the ways that toughness is expressed by male shooters is in their de\- scription of gun ownership as simply a convention of American masculin\- ity: they see familiarity with guns as the status quo for American manhood." (\href{zotero://open-pdf/library/items/W2GUQ9DQ?page=125}{Kohn 2004:125})

"However, for some shooters this assertion has a distinctly patriotic under\- tone." (\href{zotero://open-pdf/library/items/W2GUQ9DQ?page=125}{Kohn 2004:125})}
}

@misc{ParklandTimelineGuncontrol,
  title = {After {{Parkland}}: {{A}} Timeline of Gun-Control Activism, Legislation},
  shorttitle = {After {{Parkland}}},
  abstract = {The teen survivors of the mass shooting at a Florida high school have launched a movement for gun control and school safety. Here's what's happened so far.},
  language = {en},
  journal = {UPI},
  howpublished = {https://www.upi.com/After-Parkland-A-timeline-of-gun-control-activism-legislation/1001522267185/},
  file = {/Users/miriamamin/Documents/Zotero/storage/I3LJ28V8/1001522267185.html}
}

@article{GunPoliticsParkland,
  title = {Gun Politics after {{Parkland}} - \#{{NeverAgain}}},
  file = {/Users/miriamamin/Documents/Zotero/storage/KS8MLZ8U/gun-politics-after-parkland.html}
}

@article{sherfinskiDavidHoggLeads2018,
  title = {David {{Hogg}} Leads New Wave of Anti-Gun Activists against {{NRA}} after {{Parkland}}},
  abstract = {NRA members say they have survived the backlash from Columbine, Sandy Hook, Las Vegas and other shooting massacres, and as they prepare to gather for their annual convention this week they are confident that the Florida shooting will be no different. Gun control activists are determined to prove them wrong.},
  language = {en-US},
  journal = {The Washington Times},
  author = {Sherfinski, David},
  month = may,
  year = {2018},
  file = {/Users/miriamamin/Documents/Zotero/storage/SP8NNDSL/david-hogg-leads-new-wave-anti-gun-activists-again.html}
}

@article{sylwesterTwitterLanguageUse2015,
  title = {Twitter {{Language Use Reflects Psychological Differences}} between {{Democrats}} and {{Republicans}}},
  volume = {10},
  issn = {1932-6203},
  abstract = {Previous research has shown that political leanings correlate with various psychological factors. While surveys and experiments provide a rich source of information for political psychology, data from social networks can offer more naturalistic and robust material for analysis. This research investigates psychological differences between individuals of different political orientations on a social networking platform, Twitter. Based on previous findings, we hypothesized that the language used by liberals emphasizes their perception of uniqueness, contains more swear words, more anxiety-related words and more feeling-related words than conservatives' language. Conversely, we predicted that the language of conservatives emphasizes group membership and contains more references to achievement and religion than liberals' language. We analysed Twitter timelines of 5,373 followers of three Twitter accounts of the American Democratic and 5,386 followers of three accounts of the Republican parties' Congressional Organizations. The results support most of the predictions and previous findings, confirming that Twitter behaviour offers valid insights to offline behaviour.},
  language = {en},
  number = {9},
  journal = {PLOS ONE},
  doi = {10.1371/journal.pone.0137422},
  author = {Sylwester, Karolina and Purver, Matthew},
  month = sep,
  year = {2015},
  keywords = {Twitter,Anxiety,Emotions,Language,Psycholinguistics,Psychology,Religion,Semantics},
  pages = {e0137422},
  file = {/Users/miriamamin/Documents/Zotero/storage/DFXPDRCZ/Sylwester_Purver_2015_Twitter Language Use Reflects Psychological Differences between Democrats and.pdf;/Users/miriamamin/Documents/Zotero/storage/6LI2JJVZ/article.html}
}

@article{binstedComputationalRulesGenerating2009,
  title = {Computational Rules for Generating Punning Riddles},
  volume = {10},
  issn = {1613-3722},
  number = {1},
  journal = {Humor - International Journal of Humor Research},
  doi = {10.1515/humr.1997.10.1.25},
  author = {BINSTED, KIM and RITCHIE, GRAEME},
  year = {2009},
  pages = {25--76},
  file = {/Users/miriamamin/Documents/Zotero/storage/H7J77KVL/BINSTED_RITCHIE_2009_Computational rules for generating punning riddles.pdf}
}

@article{raskinScriptTheoryRevis1991,
  title = {Script Theory Revis(It)Ed: Joke Similarity and Joke Representation Model},
  volume = {4},
  issn = {1613-3722},
  shorttitle = {Script Theory Revis(It)Ed},
  number = {3-4},
  journal = {Humor - International Journal of Humor Research},
  doi = {10.1515/humr.1991.4.3-4.293},
  author = {Raskin, Victor and Attardo, Salvatore},
  year = {1991},
  pages = {293--348},
  file = {/Users/miriamamin/Documents/Zotero/storage/YZVAEZWQ/ATTARDO_RASKIN_2009_Script theory revis(it)ed.pdf}
}

@article{binstedModelStoryPuns2001,
  title = {Towards a {{Model}} of {{Story Puns}}},
  volume = {14},
  abstract = {There is a class of joke which consists of an anecdote, which is sometimes quite long and often has no inherently humorous content, followed by a punchline which is a distorted form of some well-known phrase, proverb or quotation. Usually the punchline purports to summarise or draw a moral from the preceding story. This genre has some unusual aspects, from the viewpoint of conventional claims about the attributes of jokes. These jokes also have certain structural or formal regularities which suggest that it might be possible to define a computational model of their production. We outline how this might be done, by decomposing the construction of such story puns into a sequence of stages; some of these are clearly manageable, others are less straightforward. We also make some observations about where such an endeavour would fit within the broader field of humour research.},
  journal = {Humor},
  author = {Binsted, Kim and Ritchie, Graeme},
  year = {2001},
  pages = {275--292},
  file = {/Users/miriamamin/Documents/Zotero/storage/ZPAESXBN/Binsted_Ritchie_2001_Towards a Model of Story Puns.pdf;/Users/miriamamin/Documents/Zotero/storage/H78YQA2Y/summary.html}
}

@article{stockPasswordSwordfishVerbal2006,
  title = {Password Swordfish: {{Verbal}} Humor in the Interface},
  volume = {16},
  issn = {1613-3722},
  shorttitle = {Password Swordfish},
  number = {3},
  journal = {Humor - International Journal of Humor Research},
  doi = {10.1515/humr.2003.015},
  author = {Stock, Oliviero},
  year = {2006},
  pages = {281--295},
  file = {/Users/miriamamin/Documents/Zotero/storage/Q5DYY5Z2/2006_Password swordfish.pdf}
}

@article{oringParsingJokeGeneral2011,
  title = {Parsing the Joke: {{The General Theory}} of {{Verbal Humor}} and Appropriate Incongruity},
  volume = {24},
  issn = {1613-3722},
  shorttitle = {Parsing the Joke},
  abstract = {For more than a quarter of a century, the Semantic Script Theory of Humor (SSTH) and its successor, the General Theory of Verbal Humor (GTVH), have been employed to characterize the factors that define a joke, to describe the components of jokes and their interrelationships, and to provide a model for the analysis of joke texts. But these theories have never been adequately scrutinized. When approached from the perspective of appropriate incongruity some serious questions can be raised about these theories and their usefulness in joke analysis.},
  number = {2},
  journal = {Humor - International Journal of Humor Research},
  doi = {10.1515/HUMR.2011.013},
  author = {Oring, Elliott},
  year = {2011},
  keywords = {humor theory},
  pages = {203--222},
  file = {/Users/miriamamin/Documents/Zotero/storage/5J2MIMN3/Oring_2011_Parsing the joke.pdf}
}

@misc{FirstAprilWorkshop,
  title = {The {{First}} of {{April Workshop}} on {{Computational Humour}} - {{Program}}},
  howpublished = {http://haha.fbk.eu/program.html},
  file = {/Users/miriamamin/Documents/Zotero/storage/R6H8KGSM/program.html}
}

@article{ritchieLinguisticAnalysisJokes2005,
  title = {The {{Linguistic Analysis}} of {{Jokes}}: {{Graeme Ritchie}}, {{Routledge}}, {{London}}, 2004, 244 Pp., Hardback, \textsterling{}60},
  volume = {37},
  issn = {0378-2166},
  shorttitle = {The {{Linguistic Analysis}} of {{Jokes}}},
  number = {6},
  journal = {Journal of Pragmatics},
  doi = {10.1016/j.pragma.2004.10.001},
  author = {Ritchie, Graeme},
  month = jun,
  year = {2005},
  pages = {961-965},
  file = {/Users/miriamamin/Documents/Zotero/storage/I9TRTE86/Chłopicki_2005_The Linguistic Analysis of Jokes.pdf;/Users/miriamamin/Documents/Zotero/storage/5ZG5UD35/S0378216604002127.html}
}

@book{paulosMathematicsHumorStudy1982,
  address = {{Chicago}},
  edition = {Paperback ed},
  title = {Mathematics and {{Humor}}: {{A Study Of The Logic Of Humor}}},
  isbn = {978-0-226-65025-8},
  language = {en},
  publisher = {{Univ. of Chicago Press}},
  author = {Paulos, John Allen},
  year = {1982},
  file = {/Users/miriamamin/Documents/Zotero/storage/WRXVEIGQ/Paulos - 1982 - Mathematics and humor.pdf},
  note = {OCLC: 256209077}
}

@article{kaoComputationalModelLinguistic2016,
  title = {A {{Computational Model}} of {{Linguistic Humor}} in {{Puns}}},
  volume = {40},
  copyright = {MODEL},
  issn = {0364-0213},
  abstract = {Humor plays an essential role in human interactions. Precisely what makes something funny, however, remains elusive. While research on natural language understanding has made significant advancements in recent years, there has been little direct integration of humor research with computational models of language understanding. In this paper, we propose two information-theoretic measures\textemdash{}ambiguity and distinctiveness\textemdash{}derived from a simple model of sentence processing. We test these measures on a set of puns and regular sentences and show that they correlate significantly with human judgments of funniness. Moreover, within a set of puns, the distinctiveness measure distinguishes exceptionally funny puns from mediocre ones. Our work is the first, to our knowledge, to integrate a computational model of general language understanding and humor theory to quantitatively predict humor at a fine-grained level. We present it as an example of a framework for applying models of language processing to understand higher level linguistic and cognitive phenomena.},
  number = {5},
  journal = {Cognitive Science},
  doi = {10.1111/cogs.12269},
  author = {Kao, Justine T. and Levy, Roger and Goodman, Noah D.},
  month = jul,
  year = {2016},
  pages = {1270-1285},
  file = {/Users/miriamamin/Documents/Zotero/storage/2U6TZ8S3/Kao et al_2016_A Computational Model of Linguistic Humor in Puns.pdf},
  pmid = {26235596},
  pmcid = {PMC5042108}
}

@inproceedings{sutskeverGeneratingTextRecurrent2011,
  address = {{USA}},
  series = {{{ICML}}'11},
  title = {Generating {{Text}} with {{Recurrent Neural Networks}}},
  isbn = {978-1-4503-0619-5},
  abstract = {Recurrent Neural Networks (RNNs) are very powerful sequence models that do not enjoy widespread use because it is extremely difficult to train them properly. Fortunately, recent advances in Hessian-free optimization have been able to overcome the difficulties associated with training RNNs, making it possible to apply them successfully to challenging sequence problems. In this paper we demonstrate the power of RNNs trained with the new Hessian-Free optimizer (HF) by applying them to character-level language modeling tasks. The standard RNN architecture, while effective, is not ideally suited for such tasks, so we introduce a new RNN variant that uses multiplicative (or "gated") connections which allow the current input character to determine the transition matrix from one hidden state vector to the next. After training the multiplicative RNN with the HF optimizer for five days on 8 high-end Graphics Processing Units, we were able to surpass the performance of the best previous single method for character-level language modeling \textendash{} a hierarchical non-parametric sequence model. To our knowledge this represents the largest recurrent neural network application to date.},
  booktitle = {Proceedings of the 28th {{International Conference}} on {{International Conference}} on {{Machine Learning}}},
  publisher = {{Omnipress}},
  author = {Sutskever, Ilya and Martens, James and Hinton, Geoffrey},
  year = {2011},
  pages = {1017--1024},
  file = {/Users/miriamamin/Documents/Zotero/storage/R6CGYAHP/Sutskever et al_2011_Generating Text with Recurrent Neural Networks.pdf}
}

@article{kaoFunnyThingIncongruity2013,
  title = {The {{Funny Thing About Incongruity}}: {{A Computational Model}} of {{Humor}} in {{Puns}}},
  volume = {35},
  issn = {1069-7977},
  shorttitle = {The {{Funny Thing About Incongruity}}},
  abstract = {Author(s): Kao, Justine T.; Levy, Roger; Goodman, Noah D.},
  language = {en},
  number = {35},
  journal = {Proceedings of the Annual Meeting of the Cognitive Science Society},
  author = {Kao, Justine T. and Levy, Roger and Goodman, Noah D.},
  year = {2013},
  file = {/Users/miriamamin/Documents/Zotero/storage/4VG7V9F3/Kao et al_2013_The Funny Thing About Incongruity.pdf;/Users/miriamamin/Documents/Zotero/storage/KY2T8GU6/04j190sw.pdf}
}

@misc{wahnComputationalHumor2019,
  title = {Computational Humor},
  author = {Wahn, Kristan},
  month = jan,
  year = {2019}
}

@article{yueBeNotBe2016,
  title = {To {{Be}} or {{Not To Be Humorous}}? {{Cross Cultural Perspectives}} on {{Humor}}},
  volume = {7},
  issn = {1664-1078},
  shorttitle = {To {{Be}} or {{Not To Be Humorous}}?},
  abstract = {Humor seems to manifest differently in Western and Eastern cultures, although little is known about how culture shapes humor perceptions. The authors suggest that Westerners regard humor as a common and positive disposition; the Chinese regard humor as a special disposition particular to humorists, with controversial aspects. In Study 1, Hong Kong participants primed with Western culture evaluate humor more positively than they do when primed with Chinese culture. In Study 2a, Canadians evaluate humor as being more important in comparison with Chinese participants. In Study 2b, Canadians expect ordinary people to possess humor, while Chinese expect specialized comedians to be humorous. The implications and limitations are discussed.},
  journal = {Frontiers in Psychology},
  doi = {10.3389/fpsyg.2016.01495},
  author = {Yue, Xiaodong and Jiang, Feng and Lu, Su and Hiranandani, Neelam},
  month = oct,
  year = {2016},
  file = {/Users/miriamamin/Documents/Zotero/storage/CQJVN33X/Yue et al. - 2016 - To Be or Not To Be Humorous Cross Cultural Perspe.pdf},
  pmid = {27757091},
  pmcid = {PMC5048456}
}

@article{toncarUseHumourTelevision2001,
  title = {The Use of Humour in Television Advertising: Revisiting the {{US}}-{{UK}} Comparison},
  volume = {20},
  issn = {0265-0487},
  shorttitle = {The Use of Humour in Television Advertising},
  abstract = {This paper replicates a portion of the Weinberger and Spotts (1989) study, which compared the use of humour in television advertising in the US and the UK. A careful comparison of the results of the two studies suggests that the overall use of humour has become more similar in the two countries. Unlike the Weinberger and Spotts study, the current study found no difference in the proportion of ads that use humour, and little difference in the situational use of humour. However, differences in the way that humour is used and in the types of humour used remain. These differences are discussed in the context of Hofstede's (1991) cultural dimensions.},
  number = {4},
  journal = {International Journal of Advertising},
  doi = {10.1080/02650487.2001.11104909},
  author = {Toncar, Mark F.},
  month = jan,
  year = {2001},
  pages = {521-539},
  file = {/Users/miriamamin/Documents/Zotero/storage/Y98SCV4X/Toncar - 2001 - The use of humour in television advertising revis.pdf;/Users/miriamamin/Documents/Zotero/storage/PMX45IE9/02650487.2001.html}
}

@incollection{goldsteinCrossCulturalResearch1977,
  title = {Cross {{Cultural Research}}: {{Humour Here}} and {{There}}},
  isbn = {978-0-08-021376-7},
  shorttitle = {Cross {{Cultural Research}}},
  booktitle = {It's a {{Funny Thing}}, {{Humour}}},
  publisher = {{Pergamon}},
  doi = {10.1016/B978-0-08-021376-7.50036-X},
  author = {Goldstein, Jeffrey H.},
  editor = {Chapman, ANTONY J. and Foot, HUGH C.},
  month = jan,
  year = {1977},
  pages = {167-174},
  file = {/Users/miriamamin/Documents/Zotero/storage/ML3YDADF/Goldstein - 1977 - Cross Cultural Research Humour Here and There.pdf;/Users/miriamamin/Documents/Zotero/storage/3NHF7C7V/B978008021376750036X.html}
}

@article{yueBeNotBe2016a,
  title = {To {{Be}} or {{Not To Be Humorous}}? {{Cross Cultural Perspectives}} on {{Humor}}},
  volume = {7},
  issn = {1664-1078},
  shorttitle = {To {{Be}} or {{Not To Be Humorous}}?},
  abstract = {Humor seems to manifest differently in Western and Eastern cultures, although little is known about how culture shapes humor perceptions. The authors suggest that Westerners regard humor as a common and positive disposition; the Chinese regard humor as a special disposition particular to humorists, with controversial aspects. In Study 1, Hong Kong participants primed with Western culture evaluate humor more positively than they do when primed with Chinese culture. In Study 2a, Canadians evaluate humor as being more important in comparison with Chinese participants. In Study 2b, Canadians expect ordinary people to possess humor, while Chinese expect specialized comedians to be humorous. The implications and limitations are discussed.},
  journal = {Frontiers in Psychology},
  doi = {10.3389/fpsyg.2016.01495},
  author = {Yue, Xiaodong and Jiang, Feng and Lu, Su and Hiranandani, Neelam},
  month = oct,
  year = {2016},
  file = {/Users/miriamamin/Documents/Zotero/storage/X7VE5LTZ/Yue et al_2016_To Be or Not To Be Humorous.pdf},
  pmid = {27757091},
  pmcid = {PMC5048456}
}

@article{kuipersFollowJokeHumour2016,
  title = {Follow the {{Joke}}: {{Humour}} and {{Ethnography}}},
  volume = {28},
  issn = {0921-5158},
  shorttitle = {Follow the {{Joke}}},
  number = {2},
  journal = {Etnofoor},
  author = {Kuipers, Giselinde},
  year = {2016},
  pages = {125-129},
  file = {/Users/miriamamin/Documents/Zotero/storage/FIRF8X3C/Kuipers - 2016 - Follow the Joke Humour and Ethnography.pdf}
}

@article{khanUpperSaxonChemnitz2013,
  title = {Upper {{Saxon}} ({{Chemnitz}} Dialect)},
  volume = {43},
  issn = {0025-1003, 1475-3502},
  abstract = {Upper Saxon (Obers{\"a}chsisch /ɵ{$\Elzlmrk$}poˁ{$\Elzverts$}s{$\varepsilon$}ks{$\Elzesh$}/) refers to a group of dialects spoken by over two million people in the Free State of Saxony in eastern Germany. It is considered one of the eastern branches of Central German (Wiesinger 1983, Lewis 2009), with major phonological, morphological, and lexical differences from Standard German and other regional dialects.},
  language = {en},
  number = {2},
  journal = {Journal of the International Phonetic Association},
  doi = {10.1017/S0025100313000145},
  author = {Khan, Sameer ud Dowla and Weise, Constanze},
  month = aug,
  year = {2013},
  pages = {231-241},
  file = {/Users/miriamamin/Documents/Zotero/storage/YF9XWYYF/Khan and Weise - 2013 - Upper Saxon (Chemnitz dialect).pdf;/Users/miriamamin/Documents/Zotero/storage/5DMGGU9Q/EA409B459554051EB0D96CBCF4F78D4A.html}
}

@article{binstedModelStoryPuns2001a,
  title = {Towards a {{Model}} of {{Story Puns}}},
  volume = {14},
  abstract = {There is a class of joke which consists of an anecdote, which is sometimes quite long and often has no inherently humorous content, followed by a punchline which is a distorted form of some well-known phrase, proverb or quotation. Usually the punchline purports to summarise or draw a moral from the preceding story. This genre has some unusual aspects, from the viewpoint of conventional claims about the attributes of jokes. These jokes also have certain structural or formal regularities which suggest that it might be possible to define a computational model of their production. We outline how this might be done, by decomposing the construction of such story puns into a sequence of stages; some of these are clearly manageable, others are less straightforward. We also make some observations about where such an endeavour would fit within the broader field of humour research.},
  journal = {Humor},
  author = {Binsted, Kim and Ritchie, Graeme},
  year = {2001},
  pages = {275--292},
  file = {/Users/miriamamin/Documents/Zotero/storage/KP3TXGIK/Binsted and Ritchie - 2001 - Towards a Model of Story Puns.pdf;/Users/miriamamin/Documents/Zotero/storage/JAVFLV4Q/summary.html}
}

@article{chenComparisonHumorStyles2007,
  title = {A Comparison of Humor Styles, Coping Humor, and Mental Health between {{Chinese}} and {{Canadian}} University Students},
  volume = {20},
  issn = {1613-3722},
  abstract = {This research compares the structure and correlates of the Humor Styles Questionnaire (HSQ) and Coping Humor Scale (CHS) in the Chinese context with those of Canadian samples. Chinese translations of the HSQ, CHS, and Symptom Checklist 90 (SCL-90) were administered to 354 Chinese university students (M = 23.4 years of age, SD = 3.6). As in the original Canadian samples, four humor factors were found in the HSQ: Affliative, Self-enhancing, Aggressive, and Self-defeating humor, and one factor was found in the CHS. The HSQ and CHS scale reliabilities in the Chinese sample were generally acceptable. Chinese participants, as compared to Canadian norms, reported significantly lower scores on the HSQ subscales and CHS, particularly on Aggressive humor. No significant gender differences were found on the four HSQ subscales in the Chinese sample, whereas Canadian males reported more use of Aggressive and Self-defeating humor than did females. Although no gender difference was found on Coping humor in the Canadian samples, Chinese males had significantly higher scores on this scale than did females. In both the Chinese and Canadian samples, younger participants reported more use of Affliative and Aggressive humor than did older ones. Affliative, Self-enhancing, and Coping humor were negatively correlated, while Aggressive and Selfdefeating humor were positively correlated with the subscales and General Symptomatic Index of the SCL-90. Regression results indicated that mental health is more strongly related to Self-enhancing, Self-defeating, and Coping humor than Affliative and Aggressive humor. Overall, the findings support the theoretical structure and usefulness of the HSQ and CHS in the Chinese context.},
  number = {3},
  journal = {Humor \textendash{} International Journal of Humor Research},
  doi = {10.1515/HUMOR.2007.011},
  author = {Chen, Guo-Hai and Martin, Rod A},
  year = {2007},
  keywords = {Canadian,Chinese,Comparison,Coping Humor,Humor Styles,Mental Health},
  pages = {215--234},
  file = {/Users/miriamamin/Documents/Zotero/storage/IG38ZTXT/Chen and Martin - 2007 - A comparison of humor styles, coping humor, and me.pdf}
}

@book{kuipersGoodHumorBad2015,
  address = {{Berlin, Boston}},
  title = {Good {{Humor}}, {{Bad Taste}}, {{A Sociology}} of the {{Joke}}},
  isbn = {978-1-61451-720-7},
  abstract = {This is an updated edition of Good Humor, Bad Taste: A Sociology of the Joke, published in 2006. Using a combination of interview materials, survey data, and historical materials, it explores the relationship between humor and gender, age, social class, and national differences in the Netherlands and the United States. This edition includes new developments and research findings in the field of humor studies.},
  language = {ENGL},
  publisher = {{De Gruyter Mouton}},
  doi = {10.1515/9781501510441},
  author = {Kuipers, Giselinde},
  year = {2015},
  file = {/Users/miriamamin/Documents/Zotero/storage/EM69DMTJ/[Giselinde_Kuipers]_Good_Humor,_Bad_Taste(z-lib.org).epub}
}

@article{ruchCrossnationalComparisonHumor2009,
  title = {Cross-National Comparison of Humor Categories: {{France}} and {{Germany}}},
  volume = {4},
  issn = {1613-3722},
  shorttitle = {Cross-National Comparison of Humor Categories},
  number = {3-4},
  journal = {Humor - International Journal of Humor Research},
  doi = {10.1515/humr.1991.4.3-4.391},
  author = {RUCH, WILLIBALD and OTT, CHRISTIANE and ACCOCE, JEANNINE and BARIAUD, FRAN{\c C}OISE},
  year = {2009},
  pages = {391--414},
  file = {/Users/miriamamin/Documents/Zotero/storage/L5YRV5GU/ruch1991.pdf;/Users/miriamamin/Documents/Zotero/storage/PJ9S92UM/RUCH et al. - 2009 - Cross-national comparison of humor categories Fra.pdf}
}

@article{guidiArePunMechanisms2012,
  title = {Are Pun Mechanisms Universal? {{A}} Comparative Analysis across Language Families},
  volume = {25},
  issn = {1613-3722},
  shorttitle = {Are Pun Mechanisms Universal?},
  abstract = {The purpose of this paper is to provide a new definition of pun, in order to describe it in a cross-linguistic perspective and to point out that puns, as verbal humorous phenomena which exploit ordinary phonetic processes, are universal. The definition is tested through a comparison among puns in 15 languages belonging to different families. I show that puns always imply the manipulation of a string through mechanisms involving all the elements of the phonetic chain. Such manipulation is realized in all possible string and syllable domains, tendentially within the threshold of five elements. Taking into account the progressive improvements in linguistic models of puns, the present study also provides a synthetic overview of the literature on puns and related phenomena. Results include some phonetic elements not considered in previous studies; a cross-linguistic formulation of phonetic distance between target and pun is also proposed.},
  number = {3},
  journal = {Humor},
  doi = {10.1515/humor-2012-0017},
  author = {Guidi, Annarita},
  year = {2012},
  keywords = {auto-segmental phonology,cross-linguistics,phonetic distance,pun,speech play},
  pages = {339--366},
  file = {/Users/miriamamin/Documents/Zotero/storage/NFCBBU79/Guidi - 2012 - Are pun mechanisms universal A comparative analys.pdf}
}

@book{ItFunnyThing1977,
  title = {It's a {{Funny Thing}}, {{Humour}}},
  isbn = {978-0-08-021376-7},
  language = {en},
  publisher = {{Elsevier}},
  doi = {10.1016/C2013-0-02848-4},
  year = {1977}
}

@article{krugerNatureHumorHuman1996,
  title = {The Nature of Humor in Human Nature: {{Cross}}-Cultural Commonalities},
  volume = {9},
  issn = {0951-5070},
  shorttitle = {The Nature of Humor in Human Nature},
  abstract = {It is contended that humor is a universal, pan-cultural phenomenon. Humor theory is examined on superiority, psychoanalytic, and incongruity-resolution dimensions. Cross-cultural humor commonalities are derived from the literature; and genetic, biological, and social dynamics of humor are explored. Intercultural differences in the content domain of humor are noted. It is concluded that humor is an appropriate intervention for ethnically diverse clients, when used sensitively in the counselling process.},
  number = {3},
  journal = {Counselling Psychology Quarterly},
  doi = {10.1080/09515079608258705},
  author = {Kruger, Arnold},
  month = sep,
  year = {1996},
  pages = {235-241},
  file = {/Users/miriamamin/Documents/Zotero/storage/UBKSW94E/09515079608258705.html}
}

@article{nevoSingaporeanHumorCrossCultural2001,
  title = {Singaporean {{Humor}}: {{A Cross}}-{{Cultural}}, {{Cross}}-{{Gender Comparison}}},
  volume = {128},
  issn = {0022-1309},
  shorttitle = {Singaporean {{Humor}}},
  abstract = {One hundred and nineteen undergraduate students (62 men and 57 women) of Chinese origin at the National University of Singapore answered three self-report humor questionnaires. Students were also asked to supply their favorite joke (M. A. Johnson, 1991) and a description of a person with an outstanding sense of humor (M. Crawford \& D. Gressley, 1991). These responses were compared with results obtained using the same questionnaires and methods in previous studies in Israel and the United States. In general, means and reliabilities of results obtained from the Singapore study replicated those found in other countries. However, Singaporean participants reported significantly less use of humor for coping. Content analysis of jokes supplied by Singaporean students reflected conservative values: Compared with American students, they reported a significantly greater number of jokes with aggressive content and relatively fewer jokes with sexual content. Contrary to expectations, very few gender differences were found. Regardless of gender, a majority of participants nominated a man as an example of a person with an outstanding sense of humor.},
  number = {2},
  journal = {The Journal of General Psychology},
  doi = {10.1080/00221300109598904},
  author = {Nevo, Ofra and Nevo, Baruch and Yin, Janie Leong Siew},
  month = apr,
  year = {2001},
  keywords = {cultural differences in humor,gender differences in humor,Singaporean humor},
  pages = {143-156},
  file = {/Users/miriamamin/Documents/Zotero/storage/DNCZQIDU/00221300109598904.html},
  pmid = {11506045}
}

@misc{ItFunnyThing,
  title = {It's a {{Funny Thing}}, {{Humour}}. {{Proceedings}} of {{The International Conference}} on {{Humour}} and {{Laughter}} 1976 | {{Antony J}}. {{Chapman}} and {{Hugh C}}. {{Foot}} ({{Eds}}.) | Download},
  howpublished = {https://b-ok.cc/book/2317051/279a1b},
  file = {/Users/miriamamin/Documents/Zotero/storage/32RH4S7K/279a1b.html}
}

@misc{ItFunnyThinga,
  title = {It's a {{Funny Thing}}, {{Humour}} - 1st {{Edition}}},
  howpublished = {https://www.elsevier.com/books/its-a-funny-thing-humour/chapman/978-0-08-021376-7},
  file = {/Users/miriamamin/Documents/Zotero/storage/IJLGUL97/It's a Funny Thing, Humour - 1st Edition.pdf;/Users/miriamamin/Documents/Zotero/storage/72WQJ8Z4/978-0-08-021376-7.html}
}

@misc{PDFHumorCultural,
  title = {({{PDF}}) {{Humor}} and Cultural Values in Print Advertising: {{A}} Cross-Cultural Study},
  shorttitle = {({{PDF}}) {{Humor}} and Cultural Values in Print Advertising},
  abstract = {PDF | Purpose \textendash{} The present study aims to discuss the role of Hofstede's cultural dimensions, uncertainty avoidance and individualism/collectivism, on the use of various humor types in print advertising, across culturally diverse countries. Design/methodology/approach \textendash{} A sample of...},
  language = {en},
  journal = {ResearchGate},
  howpublished = {https://www.researchgate.net/publication/235280542\_Humor\_and\_cultural\_values\_in\_print\_advertising\_A\_cross-cultural\_study},
  doi = {http://dx.doi.org/10.1108/02651331111107107},
  file = {/Users/miriamamin/Documents/Zotero/storage/IIEE6DRI/235280542_Humor_and_cultural_values_in_print_advertising_A_cross-cultural_study.html}
}

@incollection{shultzCrossCulturalStudyStructure1977,
  title = {A {{Cross}}-{{Cultural Study}} of the {{Structure}} of {{Humour}}},
  isbn = {978-0-08-021376-7},
  booktitle = {It's a {{Funny Thing}}, {{Humour}}},
  publisher = {{Pergamon}},
  doi = {10.1016/B978-0-08-021376-7.50037-1},
  author = {Shultz, Thomas R.},
  editor = {Chapman, ANTONY J. and Foot, HUGH C.},
  month = jan,
  year = {1977},
  pages = {175-179},
  file = {/Users/miriamamin/Documents/Zotero/storage/8S67YEXV/Shultz - 1977 - A Cross-Cultural Study of the Structure of Humour.pdf;/Users/miriamamin/Documents/Zotero/storage/QT2WSCT7/B9780080213767500371.html}
}

@incollection{hansenMagnificentLiarsExaggeration1977,
  title = {Magnificent {{Liars}}: {{Exaggeration}} in {{American Humour}}},
  isbn = {978-0-08-021376-7},
  shorttitle = {Magnificent {{Liars}}},
  booktitle = {It's a {{Funny Thing}}, {{Humour}}},
  publisher = {{Pergamon}},
  doi = {10.1016/B978-0-08-021376-7.50038-3},
  author = {Hansen, Arlen J.},
  editor = {Chapman, ANTONY J. and Foot, HUGH C.},
  month = jan,
  year = {1977},
  pages = {181-183},
  file = {/Users/miriamamin/Documents/Zotero/storage/I5WUF2WB/B9780080213767500383.html}
}

@incollection{castellSocialOccasionsJoking1977,
  title = {Social {{Occasions}} for {{Joking}}: {{A Cross}}-{{Cultural Study}}},
  isbn = {978-0-08-021376-7},
  shorttitle = {Social {{Occasions}} for {{Joking}}},
  booktitle = {It's a {{Funny Thing}}, {{Humour}}},
  publisher = {{Pergamon}},
  doi = {10.1016/B978-0-08-021376-7.50040-1},
  author = {Castell, Patricia J. and Goldstein, Jeffrey H.},
  editor = {Chapman, ANTONY J. and Foot, HUGH C.},
  month = jan,
  year = {1977},
  pages = {193-197},
  file = {/Users/miriamamin/Documents/Zotero/storage/A6T2SL54/B9780080213767500401.html}
}

@incollection{goldsteinCrossCulturalResearch1977a,
  title = {Cross {{Cultural Research}}: {{Humour Here}} and {{There}}},
  isbn = {978-0-08-021376-7},
  shorttitle = {Cross {{Cultural Research}}},
  booktitle = {It's a {{Funny Thing}}, {{Humour}}},
  publisher = {{Pergamon}},
  doi = {10.1016/B978-0-08-021376-7.50036-X},
  author = {Goldstein, Jeffrey H.},
  editor = {Chapman, ANTONY J. and Foot, HUGH C.},
  month = jan,
  year = {1977},
  pages = {167-174},
  file = {/Users/miriamamin/Documents/Zotero/storage/NRHQ5Z2P/Goldstein - 1977 - Cross Cultural Research Humour Here and There.pdf;/Users/miriamamin/Documents/Zotero/storage/YI8GN2Y9/B978008021376750036X.html}
}

@article{bakro-nagyUralicLanguages2012,
  title = {The {{Uralic Languages}}},
  volume = {90},
  copyright = {free},
  language = {eng},
  number = {3},
  journal = {Revue belge de Philologie et d'Histoire},
  doi = {10.3406/rbph.2012.8272},
  author = {{Bakr{\'o}-Nagy}, Marianne},
  year = {2012},
  pages = {1001-1027},
  file = {/Users/miriamamin/Documents/Zotero/storage/7ALLXQY4/Bakró-Nagy_2012_The Uralic Languages.pdf;/Users/miriamamin/Documents/Zotero/storage/DLRMWEFW/rbph_0035-0818_2012_num_90_3_8272.html}
}

@article{abondoloUralicLanguages2017,
  title = {Uralic {{Languages}}},
  abstract = {All but three of the thirty-nine Uralic languages are endangered, most of them seriously so; of the family's ten main branches, only two have members considered safe (Finnish and Estonian of the Fennic branch, plus Hungarian). This chapter surveys a selection of phonological, morphological, and syntactic features of the Uralic languages; the emphasis is on presenting aspects that are usually ignored, oversimplified, or misrepresented. Among the topics broached are vowel harmony; consonant gradation, which in the Uralic context is of four distinct kinds, three of them quite old; less-than-agglutinative (i.e. fairly fusional features of several languages); problems of phonological reconstruction; the inflection of personal pronouns; person marking on nouns and Subject, Agent, and Object marking on verbs; and kinds of relative, complement, and support clauses.},
  language = {en},
  doi = {10.1093/oxfordhb/9780199935345.013.6},
  author = {Abondolo, Daniel},
  month = may,
  year = {2017},
  file = {/Users/miriamamin/Documents/Zotero/storage/BCXS954S/oxfordhb-9780199935345-e-6.html}
}

@incollection{krachtSemanticsLocativesUralic2005,
  title = {The {{Semantics}} of {{Locatives}} in the {{Uralic Languages}}},
  language = {eng},
  booktitle = {Les Languages Ouraliennes Aujourd'hui. {{Approche}} Linguistics et Cognitive},
  author = {Kracht, Marcus},
  year = {2005},
  file = {/Users/miriamamin/Documents/Zotero/storage/T4FWHMIN/2594539.html}
}

@book{nikolaevaGrammarTundraNenets2014,
  address = {{Berlin, Boston}},
  title = {A {{Grammar}} of {{Tundra Nenets}}},
  isbn = {978-3-11-037329-5},
  abstract = {The book is the first substantial description of Tundra Nenets, a highly endangered Uralic language spoken in Western Siberia and the north of European Russia, destined for the international linguistic community. Its purpose is to provide a thorough documentation of all of the major grammatical phenomena in the language. The grammar particularly emphasizes the description of syntax, because this has traditionally been a very neglected area of Nenets studies. Many syntactic aspects have not received a systematic treatment in the existing literature or have not been addressed at all. Since the existing works are not easily available, incomplete, or idiosyncratically presented, Tundra Nenets syntax has played little or no role in the considerations of modern linguists, whether more descriptively or theoretically inclined. The book is largely descriptive: it is not intended to address theoretical questions per se and the description is not meant to be formulated within a particular framework. However, it identifies and discusses issues which are of broad typological and theoretical interest. The description is richly exemplified. Most of the cited examples are the result of fieldwork conducted by the in various locations. They are sentences produced by native speakers either spontaneously or elicited in response to questions posed in Russian. Other examples are excerpts from original texts.},
  language = {ENGL},
  publisher = {{De Gruyter Mouton}},
  doi = {10.1515/9783110320640},
  author = {Nikolaeva, Irina},
  year = {2014}
}

@book{ereltEstonianLanguage2003,
  title = {Estonian {{Language}}},
  isbn = {978-9985-50-359-1},
  language = {en},
  publisher = {{Estonian Academy Publishers}},
  author = {Erelt, Mati},
  year = {2003},
  googlebooks = {9sAYAQAAIAAJ}
}

@book{keneseiHungarian1998,
  edition = {1. publ.},
  series = {Descriptive Grammars},
  title = {Hungarian},
  isbn = {978-0-415-02139-5},
  publisher = {{Routledge}},
  author = {Kenesei, Istv{\'a}n},
  year = {1998},
  file = {/Users/miriamamin/Documents/Zotero/storage/PST8KRH8/0-280094248.html}
}

@misc{GrammatikTscheremissischenMari,
  title = {Grammatik Des {{Tscheremissischen}} ({{Mari}})},
  howpublished = {https://buske.de/grammatik-des-tscheremissischen-mari-9021.html},
  file = {/Users/miriamamin/Documents/Zotero/storage/LWGMY4PL/grammatik-des-tscheremissischen-mari-9021.html}
}

@book{alhoniemiGrammatikTscheremissischenMari1993,
  title = {Grammatik Des {{Tscheremissischen}} ({{Mari}})},
  publisher = {{Buske}},
  author = {Alhoniemi, Alho},
  year = {1993},
  file = {/Users/miriamamin/Documents/Zotero/storage/HL6M2IKP/grammatik-des-tscheremissischen-mari-9021.html}
}

@article{norrisNominalStructureLanguage2018,
  title = {Nominal Structure in a Language without Articles: {{The}} Case of {{Estonian}}},
  volume = {3},
  copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are \textcopyright, \textregistered{} or \texttrademark{} of their respective owners. No challenge to any owner's rights is intended or should be inferred.},
  issn = {2397-1835},
  shorttitle = {Nominal Structure in a Language without Articles},
  abstract = {It is standardly assumed that nominals in the languages of the world are syntactically complex in the typical case, being made up of not just NP, but one or more functional projections, e.g., DP (Abney 1987). Recently, this assumption has been questioned, especially for languages without articles (Bo{\v s}kovi{\'c} 2005, et seq.). The alternative proposal holds that nominals in Serbo-Croatian (and more strongly, languages without articles in general) lack the DP projection, and that this difference has a variety of syntactic consequences. In this paper, I investigate the nominal extended projection of another language without articles, Estonian (Finno-Ugric). On the basis of a number of facts about Estonian's system of adnominal genitives, I conclude that nominals in Estonian should not be given the same analysis as those in Serbo-Croatian. I propose instead that Estonian's nominals are DPs. I then propose that indefinite pronouns and wh-determiners instantiate the category D0 in the language, arguing that DP does more cross-linguistically than host articles. I conclude that nominal structure in languages without articles can be just as complex as nominal structure in languages with articles.},
  language = {en},
  number = {1},
  journal = {Glossa: a journal of general linguistics},
  doi = {10.5334/gjgl.384},
  author = {Norris, Mark},
  month = mar,
  year = {2018},
  keywords = {demonstratives,Estonian,genitives,indefinite pronouns,NP/DP structure},
  pages = {41},
  file = {/Users/miriamamin/Documents/Zotero/storage/93PA9526/Norris_2018_Nominal structure in a language without articles.pdf;/Users/miriamamin/Documents/Zotero/storage/PV6T8AKI/gjgl.html}
}

@inproceedings{venugopalanTranslatingVideosNatural2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1412.4729},
  address = {{Denver, Colorado, USA}},
  title = {Translating {{Videos}} to {{Natural Language Using Deep Recurrent Neural Networks}}},
  abstract = {Solving the visual symbol grounding problem has long been a goal of artificial intelligence. The field appears to be advancing closer to this goal with recent breakthroughs in deep learning for natural language grounding in static images. In this paper, we propose to translate videos directly to sentences using a unified deep neural network with both convolutional and recurrent structure. Described video datasets are scarce, and most existing methods have been applied to toy domains with a small vocabulary of possible words. By transferring knowledge from 1.2M+ images with category labels and 100,000+ images with captions, our method is able to create sentence descriptions of open-domain videos with large vocabularies. We compare our approach with recent work using language generation metrics, subject, verb, and object prediction accuracy, and a human evaluation.},
  booktitle = {{{NAACL}} 2015},
  author = {Venugopalan, Subhashini and Xu, Huijuan and Donahue, Jeff and Rohrbach, Marcus and Mooney, Raymond and Saenko, Kate},
  month = dec,
  year = {2014},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/miriamamin/Documents/Zotero/storage/IHQDYZPC/Venugopalan et al_2014_Translating Videos to Natural Language Using Deep Recurrent Neural Networks.pdf;/Users/miriamamin/Documents/Zotero/storage/DUSJRQ96/1412.html},
  annote = {Comment: NAACL-HLT 2015 camera ready}
}

@inproceedings{chuSongPIMusically2017,
  title = {Song {{From PI}}: {{A Musically Plausible Network}} for {{Pop Music Generation}}},
  shorttitle = {Song {{From PI}}},
  abstract = {We present a novel framework for generating pop music. Our model is a hierarchical Recurrent Neural Network, where the layers and the structure of the hierarchy encode our prior knowledge about how pop music is composed. In particular, the bottom layers generate the melody, while the higher levels produce the drums and chords. We conduct several human studies that show strong preference of our generated music over that produced by the recent method by Google. We additionally show two applications of our framework: neural dancing and karaoke, as well as neural story singing.},
  booktitle = {{{ICLR Workshop}}},
  author = {Chu, Hang and Urtasun, Raquel and Fidler, Sanja},
  year = {2017},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Sound},
  file = {/Users/miriamamin/Documents/Zotero/storage/9MXM74UI/Chu et al_2016_Song From PI.pdf;/Users/miriamamin/Documents/Zotero/storage/F8KRHTVX/1611.html},
  annote = {Comment: under review at ICLR 2017}
}

@misc{JokeRetrievalRecognizing,
  title = {Joke Retrieval: Recognizing the Same Joke Told Differently - {{Semantic Scholar}}},
  shorttitle = {Joke Retrieval},
  abstract = {In a corpus of jokes, a human might judge two documents to be the \&quot;same joke\&quot; even if characters, locations, and other details are varied. A given joke could be retold with an entirely different vocabulary while still maintaining its identity. Since most retrieval systems consider documents to be related only when their word content is similar, we propose joke retrieval as a domain where standard language models may fail. Other meaning-centric domains include logic puzzles, proverbs and recipes; in such domains, new techniques may be required to enable us to search effectively. For jokes, a necessary component of any retrieval system will be the ability to identify the \&quot;same joke,\&quot; so we examine this task in both ranking and classification settings. We exploit the structure of jokes to develop two domain-specific alternatives to the \&quot;bag of words\&quot; document model. In one, only the punch lines, or final sentences, are compared; in the second, certain categories of words (e.g., professions and countries) are tagged and treated as interchangeable. Each technique works well for certain jokes. By combining the methods using machine learning, we create a hybrid that achieves higher performance than any individual approach.},
  language = {en},
  howpublished = {/paper/Joke-retrieval\%3A-recognizing-the-same-joke-told-Friedland-Allan/1ad0167cdb76f2654c79f9a61f06c66ac6c8ecea},
  file = {/Users/miriamamin/Documents/Zotero/storage/QA9BV6GS/1ad0167cdb76f2654c79f9a61f06c66ac6c8ecea.html}
}

@misc{EvaluatingHumorousFeatures,
  title = {Evaluating {{Humorous Features}}: {{Towards}} a {{Humour Taxonomy}} - {{Semantic Scholar}}},
  shorttitle = {Evaluating {{Humorous Features}}},
  abstract = {The importance of the analysis of processes related to cognitive phenomena through Natural Language Processing techniques is acquiring a greater relevance every day. Opinion Mining, Sentiment Analysis or Automatic Humour Recognition are a sample about how this kind of research works grows. In this paper we focus on the study of how the features that define a corpus of humorous data (one-liners) may be used for obtaining a set of parameters that allow us to build a primitive taxonomy of humour. We analyse, through several experiments, a set of well-known features defined in the literature, besides a set of new ones, in order to determine the importance of each one for a humour taxonomy. An evaluation of all the features was performed by means of an automatic classification task over a collection of humorous blogs. The results obtained show that some of the features may represent elemental information for the purpose of creating a humour taxonomy.},
  language = {en},
  howpublished = {/paper/Evaluating-Humorous-Features\%3A-Towards-a-Humour-Reyes-Rosso/7a298e3dd06c09cec4f3bd5101a80c2fb28d3284},
  file = {/Users/miriamamin/Documents/Zotero/storage/3264KRVN/Reyes et al. - Towards a Humour Taxonomy.pdf;/Users/miriamamin/Documents/Zotero/storage/4L8APKBC/7a298e3dd06c09cec4f3bd5101a80c2fb28d3284.html}
}

@article{reyesHumorBlogosphereFirst2011,
  title = {Humor in the {{Blogosphere}}: {{First Clues}} for a {{Verbal Humor Taxonomy}}},
  volume = {18},
  shorttitle = {Humor in the {{Blogosphere}}},
  number = {4},
  journal = {Journal of Intelligent Systems},
  doi = {10.1515/JISYS.2009.18.4.311},
  author = {Reyes, A. and Rosso, P. and Buscaldi, D.},
  year = {2011},
  pages = {311--332},
  file = {/Users/miriamamin/Documents/Zotero/storage/7T4CYW6R/Reyes et al_2011_Humor in the Blogosphere.pdf}
}

@article{reyesHumourTaxonomy,
  title = {Towards a {{Humour Taxonomy}}},
  abstract = {The importance of the analysis of processes related to cognitive phenomena through Natural Language Processing techniques is acquiring a greater relevance every day. Opinion Mining, Sentiment Analysis or Automatic Humour Recognition are a sample about how this kind of research works grows. In this paper we focus on the study of how the features that define a corpus of humorous data (one-liners) may be used for obtaining a set of parameters that allow us to build a primitive taxonomy of humour. We analyse, through several experiments, a set of well-known features defined in the literature, besides a set of new ones, in order to determine the importance of each one for a humour taxonomy. An evaluation of all the features was performed by means of an automatic classification task over a collection of humorous blogs. The results obtained show that some of the features may represent elemental information for the purpose of creating a humour taxonomy.},
  language = {en},
  author = {Reyes, Antonio and Rosso, Paolo and Buscaldi, Davide},
  pages = {18}
}

@book{attardoHumorousTextsSemantic2010,
  title = {Humorous {{Texts}}: {{A Semantic}} and {{Pragmatic Analysis}}},
  isbn = {978-3-11-088796-9},
  shorttitle = {Humorous {{Texts}}},
  abstract = {This book presents a theory of long humorous texts based on a revision and an upgrade of the General Theory of Verbal Humour (GTVH), a decade after its first proposal. The theory is informed by current research in psycholinguistics and cognitive science. It is predicated on the fact that there are humorous mechanisms in long texts that have no counterpart in jokes. The book includes a number of case studies, among them Oscar Wilde's Lord Arthur Savile's Crime and Allais' story Han Rybeck. A ground-breaking discussion of the quantitative distribution of humor in select texts is presented.},
  language = {en},
  publisher = {{Walter de Gruyter}},
  author = {Attardo, Salvatore},
  month = dec,
  year = {2010},
  keywords = {Language Arts \& Disciplines / Linguistics / General,Language Arts \& Disciplines / Linguistics / Historical \& Comparative},
  file = {/Users/miriamamin/Documents/Zotero/storage/PGKYBJ8L/Attardo_2010_Humorous Texts.pdf},
  googlebooks = {fKxEfmfJvIwC},
  annote = {\textbf{Extracted Annotations (04/06/2019, 14:27:34)}

"incorporated by Artificial Intelligence (AI) (Charniak 1972, Schank 1975, Schank and Abelson 1977)" (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=16}{Attardo 2010:16})

"A script is an organized 2 complex of information about some entity" (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=16}{Attardo 2010:16})

"in the broad- est sense: an object (real or imaginary), an event, an action, a quality, etc." (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=16}{Attardo 2010:16})

"t is a cognitive structure internalized by the speaker which provides the speaker with in- formation on how a given entity is structured, what are its parts and components, or how an activity is done, a relationship organized, and so on" (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=16}{Attardo 2010:16})

"contains information which is prototypical of the entity being described, such as well-established routines and common ways to do things and to go about activities." (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=17}{Attardo 2010:17})

"At the simplest level, a script is equivalent to the lexical meaning of a word." (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=17}{Attardo 2010:17})

"A plan is (...) the repository for general information that will connect events that cannot be connected by use of the available script or by stan- dard causal chain expansion (Schank and Abelson 1977: 70)" (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=18}{Attardo 2010:18})

"Raskin introduces the idea of ``macroscript,'' clusters of scripts organized chrono- logically, and ``complex script'' i.e., scripts made of other scripts, but not organized chronologically." (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=18}{Attardo 2010:18})

"A metascript is an abstract, minimally specified script, which may be realized in different ways" (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=18}{Attardo 2010:18})

"HELPING OUT or DOING A FAVOR are metascripts, that can be instatiated by WASHING THE DISHES , for example." (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=18}{Attardo 2010:18})

"every script is a graph with lexical nodes and semantic links between the nodes. In fact, all the scripts of the language make up a single con- tinuous graph, and the lexical entry of a word is a domain within this graph (1985: 81)" (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=21}{Attardo 2010:21})

"As we have seen, formally, a script is a subgraph of a very broad graph linking all the semantic nodes (= scripts) of a culture." (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=21}{Attardo 2010:21})

"Scripts, lexical and non- lexical, are connected by links. The links can be of different semantic natures (syn- onymy, hyponymy, antonymy, etc.), and correspondingly labelled. Significantly, links may have different lengths, which reflect the fact that certain nodes may be less accessible than other nodes. 10" (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=22}{Attardo 2010:22})

"The set of scripts in the lexicon, their links, plus all the non-lexical scripts, their links, and all the links between the two sets of scripts form the ``semantic network'' which contains all of the information a speaker has about his/her culture." (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=22}{Attardo 2010:22})

"introduced into AI by Quillian (1967)." (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=22}{Attardo 2010:22})

"semantic theory must consist of the following (abstract) objects: the set of all scripts available to the speakers (along with their labeled links) and a set of combinatorial rules." (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=23}{Attardo 2010:23})

"Their function is to combine all the possible meanings of the scripts and discard those combinations that do not yield coherent readings." (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=23}{Attardo 2010:23})

"If there is (at least) one coherent, well-formed interpretation, that interpretation of the text is licensed as ``the meaning'' of the text," (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=23}{Attardo 2010:23})

"McDonough (1997) calculated that roughly 60 presuppositions or inferences were activated in a simple 4 lines joke." (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=29}{Attardo 2010:29})

"stretches of text that are compatible with more than one ``reading,'' i.e., would fit more than one script; for instance, imagine a text describing someone getting up, fixing breakfast, leaving the house, etc. These events could fit the script for GO TO WORK but also for GO ON A FISHING TRIP \textemdash{}hence the stretch of text would be compatible with both scripts." (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=31}{Attardo 2010:31})

"The second condition of the SSTH calls for the two scripts that overlap in the text to be ``opposed'' in a technical sense, to which we presently turn." (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=32}{Attardo 2010:32})

"concept of local antonymy" (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=32}{Attardo 2010:32})

"two linguistic entities whose meanings are opposites only within a par- ticular discourse and solely for the purposes of that discourse." (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=32}{Attardo 2010:32})

"script oppositions fall into three classes: actual vs. non-actual, normal vs. abnormal, and possible vs. impossible." (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=34}{Attardo 2010:34})

"The three classes are all instances of a basic opposition between real and unreal situations in the texts. These three classes of oppositions are then instantiated in more concrete opposi- tions." (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=34}{Attardo 2010:34})

"Thus, if a text is compatible fully or in part with two scripts, and the two scripts happen to be opposed to each other, then, and only then, will the text be classified as ``funny'' by the SSTH." (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=34}{Attardo 2010:34})

"first step" (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=35}{Attardo 2010:35})

"listing of all the senses of the words in the text" (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=35}{Attardo 2010:35})

"activation of the combinatorial rules" (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=35}{Attardo 2010:35})

"triggering of inferences" (\href{zotero://open-pdf/library/items/PGKYBJ8L?page=35}{Attardo 2010:35})}
}

@book{attardoLinguisticTheoriesHumor1994,
  title = {Linguistic {{Theories}} of {{Humor}}},
  copyright = {X},
  isbn = {978-3-11-014255-6},
  abstract = {So this English professor comes into class and starts talking about the textual organization of jokes, the taxonomy of puns, the relations between the linguistic form and the content of humorous texts, and other past and current topics in language-based research into humor. At the end he stuffs all},
  language = {en},
  publisher = {{Walter de Gruyter}},
  author = {Attardo, Salvatore},
  year = {1994},
  keywords = {Language Arts \& Disciplines / Linguistics / General},
  file = {/Users/miriamamin/Documents/Zotero/storage/ZSW4DQ67/Attardo_1994_Linguistic Theories of Humor.pdf},
  googlebooks = {FEWC4\_3MrO0C}
}

@misc{scottChatBotThat2017,
  title = {Chat Bot That Creates Jokes Based on User Input. {{Contribute}} to Kenanscott/Bad-Joke-Bot Development by Creating an Account on {{GitHub}}},
  copyright = {MIT},
  author = {Scott, Kenan},
  month = jul,
  year = {2017}
}

@misc{noahInspiredRequestResearch2018,
  title = {Inspired by a Request for Research from {{OpenAI}}, {{I}} Developed a Word-Level Recurrent Neural Network and Generated Jokes Using {{Beam Search}}: Noahshpak/{{Word}}-{{Level}}-{{RNN}}-{{Joke}}-{{Generator}}},
  copyright = {MIT},
  shorttitle = {Inspired by a Request for Research from {{OpenAI}}, {{I}} Developed a Word-Level Recurrent Neural Network and Generated Jokes Using {{Beam Search}}},
  author = {Noah},
  month = jan,
  year = {2018}
}

@misc{renContributeHerenericRnnjokegeneration2019,
  title = {Contribute to Hereneric/Rnn-Joke-Generation Development by Creating an Account on {{GitHub}}},
  copyright = {MIT},
  author = {Ren, He},
  month = jan,
  year = {2019}
}

@misc{ribasLSTMJokeGenerator2018,
  title = {{{LSTM}} Joke Generator. {{Contribute}} to Rahenri/Lstm-Joke-Generator Development by Creating an Account on {{GitHub}}},
  author = {Ribas, Raphael H.},
  month = jul,
  year = {2018}
}

@misc{BeginnerGuideLSTMs,
  title = {A {{Beginner}}'s {{Guide}} to {{LSTMs}} and {{Recurrent Neural Networks}}},
  abstract = {LSTMs are a powerful kind of RNN used for processing sequential data such as sound, time series (sensor) data or written natural language.},
  journal = {Skymind},
  howpublished = {http://skymind.ai/wiki/lstm}
}

@misc{abhinavmoudgilHumorGenerationRecurrent,
  title = {Humor {{Generation}} with {{Recurrent Neural Networks}} \textemdash{} {{Abhinav Moudgil Blog}}},
  howpublished = {https://amoudgl.github.io/blog/funnybot/},
  author = {{Abhinav Moudgil}},
  file = {/Users/miriamamin/Documents/Zotero/storage/PX7SX7XP/funnybot.html}
}

@article{moudgilPythonScriptsBuilding2017,
  title = {Python Scripts for Building '{{Short Jokes}}' Dataset, Featured on {{Kaggle}}},
  copyright = {GPL-2.0},
  shorttitle = {Python Scripts for Building '{{Short Jokes}}' Dataset, Featured on {{Kaggle}}},
  journal = {GitHub repository},
  author = {Moudgil, Abhinav},
  year = {2017}
}

@misc{jiriQuestionAnswerJokes2017,
  title = {Question-{{Answer Jokes}}},
  abstract = {Jokes of the question-answer form from Reddit's r/jokes},
  language = {en},
  howpublished = {https://kaggle.com/jiriroz/qa-jokes},
  author = {Jiri, Roznovjak},
  year = {2017},
  file = {/Users/miriamamin/Documents/Zotero/storage/B8UNBBAK/qa-jokes.html}
}

@article{binstedMachineHumourImplemented1996,
  title = {Machine Humour: {{An}} Implemented Model of Puns},
  shorttitle = {Machine Humour},
  abstract = {This thesis describes a formal model of a subtype of humour, and the implementation 
of that model in a program that generates jokes of that subtype. 
Although there is a great deal of literature on humour in general, very little formal 
work has been done on puns, and none has been implemented. All current linguistic 
theories of humour are over-general and not falsifiable. Our model, which is specific, 
formal, implemented and evaluated, makes a significant contribution to the field. 
Punning riddles are our chosen subtype of verbal humour, for several reasons. They are 
very common, they exhibit certain regular structures and mechanisms, and they have 
been studied previously by linguists. Our model is based on our extensive analysis of 
large numbers of punning riddles, taken from children's joke books. 
The implementation of the model, JAPE (Joke Analysis and Production Engine), generates punning riddles, from a humour independent lexicon. Pun generation requires 
much less world knowledge than pun comprehension, making it feasible for implementation. 
To support our claim that all of JAPE's output is punning riddles, we conducted an 
evaluatory experiment. We took JAPE texts, human-generated texts, nonsense non-jokes 
and sensible non-jokes, and asked joke experts to evaluate them. For joke experts, we 
used 8-11 year old children, since psychological research suggests that this age group 
enjoys, and can recognize, punning riddles better than other age groups. The results 
showed that JAPE's output texts are, in fact, recognizably jokes. 
The evaluation showed that our model adequately describes a significant subtype of 
verbal humour. We believe that this model can now be expanded to cover puns in 
general, as well as other types of linguistic humour.},
  language = {en},
  author = {Binsted, Kim},
  month = jul,
  year = {1996},
  file = {/Users/miriamamin/Documents/Zotero/storage/DMCTVS2B/Binsted_1996_Machine humour.pdf;/Users/miriamamin/Documents/Zotero/storage/54736PVA/586.html}
}

@book{venourComputationalGenerationClass2000,
  title = {The {{Computational Generation}} of a {{Class}} of {{Pun}}},
  language = {en},
  publisher = {{National Library of Canada = Biblioth{\`e}que nationale du Canada}},
  author = {Venour, C},
  year = {2000},
  googlebooks = {NNuZAQAACAAJ}
}

@misc{graemeritchieJokingComputer,
  title = {The {{Joking Computer}}},
  howpublished = {http://joking.abdn.ac.uk/home.shtml},
  author = {{Graeme Ritchie} and {Judith Masthoff}},
  file = {/Users/miriamamin/Documents/Zotero/storage/QUUT7WAB/home.html}
}

@misc{huControlledGenerationText2017,
  title = {Toward {{Controlled Generation}} of {{Text}}},
  abstract = {Generic generation and manipulation of text is challenging and has limited success compared to recent deep generative modeling in visual domain. This paper aims at generating plausible text sentences, whose attributes are controlled by learning disentangled latent representations with designated semantics. We propose a new neural generative model which combines variational auto-encoders (VAEs) and holistic attribute discriminators for effective imposition of semantic structures. The model can alternatively be seen as enhancing VAEs with the wake-sleep algorithm for leveraging fake samples as extra training data. With differentiable approximation to discrete text samples, explicit constraints on independent attribute controls, and efficient collaborative learning of generator and discriminators, our model learns interpretable representations from even only word annotations, and produces sentences with desired attributes of sentiment and tenses. Quantitative experiments using trained classifiers as evaluators validate the accuracy of short sentence and attribute generation.},
  language = {en},
  journal = {undefined},
  howpublished = {/paper/Toward-Controlled-Generation-of-Text-Hu-Yang/2a215755d7548ffc82079ce734c4ac60b62f6f56},
  author = {Hu, Zhiting and Yang, Zichao and Liang, Xiaodan and Salakhutdinov, Ruslan R. and Xing, Eric P.},
  year = {2017},
  file = {/Users/miriamamin/Documents/Zotero/storage/BZJL57YR/Hu et al_2017_Toward Controlled Generation of Text.pdf;/Users/miriamamin/Documents/Zotero/storage/BKASIZ22/2a215755d7548ffc82079ce734c4ac60b62f6f56.html}
}

@article{roeckeleinElsevierDictionaryPsychological2006,
  title = {Elsevier's {{Dictionary}} of {{Psychological Theories}}},
  isbn = {978-0-08-046064-2},
  abstract = {In attempting to understand and explain various behaviour, events, and phenomena in their field, psychologists have developed and enunciated an enormous number of `best guesses' or theories concerning the phenomenon in question. Such theories involve speculations and statements that range on a potency continuum from `strong' to `weak'. The term theory, itself, has been conceived of in various ways in the psychological literature. In the present dictionary, the strategy of lumping together all the various traditional descriptive labels regarding psychologists `best guesses' under the single descriptive term theory has been adopted. The descriptive labels of principle, law, theory, model, paradigm, effect, hypothesis and doctrine are attached to many of the entries, and all such descriptive labels are subsumed under the umbrella term theory.The title of this dictionary emphasizes the term theory (implying both strong and weak best guesses) and is a way of indication, overall, the contents of this comprehensive dictionary in a parsimonious and felicitous fashion.The dictionary will contain approximately 2,000 terms covering the origination, development, and evolution of various psychological concepts, as well as the historical definition, analysis, and criticisms of psychological concepts. Terms and definitions are in English.*Contains over 2,000 terms covering the origination, development and evolution of various psychological concepts*Covers a wide span of theories, from auditory, cognitive tactile and visual to humor and imagery*An essential resource for psychologists needing a single-source quick reference},
  language = {en},
  journal = {Theories of Humor},
  publisher = {{Elsevier}},
  editor = {Roeckelein, J. E.},
  month = jan,
  year = {2006},
  keywords = {Psychology / General,Psychology / Movements / General},
  pages = {284 ff},
  file = {/Users/miriamamin/Documents/Zotero/storage/4QMEUNWF/Roeckelein_2006_Elsevier's Dictionary of Psychological Theories.pdf},
  googlebooks = {1Yn6NZgxvssC}
}

@article{aaronsmutsHumor2019,
  title = {Humor},
  journal = {Internet Encyclopedia of Philosophy},
  author = {{Aaron Smuts}},
  year = {2019},
  file = {/Users/miriamamin/Documents/Zotero/storage/JMW28QF2/humor.html},
  note = {https://www.iep.utm.edu/}
}

@article{attardoHumorLanguage2017,
  title = {Humor in {{Language}}},
  abstract = {Interest in the linguistics of humor is widespread and dates since classical times. Several theoretical models have been proposed to describe and explain the function of humor in language. The most widely adopted one, the semantic-script theory of humor, was presented by Victor Raskin, in 1985. Its expansion, to incorporate a broader gamut of information, is known as the General Theory of Verbal Humor. Other approaches are emerging, especially in cognitive and corpus linguistics. Within applied linguistics, the predominant approach is analysis of conversation and discourse, with a focus on the disparate functions of humor in conversation. Speakers may use humor pro-socially, to build in-group solidarity, or anti-socially, to exclude and denigrate the targets of the humor. Most of the research has focused on how humor is co-constructed and used among friends, and how speakers support it. Increasingly, corpus-supported research is beginning to reshape the field, introducing quantitative concerns, as well as multimodal data and analyses. Overall, the linguistics of humor is a dynamic and rapidly changing field.},
  language = {en},
  journal = {Oxford Research Encyclopedia of Linguistics},
  doi = {10.1093/acrefore/9780199384655.013.342},
  author = {Attardo, Salvatore},
  month = mar,
  year = {2017},
  file = {/Users/miriamamin/Documents/Zotero/storage/6Y75CW8K/acrefore-9780199384655-e-342.html}
}

@article{attardoHumorLanguage2017a,
  title = {Humor in {{Language}}},
  volume = {1},
  language = {en},
  journal = {Oxford Research Encyclopedia of Linguistics},
  publisher = {{Oxford University Press}},
  doi = {10.1093/acrefore/9780199384655.013.342},
  author = {Attardo, Salvatore},
  month = mar,
  year = {2017},
  file = {/Users/miriamamin/Documents/Zotero/storage/LFTLUX26/Attardo - 2017 - Humor in Language.pdf}
}

@misc{InternationalSocietyHumor,
  title = {International {{Society}} for {{Humor Studies}} ({{ISHS}}) {{Home Page}}},
  howpublished = {http://www.humorstudies.org/},
  file = {/Users/miriamamin/Documents/Zotero/storage/NIPVD99T/www.humorstudies.org.html}
}

@book{daviesJokesTheirRelations2012,
  address = {{Berlin, Boston}},
  edition = {Reprint 2012},
  title = {Jokes and Their {{Relations}} to {{Society}}},
  isbn = {978-3-11-016104-5},
  language = {ENGL},
  publisher = {{De Gruyter Mouton}},
  doi = {10.1515/9783110806144},
  author = {Davies, Christie},
  year = {2012},
  file = {/Users/miriamamin/Documents/Zotero/storage/32MHXWK7/Davies_2012_Jokes and their Relations to Society.pdf}
}

@incollection{monroHumor1967,
  title = {Humor},
  booktitle = {The {{Encyclopedia}} of {{Philosophy}}},
  publisher = {{Macmillan}},
  author = {Monro, D. H.},
  editor = {Edwards, Paul},
  year = {1967},
  pages = {4--90}
}

@article{craigHumor2013,
  title = {Humor},
  isbn = {978-0-203-15790-9},
  abstract = {The most complete and up-to-date philosophy reference for a new generation, with entries ranging from Abstract Objects to Wisdom, Socrates to Jean-Paul Sartre,},
  language = {en},
  journal = {Concise Routledge Encyclopedia of Philosophy},
  publisher = {{Routledge}},
  author = {Craig, Edward},
  month = jan,
  year = {2013},
  file = {/Users/miriamamin/Documents/Zotero/storage/IHT32KYT/9780203157909.html}
}

@book{mcgheeHumorItsOrigin1979,
  address = {{San Francisco}},
  title = {Humor, {{Its Origin}} and {{Development}}},
  isbn = {978-0-7167-1095-0},
  language = {en},
  publisher = {{W. H. Freeman}},
  author = {McGhee, Paul E.},
  year = {1979},
  googlebooks = {8GZsQgAACAAJ}
}

@misc{josephPythonProjectInspired2018,
  title = {A {{Python}} Project Inspired by the Research of {{Chlo{\'e} Kiddon}} and {{Yuriy Brun}}.  {{Part}} of the {{Funniest Computer Ever Open Source}} Initiative: Tansaku/Twss},
  shorttitle = {A {{Python}} Project Inspired by the Research of {{Chlo{\'e} Kiddon}} and {{Yuriy Brun}}.  {{Part}} of the {{Funniest Computer Ever Open Source}} Initiative},
  author = {Joseph, Sam},
  month = oct,
  year = {2018}
}

@inproceedings{sjoberghMeasureFunninessApplied2009,
  title = {A {{Measure}} of {{Funniness}}, {{Applied}} to {{Finding Funny Things}} in {{WordNet}}},
  copyright = {X},
  abstract = {We generate two new types of jokes based on ambiguity and spelling similarity
in multi-word expressions in WordNet. Since many similar jokes can be generated for each multi-word expression, we also use a measure of the funniness of words to select which of the possible joke candidates is likely to be the funniest. Evaluation shows that the funniness measure does on average find funnier candidates than the baseline, which in turn outperforms selecting the least funny candidate. The funniness measure thus ranks
candidates according to how funny they are. The differences between the methods are quite small though, so the ranking is less than perfect. Comparing the generated jokes to human made jokes shows that the system is not as funny as professional human made humor, but the better jokes achieve human level.},
  booktitle = {Proceedings of the {{Conference}} of the {{Pacific Association}} for {{Computational Linguistics}} 2009},
  publisher = {{Pacific Association for Computational Linguistics}},
  author = {Sj{\"o}bergh, Jonas and Araki, Kenji},
  month = jan,
  year = {2009},
  pages = {pp 236-241},
  file = {/Users/miriamamin/Documents/Zotero/storage/Z2DWJ27P/Sjöbergh_Araki_2009_A Measure of Funniness, Applied to Finding Funny Things in WordNet.pdf},
  annote = {\textbf{Extracted Annotations (14/06/2019, 23:38:48)}

"In our joke corpus there are jokes on the form ``If you saw a heat wave, would you wave back?''" (\href{zotero://open-pdf/library/items/Z2DWJ27P?page=2}{Sj{\"o}bergh and Araki 2009:237})

"The output is currently based on a simple tem- plate, by starting with ``I saw'' and then adding the compound noun. This is then followed by the ex- ample sentence, with the original subject replaced with the appropriate pronoun (also replacing any genitive pronouns etc. in the rest of the example sentence)." (\href{zotero://open-pdf/library/items/Z2DWJ27P?page=3}{Sj{\"o}bergh and Araki 2009:238})

"Another type of joke in our joke corpus is jokes like ``Acupuncture: a jab well done'' or ``Shotgun wedding: a case of wife or death'', i.e. making use of the facts that ``life or death'' is fixed expression and that ``wife'' and ``life'' are very similar. To generate simple versions of jokes like these, we make use of WordNet compound nouns again. The compound must contain a word that is also included in WordNet by itself and that by chang- ing one letter in the word becomes another word in WordNet." (\href{zotero://open-pdf/library/items/Z2DWJ27P?page=3}{Sj{\"o}bergh and Araki 2009:238})

"Both methods detailed above can in general gen- erate very many jokes for each compound noun." (\href{zotero://open-pdf/library/items/Z2DWJ27P?page=4}{Sj{\"o}bergh and Araki 2009:239})

"To filter out which possible joke for a compound noun is the funniest and then discard the other possibilities we use the previously mentioned funniness measure." (\href{zotero://open-pdf/library/items/Z2DWJ27P?page=4}{Sj{\"o}bergh and Araki 2009:239})

"The evaluators also rated a few other jokes on a scale from 1 (boring) to 5 (funny)." (\href{zotero://open-pdf/library/items/Z2DWJ27P?page=4}{Sj{\"o}bergh and Araki 2009:239})

Sj{\"o}bergh and Araki are creating two types of jokes by automatically selecting possibly ambiguous compound nouns from WordNet. For the first type of joke, they select compound words, where both parts also occur as single entries. The first must occur as a noun, the second one as a verb. For this verb the WordNet, example sentences and definitions are extracted. These text chunks are completed by the starting phrase `I saw' to create jokes like: `I saw a fish stick. She (the fish) stuck her thumb in the crack.'. For the second type of joke, compounds are selected when they contain a word that is included in WordNet itself. Additionally, by changing one letter that word must become another word in WordNet. All words that have the original compound in their WordNet definition are extracted and combines to jokes such: `Ares: (Greek mythology) Greek god of car' (from the compound `god of war'). To automatically only select the funniest output, the authors implement a measure of funniness and only output jokes above a certain threshold. The measure is calculated by the relation of the frequency of the selected compound between a joke corpus and a non-humorous corpus. Unfortunately, apart from the examples given above, the authors do not share the generated jokes in their publication.}
}

@inproceedings{sjoberghEvaluationHumorGeneration2010,
  address = {{Leicester, UK}},
  title = {Evaluation of a {{Humor Generation System}} by {{Real World Application}} with 500,000 to {{Win}}},
  copyright = {X},
  abstract = {We describe the evaluation of a system for automatic
humor generation in Japanese. First we used the traditional ``having jokes rated by evaluators'' method, with a result of 3.3 on a scale from 1 (boring) to 5 (funny). To complement this evaluation and to see if 3.3 is ``good enough'' we entered a system generated performance in a competition with a \textyen{}500,000 prize. We also generated responses to arbitrary requests from the audience at a live event. While we did not win the 500,000 yen we did reach the final, and both the performance and the real time generation were well received. Sentiment analysis of blogs covering the event also showed that our system compared
well to the other teams. That the system could compete successfully against human made contributions indicates that the score of 3.3 is ``good enough'' for real world applications of the system.},
  booktitle = {Proceedings of the {{Linguistic And Cognitive Approaches To Dialog Agents Symposium}}},
  author = {Sj{\"o}bergh, Jonas and Araki, Kenji},
  month = jan,
  year = {2010},
  pages = {pp. 59-64},
  file = {/Users/miriamamin/Documents/Zotero/storage/8KY3S5FZ/Sjöbergh_Araki_2010_Evaluation of a Humor Generation System by Real World Application with 500,000.pdf},
  annote = {\textbf{Extracted Annotations (14/06/2019, 23:58:56)}

"Humans often use humor but computers are so far bad at this." (\href{zotero://open-pdf/library/items/8KY3S5FZ?page=2}{Sj{\"o}bergh and Araki 2010:2})

"We have a humor generation system that has been evaluated in the traditional way of asking evaluators to rate how funny they thought the system output was [4, 5]. The latest version achieved a score of 3.3 on a scale from 1 to 5. As an earlier version scored 2.8 in a different evaluation, it seems likely that the system has improved, but how good is 3.3?" (\href{zotero://open-pdf/library/items/8KY3S5FZ?page=2}{Sj{\"o}bergh and Araki 2010:2})

"It is of course possible to hire professional comedians to create performances similar to what the system generates and then compare the system to human level per- formance. A quick subjective check of the system output shows that it is quite far from human level performance, though, so spending money on this is currently not that appealing. There are no freely available sources of human made humor that are similar enough to the system output to be useful as comparisons." (\href{zotero://open-pdf/library/items/8KY3S5FZ?page=2}{Sj{\"o}bergh and Araki 2010:2})

"We found an opportunity for this in a competition for silly robots. The competition rules were that the system must have some mechanical parts, have no serious purpose, and must make people laugh." (\href{zotero://open-pdf/library/items/8KY3S5FZ?page=2}{Sj{\"o}bergh and Araki 2010:2})

"m reusing jokes it has heard other people tell." (\href{zotero://open-pdf/library/items/8KY3S5FZ?page=3}{Sj{\"o}bergh and Araki 2010:3})

"To gener- ate a joke a proverb is twisted into a new variant by replacing content words with similar sounding dirty words." (\href{zotero://open-pdf/library/items/8KY3S5FZ?page=3}{Sj{\"o}bergh and Araki 2010:3})

"The jokes are normally presented in patterns like ``Recently my life has felt like proverb'' ``Oh? For me it has been more like dirty proverb''" (\href{zotero://open-pdf/library/items/8KY3S5FZ?page=3}{Sj{\"o}bergh and Araki 2010:3})

"A riddle is formed along the lines of: ``A word is a word, but what kind of word is hint?'', ``What?'', ``Answer: similar sounding dirty word''. Hints are gener- ated by searching a large corpus for phrases like ``a dirty word is hint''. Hints found are then assumed to be reasonable descriptions if they co-occur more strongly with the answer than with the original word." (\href{zotero://open-pdf/library/items/8KY3S5FZ?page=3}{Sj{\"o}bergh and Araki 2010:3})

"Most results that can be taken from this evaluation are of course quite informal. We do however think they give an interesting complemen- tary view and tell us things not possible to learn from more traditional and strict evaluation methods." (\href{zotero://open-pdf/library/items/8KY3S5FZ?page=6}{Sj{\"o}bergh and Araki 2010:6})}
}

@article{westReverseEngineeringSatirePaper2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1901.03253},
  primaryClass = {cs},
  title = {Reverse-{{Engineering Satire}}, or "{{Paper}} on {{Computational Humor Accepted Despite Making Serious Advances}}"},
  copyright = {X},
  abstract = {Humor is an essential human trait. Efforts to understand humor have called out links between humor and the foundations of cognition, as well as the importance of humor in social engagement. As such, it is a promising and important subject of study, with relevance for artificial intelligence and human-computer interaction. Previous computational work on humor has mostly operated at a coarse level of granularity, e.g., predicting whether an entire sentence, paragraph, document, etc., is humorous. As a step toward deep understanding of humor, we seek fine-grained models of attributes that make a given text humorous. Starting from the observation that satirical news headlines tend to resemble serious news headlines, we build and analyze a corpus of satirical headlines paired with nearly identical but serious headlines. The corpus is constructed via Unfun.me, an online game that incentivizes players to make minimal edits to satirical headlines with the goal of making other players believe the results are serious headlines. The edit operations used to successfully remove humor pinpoint the words and concepts that play a key role in making the original, satirical headline funny. Our analysis reveals that the humor tends to reside toward the end of headlines, and primarily in noun phrases, and that most satirical headlines follow a certain logical pattern, which we term false analogy. Overall, this paper deepens our understanding of the syntactic and semantic structure of satirical news headlines and provides insights for building humor-producing systems.},
  journal = {arXiv:1901.03253 [cs]},
  author = {West, Robert and Horvitz, Eric},
  month = jan,
  year = {2019},
  keywords = {Computer Science - Computation and Language,Computer Science - Artificial Intelligence},
  file = {/Users/miriamamin/Documents/Zotero/storage/B4GLSUWA/West_Horvitz_2019_Reverse-Engineering Satire, or Paper on Computational Humor Accepted Despite.pdf;/Users/miriamamin/Documents/Zotero/storage/TF4NI36Z/1901.html},
  annote = {Comment: Proceedings of the 33rd AAAI Conference on Artificial Intelligence, 2019}
}

@inproceedings{burtenshawBriefIntroductionNatural2018,
  address = {{Tilburg, the Netherlands}},
  title = {A {{Brief Introduction}} to {{Natural Language Generation}} within {{Computational Creativity}}},
  booktitle = {Proceedings of the 3rd {{Workshop}} on {{Computational Creativity}} in {{Natural Language Generation}} ({{CC}}-{{NLG}} 2018)},
  publisher = {{Association for Computational Linguistics}},
  author = {Burtenshaw, Ben},
  month = nov,
  year = {2018},
  pages = {2--4},
  file = {/Users/miriamamin/Documents/Zotero/storage/UZRRT9Y7/Burtenshaw_2018_A Brief Introduction to Natural Language Generation within Computational.pdf}
}

@article{gattSurveyStateArt2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1703.09902},
  primaryClass = {cs},
  title = {Survey of the {{State}} of the {{Art}} in {{Natural Language Generation}}: {{Core}} Tasks, Applications and Evaluation},
  copyright = {X},
  shorttitle = {Survey of the {{State}} of the {{Art}} in {{Natural Language Generation}}},
  abstract = {This paper surveys the current state of the art in Natural Language Generation (NLG), defined as the task of generating text or speech from non-linguistic input. A survey of NLG is timely in view of the changes that the field has undergone over the past decade or so, especially in relation to new (usually data-driven) methods, as well as new applications of NLG technology. This survey therefore aims to (a) give an up-to-date synthesis of research on the core tasks in NLG and the architectures adopted in which such tasks are organised; (b) highlight a number of relatively recent research topics that have arisen partly as a result of growing synergies between NLG and other areas of artificial intelligence; (c) draw attention to the challenges in NLG evaluation, relating them to similar challenges faced in other areas of Natural Language Processing, with an emphasis on different evaluation methods and the relationships between them.},
  journal = {arXiv:1703.09902 [cs]},
  author = {Gatt, Albert and Krahmer, Emiel},
  month = mar,
  year = {2017},
  keywords = {Computer Science - Computation and Language,Computer Science - Artificial Intelligence,Computer Science - Neural and Evolutionary Computing,H.5,I.2.7},
  file = {/Users/miriamamin/Documents/Zotero/storage/XUUPLVTK/Gatt_Krahmer_2017_Survey of the State of the Art in Natural Language Generation.pdf;/Users/miriamamin/Documents/Zotero/storage/XFRBE9BL/1703.html},
  annote = {Comment: Published in Journal of AI Research (JAIR), volume 61, pp 75-170. 118 pages, 8 figures, 1 table

in their survey of the state of the art of natural language genration, the authors only cite JAPE and the X-Y-Z generator. ``Presumably, many of the central problems within ai need to be solved first before generation systems will be capable of producing these kinds of advanced jokes.''}
}

@misc{PDFNeuralApproach,
  title = {[{{PDF}}] {{A Neural Approach}} to {{Pun Generation}} - {{Semantic Scholar}}},
  howpublished = {https://www.semanticscholar.org/paper/A-Neural-Approach-to-Pun-Generation-Yu-Tan/591ea6ff771c5cd5591c9d69d76ad64f749b0ab1},
  file = {/Users/miriamamin/Documents/Zotero/storage/ZQWL98QY/591ea6ff771c5cd5591c9d69d76ad64f749b0ab1.html}
}

@inproceedings{yuNeuralApproachPun2018,
  title = {A {{Neural Approach}} to {{Pun Generation}}},
  volume = {Volume 1: Long Papers},
  copyright = {GENER},
  abstract = {Provided with two pseudo-words as inputs to the encoder in the backward generation process (e.g. ``countv01'' as input1 and ``countv08'' as input2), we decode two output sentences in parallel and the two sentences should be the same except for the input pseudo-words. Our joint beam search algorithm selects candidates while decoding for the two inputs according to the joint score distribution on all beams. The decoding process will be finished after all the beams have selected ``''. We improve the pun generation model by adding some associative words to the sentence which could remind people some special sense of the target word.},
  booktitle = {Proceedings of the 56th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Yu, Zhiwei and Tan, Jiwei and Wan, Xiaojun},
  year = {2018},
  keywords = {Algorithm,Language model,Natural language generation,Text corpus},
  pages = {pp 1650--1660},
  file = {/Users/miriamamin/Documents/Zotero/storage/7BJG9XGF/Yu et al_2018_A Neural Approach to Pun Generation.pdf},
  annote = {\textbf{Extracted Annotations (15/06/2019, 00:46:28)}

"Previous efforts rely on templates or laboriously manually annotated pun datasets, which heavily constrains the quality and diversity of generated puns." (\href{zotero://open-pdf/library/items/7BJG9XGF?page=1}{Yu et al 2018:1})

"sequence-to-sequence models pro- vide an effective technique for text gener- ation, it is promising to investigate these models on the pun generation task. In this paper, we propose neural network mod- els for homographic pun generation, and they can generate puns without requiring any pun data for training." (\href{zotero://open-pdf/library/items/7BJG9XGF?page=1}{Yu et al 2018:1})

"We first train a conditional neural language model from a general text corpus, and then generate puns from the language model with an elaborately designed decoding algorithm." (\href{zotero://open-pdf/library/items/7BJG9XGF?page=1}{Yu et al 2018:1})

"Most previous research on pun generation is based on templates which is convenient but lacks linguistic subtlety and can be inflexible." (\href{zotero://open-pdf/library/items/7BJG9XGF?page=2}{Yu et al 2018:2})

"In this paper, we use the English Wikipedia corpus to train the language model." (\href{zotero://open-pdf/library/items/7BJG9XGF?page=7}{Yu et al 2018:7})}
}

@article{shahComputationalCreativityAutomated2016,
  title = {Computational {{Creativity}}: {{Automated Pun Generation}}},
  volume = {140},
  copyright = {X},
  shorttitle = {Computational {{Creativity}}},
  journal = {International Journal of Computer Applications},
  doi = {10.5120/ijca2016909467},
  author = {Shah, Priyanshi R. and Thakkar, Chintan D. and Mali, Swati},
  month = apr,
  year = {2016},
  pages = {18-22},
  file = {/Users/miriamamin/Documents/Zotero/storage/VZTAR6KI/R et al_2016_Computational Creativity.pdf},
  annote = {The authors are basically re-implementing JAPE with some minor improvements (not concerning the joke generation): integration of existing human-made puns, child-friendly GUI with joke categories, text-box for answering the jokes (claps if joke answered correctly), parental mode to block inappropriate words, text-to-speech system to read the puns. They suggest to use the system to help children suffering from autism spectrum disorder learn faster and broaden their vocabulary.}
}

@inproceedings{raskinPrefaceArtificialIntelligence2012,
  title = {Preface: {{Artificial Intelligence}} of {{Humor}} \textemdash{} {{Computational Humor}}},
  copyright = {X},
  shorttitle = {Preface},
  abstract = {The general goal of the symposium was to advance the state of the art in the direction of developing an AI system (the system) capable of understanding the mechanism of a joke at a level sufficient for providing a punch line to a human generated setup (even if unintentional) and conversely, for computer reacting competently to a human generated punch line that follows a setup, generated by either participant. The effort is multidisciplinary in nature, and the participants from several of the contributing disciplines, viz., computational semantics, knowledge representation, computational psychology, humanoid robotics, human-computer interface, human factors, to name just a few, took part in the work of the symposium.},
  language = {en},
  booktitle = {2012 {{AAAI Fall Symposium Series}}},
  author = {Raskin, Victor and Taylor, Julia M.},
  month = oct,
  year = {2012},
  file = {/Users/miriamamin/Documents/Zotero/storage/N4V3A36T/Raskin_Taylor_2012_Preface.pdf;/Users/miriamamin/Documents/Zotero/storage/3FJ2TZR5/5683.html},
  annote = {introducing a symposium about artificial humor that I should check. Stressing the need for interdisciplinary approaches and regretting that CH is a small field}
}

@inproceedings{jingComparingJokesNLP2018,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Comparing {{Jokes}} with {{NLP}}: {{How Far Can Joke Vectors Take Us}}?},
  copyright = {X},
  isbn = {978-3-319-91131-1},
  shorttitle = {Comparing {{Jokes}} with {{NLP}}},
  abstract = {This paper describes the results of comparison of jokes based on neural network language models and the General Theory of Verbal Humor knowledge resources. The question to be explored is whether joke similarity can be inferred from joke text similarity. Our results indicate that while similarities in text can be detected by doc2vec and jokes with somewhat similar texts can be consistently clustered, there is very little, if any, correlation between doc2vec cosine similarity and KR-annotated joke similarity.},
  language = {en},
  booktitle = {Distributed, {{Ambient}} and {{Pervasive Interactions}}: {{Technologies}} and {{Contexts}}},
  publisher = {{Springer International Publishing}},
  author = {Jing, Xiaonan and Talekar, Chinmay and Taylor Rayz, Julia},
  editor = {Streitz, Norbert and Konomi, Shin'ichi},
  year = {2018},
  keywords = {Computational humor,Clustering,Doc2vec,General theory of verbal humor},
  pages = {310-326},
  file = {/Users/miriamamin/Documents/Zotero/storage/MW8Q87XZ/Jing et al_2018_Comparing Jokes with NLP.pdf},
  annote = {identify two classes of humor detection systems: Humor detection can be either done by comparing the text in question with a set of humorous text and classify it as humorous if its close to them. Or it can be classified based on features that were defined before with the help of humor theory. the authors want to find out whether the joke vectors the nn learns correlate with the GTVH. (if that would be the case the algorithm would identify jokes as similar if they share more KR (knowledge ressources). doint this, they wanted to find out whwther text similarity correlated with GVTH-based joke similarity~}
}

@article{raskinNonliteralnessNonbonafideLanguage1994,
  title = {Non-Literalness and Non-Bona-F{\^i}de in Language: {{An}} Approach to Formal and Computational Treatments of Humor},
  volume = {2},
  copyright = {T},
  issn = {0929-0907, 1569-9943},
  shorttitle = {Non-Literalness and Non-Bona-F{\^i}de in Language},
  abstract = {The paper is devoted to the study of humor as an important pragmatic phenomenon bearing on cognition, and, more specifically, as a cooperative mode of non-bona-fide communication. Several computational models of humor are presented in increasing order of complexity and shown to reveal important cognitive structures in jokes. On the basis of these limited implementations, the concept of a full-fledged computational model for the understanding and generation of humor is introduced and discussed in various aspects. The model draws upon the authors \&apos; General Theory of Verbal Humor, with its six knowledge resources informing a joke, and on SMEARR, a sophisticated semantic-network-based computational lexical environment. The relevance of the approach to the interpretation, generation, and cognitive structure of humor is discussed in the broader context of the nature of the cooperative non-bona-fide modes of communication.},
  language = {en},
  number = {1},
  journal = {Pragmatics \& Cognition},
  doi = {10.1075/pc.2.1.02ras},
  author = {Raskin, Victor and Attardo, Salvatore},
  month = jan,
  year = {1994},
  pages = {31-69},
  file = {/Users/miriamamin/Documents/Zotero/storage/32AF2IW4/Raskin_Attardo_1994_Non-literalness and non-bona-fîde in language.pdf;/Users/miriamamin/Documents/Zotero/storage/ECDVIJIP/pc.2.1.html}
}

@inproceedings{binstedUsingHumourMake1995,
  title = {Using {{Humour}} to {{Make Natural Language Interfaces More Friendly}}},
  copyright = {X},
  abstract = {As natural language interfaces become more widespread, much research is being carried out on ways to make them more congenial. We believe that the judicious incorporation of humorous mechanisms within the user-interface of a computer system could contribute to that goal. A limited use of humour within certain facilities --- such as the signalling of errors, the reporting of the unavailability of facilities, and certain aspects of information provision --- could render a computer system more userfriendly. In particular, such a system should appear less alien, less intimidating, and less patronising. The use of humour would have to be very constrained, not simply because there are limits on what is currently possible, but also because unrestricted facetiousness would be counter-productive. This could be achieved by associating the humorous behaviour with some limited part of the interface, such as a partly-anthropomorphised intelligent agent. Past success in implementing a program genera...},
  booktitle = {Proceedings of the {{AI Alife}} and Entertainment Workshop,  International Joint Conference on Artificial Intelligence},
  author = {Binsted, Kim},
  month = may,
  year = {1995},
  file = {/Users/miriamamin/Documents/Zotero/storage/PI354ZXP/Binsted_1995_Using Humour to Make Natural Language Interfaces More Friendly.pdf}
}

@incollection{raskinComputationalHumorPun2008,
  title = {Computational Humor: {{Beyond}} the Pun?},
  isbn = {978-3-11-019849-2},
  abstract = {The book is intended to provide a definitive view of the field of humor research for both beginning and established scholars in a variety of fields who are developing an interest in humor and need to familiarize themselves with the available body of knowledge. Each chapter of the book is devoted to an important aspect of humor research or to a disciplinary approach to the field, and each is written by the leading expert or emerging scholar in that area. There are two primary motivations for the book. The positive one is to collect and summarize the impressive body of knowledge accumulated in humor research in and around Humor: The International Journal of Humor Research. The negative motivation is to prevent the embarrassment to and from the "first-timers," often established experts in their own field, who venture into humor research without any notion that there already exists a body of knowledge they need to acquire before publishing anything on the subject-unless they are in the business of reinventing the wheel and have serious doubts about its being round! The organization of the book reflects the main groups of scholars participating in the increasingly popular and high-powered humor research movement throughout the world, an 800 to 1,000-strong contingent, and growing. The chapters are organized along the same lines: History, Research Issues, Main Directions, Current Situation, Possible Future, Bibliography-and use the authors' definitive credentials not to promote an individual view, but rather to give the reader a good comprehensive and condensed view of the area.},
  language = {en},
  booktitle = {The {{Primer}} of {{Humor Research}}},
  publisher = {{Walter de Gruyter}},
  author = {Raskin, Victor},
  month = nov,
  year = {2008},
  keywords = {Language Arts \& Disciplines / Linguistics / General,Language Arts \& Disciplines / Linguistics / Historical \& Comparative,Humor / General,Language Arts \& Disciplines / Linguistics / Sociolinguistics},
  googlebooks = {Z8DytgeDVQAC}
}

@article{hempelmannComputationalHumorPun2008,
  title = {Computational Humor: {{Beyond}} the Pun?},
  volume = {8},
  copyright = {X},
  journal = {The Primer of Humor Research. Humor Research},
  author = {Hempelmann, Christian F},
  year = {2008},
  pages = {333--360},
  file = {/Users/miriamamin/Documents/Zotero/storage/4WZDYKXB/Hempelmann_2008_Computational humor.pdf},
  annote = {Excerpt

critisises that the existing pun generatots are just using templates and have no theory about humor. one of the reasons is that the computer scientists behind these systems had no expertise in humor theory (p 339). explains in detail how puns can be analysed with the GVTH. mentions that one of the major problemns is that humans can make sense of the language using their knowledge about the worls while machines dont have this knowledge. he suggests to promote ontological semantics}
}

@inproceedings{hempelmannComputerTellMe2006,
  title = {Computer, {{Tell Me}} a {{Joke}} ... but {{Please Make}} It {{Funny}}: {{Computational Humor}} with {{Ontological Semantics}}.},
  volume = {13},
  copyright = {X},
  shorttitle = {Computer, {{Tell Me}} a {{Joke}} ... but {{Please Make}} It {{Funny}}},
  abstract = {Computational humor is a subdiscipline of computational linguistics with applications in human computer interfaces, edutainment, affective computing, intelligent agents, and other areas. Based on ontological semantics, we develop the resources and algorithms the computer needs to understand and produce humor, in principle and on a detailed example. Our ultimate output will not be that of a toy system that fills in templates, previously the only available approach, but rather true natural language generation, based on the computer approximation of the human understanding of the joke. This paper shows how ontological semantics provides for and computes the full computer understanding of humor, a sine qua non of humor generation.},
  booktitle = {Proceedings of {{FLAIRS Conference}} 2006},
  author = {Hempelmann, Christian and Raskin, Victor and E. Triezenberg, Katrina},
  month = jan,
  year = {2006},
  pages = {746-751},
  file = {/Users/miriamamin/Documents/Zotero/storage/X6DZ5CFA/Hempelmann et al_2006_Computer, Tell Me a Joke.pdf},
  annote = {Author claims that computational Humor is a subdiscipline of computational lnguistics and that in order to produce humor the computer has to understand humor. they show how humor (based on the SSTH) can be modeled using ontological semantics (a system that transforms text into a text-meaning representation (TMR) metalanguage). it does not become clear in how far such systems are actually implemented and thus how feasible their suggestion is.~}
}

@inproceedings{stockHAHAcronymComputationalHumor2005,
  address = {{Stroudsburg, PA, USA}},
  series = {{{ACLdemo}} '05},
  title = {{{HAHAcronym}}: {{A Computational Humor System}}},
  copyright = {GENER},
  shorttitle = {{{HAHAcronym}}},
  abstract = {Computational humor will be needed in interfaces, no less than other cognitive capabilities. There are many practical settings where computational humor will add value. Among them there are: business world applications (such as advertisement, e-commerce, etc.), general computer-mediated communication and human-computer interaction, increase in the friendliness of natural language interfaces, educational and edutainment systems. In particular in the educational field it is an important resource for getting selective attention, help in memorizing names and situations etc. And we all know how well it works with children.Automated humor production in general is a very difficult task but we wanted to prove that some results can be achieved even in short time. We have worked at a concrete limited problem, as the core of the European Project HAHAcronym. The main goal of HAHAcronym has been the realization of an acronym ironic re-analyzer and generator as a proof of concept in a focalized but non restricted context. To implement this system some general tools have been adapted, or developed for the humorous context. Systems output has been submitted to evaluation by human subjects, with a very positive result.},
  booktitle = {Proceedings of the {{ACL}} 2005 on {{Interactive Poster}} and {{Demonstration Sessions}}},
  publisher = {{Association for Computational Linguistics}},
  doi = {10.3115/1225753.1225782},
  author = {Stock, Oliviero and Strapparava, Carlo},
  year = {2005},
  pages = {113--116},
  file = {/Users/miriamamin/Documents/Zotero/storage/5KADP29V/Stock_Strapparava_2005_HAHAcronym.pdf}
}

@inproceedings{raskinLittleMetatheoryThought2012,
  title = {A {{Little Metatheory}}: {{Thought}} on {{What aTheory}} of {{Computational Humor Should Look Like}}},
  copyright = {X},
  shorttitle = {A {{Little Metatheory}}},
  abstract = {This exercise in metatheory presents what any theory consists of and what properties it should have. It, then, adjust the general recipe to a theory of humor and computational humor. In this light, it reviews the state of the art in computational humor and suggests the main lines of development.},
  language = {en},
  booktitle = {2012 {{AAAI Fall Symposium Series}}},
  author = {Raskin, Victor},
  month = oct,
  year = {2012},
  file = {/Users/miriamamin/Documents/Zotero/storage/I4THZHHF/Raskin_2012_A Little Metatheory.pdf;/Users/miriamamin/Documents/Zotero/storage/LLUPNIKA/5644.html},
  annote = {The author argues for the need of a theory of computational humor in order to advance it. he bases his meta-theory of computational humro on SST, GVTH (and OSTH). he summarizes his metatheory:

"the main hypothesis that the text of a (potential) joke is compatible, in full or in part, with two opposing scripts and that a computational system based on this hypothesis is possible that can detect, comprehend, and generate humor;"

He defines properties of theories of CH:~

\begin{itemize}

\item 

adequate, if it provides an accurate account of all the phenomena in its purview in computational implementations; 

\item 

effective, if it comes with a computational methodology for its implementation; 

\item 

formal, trivial because any miscalculation in formality will result in systemic failure; 

\item 

constructive, if that implementation can be computationally completed in finite time\textemdash{}an issue of computational complexity of the system; 

\item 

decidable, if there is a computational algorithm for its implementation in principle; 

\item 

computable, if this algorithm can actually be implemented, 

\item 

explicit, if it is fully aware of all of its components and provides a full account of each of them, which should be trivially achieved in a functional computational system.

\end{itemize}

He regrets that Milhalcea and Strapparavas approaches cannot contribute to insights into the nature of verbal jokes, although that was not part of the properties he defined. he also ignores other approaches (Sj{\"o}berg et al). He mentions the problems of funding and claims that for raising funds it is nececarry to show applications. also claims that ontological semantic technology is the only possibe approach to computational humor.}
}

@article{taylorCognitiveInformaticsNatural2013,
  title = {Towards the {{Cognitive Informatics}} of {{Natural Language}}: {{The Case}} of {{Computational Humor}}},
  volume = {7},
  copyright = {T},
  issn = {1557-3958 DOI: 10.4018/ijcini.2013070102},
  shorttitle = {Towards the {{Cognitive Informatics}} of {{Natural Language}}},
  abstract = {Towards the Cognitive Informatics of Natural Language: The Case of Computational Humor: 10.4018/ijcini.2013070102: This paper deals with a contribution of computational analysis of verbal humor to natural language cognition. After a brief introduction to the growing area},
  language = {en},
  number = {3},
  journal = {International Journal of Cognitive Informatics and Natural Intelligence (IJCINI)},
  doi = {10.4018/ijcini.2013070102},
  author = {Taylor, Julia M. and Raskin, Victor},
  month = jul,
  year = {2013},
  pages = {25-45},
  file = {/Users/miriamamin/Documents/Zotero/storage/4AIJRX44/taylor2013-3.pdf;/Users/miriamamin/Documents/Zotero/storage/NWYAFQXB/103126.html}
}

@article{hulstijnAutomaticInterpretationGeneration1996,
  title = {Automatic {{Interpretation}} and {{Generation}} of {{Verbal Humor}}: {{Proceedings}} of the {{Twelfth Twente Workshop}} on {{Language Technology}}, Joint with {{International Workshop}} on {{Computational Humor}}},
  copyright = {GENER},
  shorttitle = {Automatic {{Interpretation}} and {{Generation}} of {{Verbal Humor}}},
  language = {English},
  author = {Hulstijn, J. and Nijholt, Antinus},
  month = sep,
  year = {1996},
  file = {/Users/miriamamin/Documents/Zotero/storage/CC5L4BTV/Hulstijn_Nijholt_1996_Automatic Interpretation and Generation of Verbal Humor.pdf;/Users/miriamamin/Documents/Zotero/storage/ZEVREB7U/automatic-interpretation-and-generation-of-verbal-humor-proceedin.html}
}

@inproceedings{moralesIdentifyingHumorReviews2017,
  title = {Identifying {{Humor}} in {{Reviews}} Using {{Background Text Sources}}},
  copyright = {RECOG},
  language = {en-us},
  booktitle = {Proceedings of the 2017 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  doi = {10.18653/v1/D17-1051},
  author = {Morales, Alex and Zhai, ChengXiang},
  month = sep,
  year = {2017},
  pages = {492-501},
  file = {/Users/miriamamin/Documents/Zotero/storage/C9Z5AMQD/Morales_Zhai_2017_Identifying Humor in Reviews using Background Text Sources.pdf;/Users/miriamamin/Documents/Zotero/storage/7648WH99/D17-1051.html}
}

@inproceedings{wintersAutomaticJokeGeneration2018,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Automatic {{Joke Generation}}: {{Learning Humor}} from {{Examples}}},
  copyright = {X},
  isbn = {978-3-319-91131-1},
  shorttitle = {Automatic {{Joke Generation}}},
  abstract = {Computational humor systems often employ explicit rules encoding assumptions about what constitutes a funny joke. This paper explores how a program can teach itself to generate jokes based on a corpus of rated example jokes. We implement a system called Generalized Analogy Generator (Gag) capable of generating jokes using the ``I like my X like I like my Y, Z'' template. We use established humor theory and extend computational humor concepts to allow the system to learn the structures of the given jokes and estimate how funny people might find specific instantiations of joke structures. We also implement a platform for the collection of jokes and their ratings, which are used for the training data and evaluation of the system. Since Gag uses generalized components and learns its own schemas, this program successfully generalizes the most well-known analogy generator in the computational humor field.},
  language = {en},
  booktitle = {Distributed, {{Ambient}} and {{Pervasive Interactions}}: {{Technologies}} and {{Contexts}}},
  publisher = {{Springer International Publishing}},
  author = {Winters, Thomas and Nys, Vincent and De Schreye, Daniel},
  editor = {Streitz, Norbert and Konomi, Shin'ichi},
  year = {2018},
  keywords = {Computational humor,Analogy generation,Crowdsourcing,Joke generation,Machine learning},
  pages = {360-377},
  file = {/Users/miriamamin/Documents/Zotero/storage/M8JRFDG9/Winters et al_2018_Automatic Joke Generation.pdf},
  annote = {they include users feedback to improve their jokes over time. they also use the XYz approach, but unlike petrovic et al, they dont use a fixed measure to select the words to fill the slots, but they adapt the measure with user feedback.}
}

@inproceedings{leeTemporalCommunityContexts2017,
  title = {A {{Temporal Community Contexts Based Funny Joke Generation}}},
  copyright = {X},
  abstract = {It is still a long way to communicate humans and machines emotionally. There are some tries to provide sentimental conversations among humans and machines. Computational humor is one of research topics in computational linguistics and artificial intelligence. We introduce a new method to generate jokes in a sentence related temporal and spatial contexts for continuous conversations with images. We propose a novel model based on a recurrent neural network with natural language processing (NLP) and understanding (NLU) methods. The method generates jokes in a sentence considering temporal and spatial context. The method can joke to trend sensitive users according to different points of humor that vary from region to region. Through this, the user can feel the interest of the conversational service with humorous responses or contents. We apply the method to some applications such as psychiatric counseling and stress management to enhance the applicability of conversational service.},
  booktitle = {2017 18th {{IEEE International Conference}} on {{Mobile Data Management}} ({{MDM}})},
  doi = {10.1109/MDM.2017.62},
  author = {Lee, D. and Han, S. and Oh, K. and Choi, H.},
  month = may,
  year = {2017},
  keywords = {artificial intelligence,Artificial intelligence,computational humor,computational linguistics,Computational modeling,Context,conversational service,Emotion recognition,funny joke generation,Generators,human computer interaction,image processing,joke generation,natural language processing,Natural language processing,natural language processing method,natural language understanding method,NLP,NLP method,NLU method,psychiatric counseling,recurrent neural nets,recurrent neural network,sentence related spatial contexts,sentence related temporal contexts,stress management,temporal community contexts},
  pages = {360-365},
  file = {/Users/miriamamin/Documents/Zotero/storage/4GQV73CT/Lee et al_2017_A Temporal Community Contexts Based Funny Joke Generation.pdf;/Users/miriamamin/Documents/Zotero/storage/YD9RZNGZ/7962480.html},
  annote = {The authors suggest neural network architectures that creates humorous posts for a humorous internet community website. They present three architectures: 1. ``na{\"i}ve network'' that generates a sentence from an image and a title or an image and a comment. 2. Title network: generates a title from an image and the posts comments. 3. Trend network, that generates a title from the temporal relationship between posts and the posts attributes (like country, community and posting date). They did not realize these algorithms yet, but expect to create interesting titles and insights into humor trends in different national communities. Since they did not publish a follow-up paper, I assume their experiments were not successful. one interesting thing (unrelated to their endeavor) they mention is that the distance among domains can be measured with vector space models. They also argue why previous CH efforts were not feasible: 1. They're based on expert knowledge and ontologies, which is costly to maintain. 2. They use predefines features to create humor (instead of automatic feature learning) 3. They did not consider photos and videos.}
}

@inproceedings{taylorNaturalLanguageCognition2013,
  title = {Natural Language Cognition of Humor by Humans and Computers: {{A}} Computational Semantic Approach},
  copyright = {T},
  shorttitle = {Natural Language Cognition of Humor by Humans and Computers},
  abstract = {This paper deals with a contribution of computational analysis of verbal humor to natural language cognition. After a brief introduction to the growing area of computational humor and of its roots in humor theories, it describes and compares the results of a human-subject and computer experiment. The specific interest is to compare how well the computer, equipped with the resources and methodologies of the Ontological Semantic Technology, a comprehensive meaning access approach to natural language processing, can model several aspects of the cognitive behaviors of humans processing jokes from the Internet.},
  booktitle = {2013 {{IEEE}} 12th {{International Conference}} on {{Cognitive Informatics}} and {{Cognitive Computing}}},
  doi = {10.1109/ICCI-CC.2013.6622227},
  author = {Taylor, J. M. and Raskin, Victor},
  month = jul,
  year = {2013},
  keywords = {jokes,Psychology,Semantics,computational humor,natural language processing,cognition,Cognition,comprehensive meaning,comprehensive meaning access approach,computational analysis,computational semantic approach,Computers,human cognitive behaviors,humor research,Instruments,Internet,linguistics,natural language,natural language cognition,Natural languages,ontological semantic technology,ontologies (artificial intelligence),psychology,verbal humor},
  pages = {68-75},
  file = {/Users/miriamamin/Documents/Zotero/storage/CDMII2AH/Taylor_Raskin_2013_Natural language cognition of humor by humans and computers.pdf;/Users/miriamamin/Documents/Zotero/storage/6PNHC38I/6622227.html}
}

@inproceedings{taylorComputationalDetectionHumor2009,
  title = {Computational {{Detection}} of {{Humor}}: {{A Dream}} or a {{Nightmare}}? {{The Ontological Semantics Approach}}},
  volume = {3},
  copyright = {RECOG},
  shorttitle = {Computational {{Detection}} of {{Humor}}},
  abstract = {This paper deals with computational detection of humor. It assumes that computational humor is a useful task for any number of reasons and in many applications. It discusses the computational linguistic/ semantic precondi{$\lnot$}tions for computational humor and an ontological semantic approach to the task of humor detection, based on direct and comprehensive access to meaning rather than on trying to guess it through statistical-cum-syntactical keyword methods. The pa{$\lnot$}per is informed by the experience of designing and imple{$\lnot$}menting a humor detection model, whose decent success rate confirmed some of the assumptions while its misses made other ideas prominent, including the necessity of full text comprehension. The bulk of the paper explains how the comprehensive representation of meaning and, most impor{$\lnot$}tantly how unstructured natural language text is automati{$\lnot$}cally translated into the ontologically defined text meaning representations that can be used then to de{$\lnot$}tect humor in them, if any, automatically.},
  booktitle = {2009 {{IEEE}}/{{WIC}}/{{ACM International Joint Conference}} on {{Web Intelligence}} and {{Intelligent Agent Technology}}},
  doi = {10.1109/WI-IAT.2009.318},
  author = {Taylor, Julia M.},
  month = sep,
  year = {2009},
  keywords = {natural language,Natural languages,Application software,Computational intelligence,Computational linguistics,Conferences,Humans,humor detection,Intelligent agent,Learning systems,ontologies,Ontologies,semantics,USA Councils},
  pages = {429-432},
  file = {/Users/miriamamin/Documents/Zotero/storage/C2BH5YMF/Taylor_2009_Computational Detection of Humor.pdf;/Users/miriamamin/Documents/Zotero/storage/I5KBFEYY/5285062.html}
}

@book{sharpHumanMachineInteractionTranslation2011,
  title = {Human-{{Machine Interaction}} in {{Translation}}: {{Proceedings}} of the 8th {{International NLPCS Workshop}}},
  isbn = {978-87-593-1615-3},
  shorttitle = {Human-{{Machine Interaction}} in {{Translation}}},
  abstract = {This special issue of Copenhagen Studies in Language is devoted to human and machine translation and human-computer interaction in translation, which were the two main foci of the 8th International Workshop on Natural Language Processing and Cognitive Science (NLPCS 2011), held at Copenhagen Business School, Denmark, in August 2011. The volume includes the 19 papers which were selected for presentation at the workshop and the text of invite keynote lectures. The workshop provided an attractive interdisciplinary forum for fostering interactions among researchers and practitioners in Natural Language Processing (NLP) working within the paradigm of Cognitive Science (CS). The overall emphasis of the annual NLPCS research workshop series is on the contribution of cognitive science to language processing, including human and machine translation, human-machine interface design, conceptualisation, representation, meaning construction, ontology building, and text mining.},
  language = {en},
  publisher = {{Samfundslitteratur}},
  author = {Sharp, Bernadette and Carl, M. and Zock, M. and Jakobsen, A. L.},
  year = {2011},
  keywords = {Language Arts \& Disciplines / Translating \& Interpreting},
  googlebooks = {jDpS6D60o8AC}
}

@inproceedings{zhangRecognizingHumorTwitter2014,
  address = {{New York, NY, USA}},
  series = {{{CIKM}} '14},
  title = {Recognizing {{Humor}} on {{Twitter}}},
  copyright = {RECOG},
  isbn = {978-1-4503-2598-1},
  abstract = {In this paper, we present our work of humor recognition on Twitter, which will facilitate affect and sentimental analysis in the social network. The central question of what makes a tweet (Twitter post) humorous drives us to design humor-related features, which are derived from influential humor theories, linguistic norms, and affective dimensions. Using machine learning techniques, we are able to recognize humorous tweets with high accuracy and F-measure. More importantly, we single out features that contribute to distinguishing non-humorous tweets from humorous tweets, and humorous tweets from other short humorous texts (non-tweets). This proves that humorous tweets possess discernible characteristics that are neither found in plain tweets nor in humorous non-tweets. We believe our novel findings will inform and inspire the burgeoning field of computational humor research in the social media.},
  booktitle = {Proceedings of the 23rd {{ACM International Conference}} on {{Conference}} on {{Information}} and {{Knowledge Management}}},
  publisher = {{ACM}},
  doi = {10.1145/2661829.2661997},
  author = {Zhang, Renxian and Liu, Naishi},
  year = {2014},
  keywords = {humor recognition,computational humor,machine learning,twitter},
  pages = {889--898}
}

@inproceedings{chandrasekaranWeAreHumor2016,
  title = {We {{Are Humor Beings}}: {{Understanding}} and {{Predicting Visual Humor}}},
  copyright = {X},
  shorttitle = {We {{Are Humor Beings}}},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Chandrasekaran, Arjun and Vijayakumar, Ashwin K. and Antol, Stanislaw and Bansal, Mohit and Batra, Dhruv and Lawrence Zitnick, C. and Parikh, Devi},
  year = {2016},
  pages = {4603-4612},
  file = {/Users/miriamamin/Documents/Zotero/storage/DDHA7QCY/Chandrasekaran et al_2016_We Are Humor Beings.pdf;/Users/miriamamin/Documents/Zotero/storage/PKC29HGI/Chandrasekaran_We_Are_Humor_CVPR_2016_paper.html},
  annote = {Excerpt

dealing with visual humor and the following tasks: predicting how funny a scene is and alterning the funniness of the scene (funny-unfunny). they train neural networks to complete the tasks, using their own datasets they created for this prupose

~}
}

@article{taylorOntologybasedViewNatural2010,
  title = {Ontology-Based View of Natural Language Meaning: The Case of Humor Detection},
  volume = {1},
  copyright = {T},
  issn = {1868-5145},
  shorttitle = {Ontology-Based View of Natural Language Meaning},
  abstract = {This paper deals with computational detection of humor. It assumes that computational humor is an useful task for any number of reasons and in many applications. Besides these applications, it also shows that recognition of humor is a perfect test platform for an advanced level of language understanding by a computer. It discusses the computational linguistic/semantic preconditions for computational humor and an ontological semantic approach to the task of humor detection, based on direct and comprehensive access to meaning rather than on trying to guess it with statistical-cum-syntactical keyword methods. The paper is informed by the experience of designing and implementing a humor detection model, whose decent success rate confirmed some of the assumptions while its flaws made other ideas prominent, including the necessity of full text comprehension. The bulk of the paper explains how the comprehensive meaning access technology makes it possible for unstructured natural language text to be automatically translated into the ontologically defined text meaning representations that can be used then to detect humor in them, if any, automatically. This part is informed by the experience, subsequent to humor detection, of designing, implementing, and testing an ontological semantic text analyzer that takes an English sentence as input and outputs its text meaning representation (TMR). Every procedure mentioned in the paper has either been implemented or proven to be implementable within the approach.},
  language = {en},
  number = {3},
  journal = {Journal of Ambient Intelligence and Humanized Computing},
  doi = {10.1007/s12652-010-0014-2},
  author = {Taylor, Julia M.},
  month = sep,
  year = {2010},
  keywords = {Semantics,Ontologies,Analyzer,Humor detection,Natural language,Text meaning representation},
  pages = {221-234},
  file = {/Users/miriamamin/Documents/Zotero/storage/5A78YQFR/Taylor_2010_Ontology-based view of natural language meaning.pdf}
}

@inproceedings{friedlandJokeRetrievalRecognizing2008,
  address = {{New York, NY, USA}},
  series = {{{CIKM}} '08},
  title = {Joke {{Retrieval}}: {{Recognizing}} the {{Same Joke Told Differently}}},
  copyright = {X},
  isbn = {978-1-59593-991-3},
  shorttitle = {Joke {{Retrieval}}},
  abstract = {In a corpus of jokes, a human might judge two documents to be the "same joke" even if characters, locations, and other details are varied. A given joke could be retold with an entirely different vocabulary while still maintaining its identity. Since most retrieval systems consider documents to be related only when their word content is similar, we propose joke retrieval as a domain where standard language models may fail. Other meaning-centric domains include logic puzzles, proverbs and recipes; in such domains, new techniques may be required to enable us to search effectively. For jokes, a necessary component of any retrieval system will be the ability to identify the "same joke," so we examine this task in both ranking and classification settings. We exploit the structure of jokes to develop two domain-specific alternatives to the "bag of words" document model. In one, only the punch lines, or final sentences, are compared; in the second, certain categories of words (e.g., professions and countries) are tagged and treated as interchangeable. Each technique works well for certain jokes. By combining the methods using machine learning, we create a hybrid that achieves higher performance than any individual approach.},
  booktitle = {Proceedings of the 17th {{ACM Conference}} on {{Information}} and {{Knowledge Management}}},
  publisher = {{ACM}},
  doi = {10.1145/1458082.1458199},
  author = {Friedland, Lisa and Allan, James},
  year = {2008},
  keywords = {document similarity,domain-specific retrieval,humor},
  pages = {883--892},
  file = {/Users/miriamamin/Documents/Zotero/storage/Z6VP5VV5/Friedland_Allan_2008_Joke Retrieval.pdf},
  annote = {information retrieval approach to computational humor and the other way around (humor as an alternative notion of document similarity). they want to find a system that, given a joke, retrieves a similar joke from a corpus. they acknowledge the fact that two similar jokes (in opposition to most similar documents) do not neccesseraliy have to share the same text. they define two models: first compares only the punchline (assuming its the final sentence) second marks certain categories (eg professions or nationalities) as interchangable. they ignore the GTVH}
}

@inproceedings{hongAutomaticallyExtractingWord2009,
  address = {{Stroudsburg, PA, USA}},
  series = {{{CALC}} '09},
  title = {Automatically {{Extracting Word Relationships As Templates}} for {{Pun Generation}}},
  copyright = {X},
  isbn = {978-1-932432-36-7},
  abstract = {Computational models can be built to capture the syntactic structures and semantic patterns of human punning riddles. This model is then used as rules by a computer to generate its own puns. This paper presents T-PEG, a system that utilizes phonetic and semantic linguistic resources to automatically extract word relationships in puns and store the knowledge in template form. Given a set of training examples, it is able to extract 69.2\% usable templates, resulting in computer-generated puns that received an average score of 2.13 as compared to 2.70 for human-generated puns from user feedback.},
  booktitle = {Proceedings of the {{Workshop}} on {{Computational Approaches}} to {{Linguistic Creativity}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Hong, Bryan Anthony and Ong, Ethel},
  year = {2009},
  pages = {24--31},
  file = {/Users/miriamamin/Documents/Zotero/storage/HH6FASMV/Hong_Ong_2009_Automatically Extracting Word Relationships As Templates for Pun Generation.pdf},
  annote = {the authors present an algorithm that takes question-answer jokes as training data and extracts the structural pattern from these jokes. they call the system T-PEG. the semantic links among the words are determined using conceptnet. these patterns are captured with the use of templates, that contain the relationships between the words as well as the syntctical structure. eg from the source pun 'Which bird can lift the heaviest weights? The crane. ' the syntactical structure 'Which {$<$}X1{$>$} can {$<$}X3{$>$} the heaviest {$<$}X6{$>$}? The {$<$}Y1{$>$}.' and the word relationships 'X1 ConceptuallyRelatedTo X6\\
X6 ConceptuallyRelatedTo X1\\
Y1 IsA X1\\
X6 CapableOfReceivingAction X3 Y1 CapableOf X3Y1 UsedFor X3' are extracted to compoe the template. from a joke, only the words that actually have relationships to other words in the joke are treated as variables. to generate jokes, the system uses the library of patterns and conceptnet for semantic relationships, unisyn for shomonyms nad wordnet for synonyms. also the user has to give a keyword.~ the authors fid, that from the 29 template they can extract from the data, 27 (69\%) ae usable. the authors testes the algorithm by inputting keywords fro the source puns to determine if they can be generated back (worked in 74\%). the generated jokes were rated and compared against the human created counterpart. the computer generated jokes got an average of 2.13, the human ones 2,7.}
}

@incollection{valituttiHowManyJokes2011,
  title = {How Many Jokes Are Really Funny? {{Toward}} a {{New Approach}} to the {{Evaluation}} of {{Computational Humor Generators}}},
  copyright = {X EVAL},
  isbn = {978-87-593-1615-3},
  abstract = {This special issue of Copenhagen Studies in Language is devoted to human and machine translation and human-computer interaction in translation, which were the two main foci of the 8th International Workshop on Natural Language Processing and Cognitive Science (NLPCS 2011), held at Copenhagen Business School, Denmark, in August 2011. The volume includes the 19 papers which were selected for presentation at the workshop and the text of invite keynote lectures. The workshop provided an attractive interdisciplinary forum for fostering interactions among researchers and practitioners in Natural Language Processing (NLP) working within the paradigm of Cognitive Science (CS). The overall emphasis of the annual NLPCS research workshop series is on the contribution of cognitive science to language processing, including human and machine translation, human-machine interface design, conceptualisation, representation, meaning construction, ontology building, and text mining.},
  language = {en},
  booktitle = {Human-{{Machine Interaction}} in {{Translation}}: {{Proceedings}} of the 8th {{International NLPCS Workshop}}},
  publisher = {{Samfundslitteratur}},
  author = {Valitutti, Alessandro},
  editor = {Sharp, Bernadette and Zock, Michael and Carl, Michael and Jakobsen, Arnt Lykke},
  year = {2011},
  keywords = {Language Arts \& Disciplines / Translating \& Interpreting},
  pages = {189-200},
  file = {/Users/miriamamin/Documents/Zotero/storage/MGS44RYH/Sharp et al_2011_How many jokes are really funny.pdf},
  googlebooks = {jDpS6D60o8AC},
  annote = {introduce a measure for the evaluation of verbal jokes. they suggest to not rate the funniness of one item but the rate of jokes with a fix value of funniness. performance of the pun generator is defined as the fracton of funny items in a set of generated jokes = humorous frequence (HF). tested on two pun generators}
}

@article{ruchEmpiricalVerificationGeneral1993,
  title = {Toward an {{Empirical Verification}} of the {{General Theory}} of {{Verbal Humor}}},
  volume = {6},
  abstract = {The present study derives hypotheses from the General Theory of Verbal Humor (GTVH) and tests them on a sample of 534 subjects. Subjects are presented with three sets of jokes, each consisting of an anchor joke and comparison jokes in which variations in one and only one of the six
Knowledge Resources (KR), script Opposition (SO), logical mechanism (LM), Situation (SI) target (TA), narrative strategy (NS), andlanguage (LA) occurred. Subjects rated the degree of similarity between the anchor joke and the six comparison jokes. The results support the hypothesis that the extent to which the similarity judgment is affected depends on the type of the KR manipulated. Also, there generally is a decreasing trend in similarity between the KRs LA and SO. Whereas there was a significant difference between all consecutive KRs, {\"a}s predicted by the hierarchy postulated by the GTVH, SI and LM were not in the right order. Possible explanations for thisfact are discussed.
This article presents and discusses a study which empirically Supports some of the Claims of the General Theory of Verbal Humor (GTVH). After introducing the theory, the article will present the hypotheses derived from the theory that were tested and finally the results of the investigation.},
  journal = {Humor-international Journal of Humor Research - HUMOR},
  doi = {10.1515/humr.1993.6.2.123},
  author = {Ruch, Willibald and Attardo, Salvatore and Raskin, Victor},
  month = jan,
  year = {1993},
  pages = {123-136},
  file = {/Users/miriamamin/Documents/Zotero/storage/AXJUV56U/Ruch et al_1993_Toward an Empirical Verification of the General Theory of Verbal Humor.pdf}
}

@article{rayzComputationallyRecognizingWordplay2004,
  title = {Computationally Recognizing Wordplay in Jokes},
  copyright = {RECOG},
  abstract = {In artificial intelligence, researchers have begun to look at ap-proaches for computational humor. Although there appears to be no complete computational model for recognizing verbally expressed humor, it may be possible to recognize jokes based on statistical language recognition techniques. This is an in-vestigation into computational humor recognition. It considers a restricted set of all possible jokes that have wordplay as a component and examines the limited domain of "Knock Knock" jokes. The method uses Raskin's theory of humor for its theoretical foundation. The original phrase and the complimentary wordplay have two different scripts that overlap in the setup of the joke. The algorithm deployed learns statistical patterns of text in N-grams and provides a heuristic focus for a location of where wordplay may or may not occur. It uses a wordplay generator to produce an utter-ance that is similar in pronunciation to a given word, and the wordplay recognizer determines if the utterance is valid. Once a possible wordplay is discovered, a joke recognizer de-termines if a found wordplay transforms the text into a joke.},
  journal = {Cognitive Science - COGSCI},
  author = {Rayz, Julia},
  month = jan,
  year = {2004},
  file = {/Users/miriamamin/Documents/Zotero/storage/IVZPZ4PX/Rayz_2004_Computationally recognizing wordplay in jokes.pdf}
}

@inproceedings{yangwangCanHasCheezburger2015,
  title = {I {{Can Has Cheezburger}}? {{A Nonparanormal Approach}} to {{Combining Textual}} and {{Visual Information}} for {{Predicting}} and {{Generating Popular Meme Descriptions}}},
  copyright = {X GENER},
  shorttitle = {I {{Can Has Cheezburger}}?},
  doi = {10.3115/v1/N15-1039},
  author = {Yang Wang, William and Wen, Miaomiao},
  month = jan,
  year = {2015},
  pages = {355-365},
  file = {/Users/miriamamin/Documents/Zotero/storage/RUCDZ8VW/Yang Wang_Wen_2015_I Can Has Cheezburger.pdf},
  annote = {the authors generate meme captions given an input image. they find the keywords describing the image via google image search and use these keywords to retrieve meme captions from a meme caption data base. they rank the retrieved captions according to measurements based on some textual and visual features they define. unsurpisingley, they actually create humorous memes. (but they dont really create teyt, actually they just created an algorithm to retrieve funny already existing memes..)}
}

@inproceedings{davidovSemisupervisedRecognitionSarcastic2010,
  address = {{Stroudsburg, PA, USA}},
  series = {{{CoNLL}} '10},
  title = {Semi-Supervised {{Recognition}} of {{Sarcastic Sentences}} in {{Twitter}} and {{Amazon}}},
  copyright = {RECOG},
  isbn = {978-1-932432-83-1},
  abstract = {Sarcasm is a form of speech act in which the speakers convey their message in an implicit way. The inherently ambiguous nature of sarcasm sometimes makes it hard even for humans to decide whether an utterance is sarcastic or not. Recognition of sarcasm can benefit many sentiment analysis NLP applications, such as review summarization, dialogue systems and review ranking systems. In this paper we experiment with semi-supervised sarcasm identification on two very different data sets: a collection of 5.9 million tweets collected from Twitter, and a collection of 66000 product reviews from Amazon. Using the Mechanical Turk we created a gold standard sample in which each sentence was tagged by 3 annotators, obtaining F-scores of 0.78 on the product reviews dataset and 0.83 on the Twitter dataset. We discuss the differences between the datasets and how the algorithm uses them (e.g., for the Amazon dataset the algorithm makes use of structured information). We also discuss the utility of Twitter \#sarcasm hashtags for the task.},
  booktitle = {Proceedings of the {{Fourteenth Conference}} on {{Computational Natural Language Learning}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Davidov, Dmitry and Tsur, Oren and Rappoport, Ari},
  year = {2010},
  pages = {107--116},
  file = {/Users/miriamamin/Documents/Zotero/storage/S6HHY769/Davidov et al_2010_Semi-supervised Recognition of Sarcastic Sentences in Twitter and Amazon.pdf}
}

@article{rayzComputationalRecognitionHumorous2004,
  title = {Toward Computational Recognition of Humorous Intent},
  copyright = {RECOG},
  abstract = {Recognizing the intent of a written utterance is a difficult task. To understand the intended meanings, it may be neces-sary to recognize all possible meanings of the utterance; and, then choose the most appropriate one for the situation. The choice may be made using heuristics. A method for recogni-tion of a humorous intent in a text is proposed. Computational recognition of a humorous intent can be broken down into two parts: recognition of a humorous text, and recognition of the intent to be humorous. To narrow the focus, we propose to recognize the humorous intent of short dialogs. A dialog will be considered humorous if the first part of the text can have two meanings; and, one of the meanings conflicts with the meaning of the punchline. The intent of the text is considered humorous if the schema related to the non-conflicting mean-ing of the setup has not been activated in the preceding text.},
  journal = {Cognitive Science - COGSCI},
  author = {Rayz, Julia},
  month = jan,
  year = {2004},
  file = {/Users/miriamamin/Documents/Zotero/storage/RT6PEZDI/Rayz_2004_Toward computational recognition of humorous intent.pdf}
}

@article{rayzReverseEngineeringHumor2019,
  title = {Reverse {{Engineering Humor}}},
  abstract = {Heuristic and validating experiments concerning computa-tional selection and recognition of words that lead to hu-morous wordplay in a set of jokes are reviewed. The experi-ments were not designed to classify jokes and non-jokes. In-stead, all texts were known to be jokes based on wordplay. The task was to find the words that lead to wordplay, and recognizing resulting wordplay. The term "reverse engineering" is used "tongue and cheek" to describe this project's deconstruction of already established jokes. The jokes were selected from Kostick et al (1998). Jokes were sequentially read by a human until those matching the desired number and characteristic were found. Usually jokes have a setup and a punchline. The setup creates expectations, the punchline violates them, leading to a different interpretation of the setup (Ritchie, 1999). Each wordplay joke contains a (source, target) pair of words. The source is an utterance in the joke; the source conflicts with the perceiver's initial interpretation. The tar-get is an utterance that sounds similar to the source. The similarity in pronunciation between the source and the tar-get, in addition to the conflict with the initial interpretation, leads to discovery of a second interpretation of the text. For example, consider (Kostick et al, 1998): Rich: How was your date? Mitch: Terrible! She didn't smile once all night! Rich: Poker face, eh? Mitch: No, but I wanted to. The (source, target) pair is (poker, poke her). In our experiments, all the words in the jokes are rated with familiarity values (Wilson, 1987) and Ku{\v c}era-Francis (KF) frequency (1967). The first experiment was conducted to decrease the search space of target source pairs. The two hypotheses were: the source of the joke has a lower familiarity value than the me-dian familiarity value of all words in the joke; the source of the joke has a lower KF frequency value than the median KF value of the joke. The hypotheses were tested on a set of 50 short jokes of different length (10 words \textendash{} 38 words). Words with unknown familiarity or KF frequency value were included with a corresponding value of 0. The results were: the source of the joke had a lower familiarity value than the median familiarity in 48 jokes out of 50; the source of the joke had a lower KF frequency than the median in 49 jokes out of 50. Combining the hypotheses reduced the overall source search space in 50 jokes by 50.79\%. The source is usually positioned closer to the end of the joke. Thus, our source search starts from the last word of the joke, and moves towards the first word. This method re-duced the search space by 86.69\%. The addition of heuristic function that incorporated results of the first experiment reduced the search space by an additional 0.78\%. While this number seems small, it substantially decreases search space with the increase of text length. Once the source is chosen, targets are generated using phoneme substitution. The phonemes to be substituted are chosen taking into account cost (Hemplemann, 2003) and confusion (Frisch, 1996) metrics. The resulting utterances are used as target candidates. To find a heuristic function of word selection that leads to the desired (source, pair), we looked at the relationship be-tween familiarity and KF frequency of words that lead to humor. A sample of 1182 target pun pairs was taken from Hempelmann (2003). The values for familiarity and KF fre-quency of words were taken from MRC Psycholinguistic Database. Since familiarity and KF frequency values are only available for single words, puns where the target or source consisted of more than one word were discarded. Additionally, puns with unknown values of familiarity or KF frequency for target or source were discarded. The re-sults showed: (1) the familiarity value of the source is at least 5\% lower than the corresponding familiarity value of the target in 56\% of the data; (2) the KF frequency value for the source is at least 10\% lower than the corresponding KF frequency value for the target in 71\% of the data. The addition of the higher familiarity and frequency selection condition further narrows the choices for target selection for each source. In summary, the presented results are useful for computa-tional humor recognizers. Regardless of the nature of the recognizer (ontologically-, statistically-, etc based), analyz-ing each word of a joke takes too long. The presented re-search takes advantage of the joke's structure in relation to familiarity and KF frequency values to apply the recogniz-ers resources in the most efficient manner.},
  author = {Rayz, Julia},
  month = jun,
  year = {2019}
}

@inproceedings{wimtinholtComputationalHumourUtilizing2007,
  title = {Computational {{Humour}}: {{Utilizing Cross}}-{{Reference Ambiguity}} for {{Conversational Jokes}}},
  volume = {4578},
  copyright = {X},
  shorttitle = {Computational {{Humour}}},
  abstract = {This paper presents a computer implementation that utilizes cross-reference ambiguity in utterances for simple conversational jokes. The approach is based on the SSTH. Using a simple script representa- tion, it is shown that cross-reference ambiguities always satisfy the SSTH requirement for script overlap. To determine whether script opposition is present, we introduce a method that compares the concepts involved based on their semantic properties. When a given cross-reference ambigu- ity results in script opposition it is possible to generate a punchline based on this ambiguity. As a result of the low performance of the anaphora res- olution algorithm and the data sparseness in ConceptNet the application performs moderately, but it does provide future prospects in generating conversational humour.},
  booktitle = {{{LNCS}}},
  doi = {10.1007/978-3-540-73400-0_60},
  author = {Wim Tinholt, Hans and Nijholt, Anton},
  month = jul,
  year = {2007},
  pages = {477-483},
  file = {/Users/miriamamin/Documents/Zotero/storage/BITD3YII/Wim Tinholt_Nijholt_2007_Computational Humour.pdf},
  annote = {the authors present an algorithm that uses falsely referenced anaphora to create ambiguity ("The cops arrested the demonstrators because they were violent"). they use SSTH as theoretical background. representing the semantic scripts as a graph, they define script overlap as the existence of a common subgraph G in S1 and S2. for script opposition, they retrieve properties of nouns from conceptnet and define them as apposed if they have a sufficient number of properties in common and have at least one anzonymous pair in the non-overlapping properties. thes system was implemented in a chatbot where the user has to give the chatbot the joke suggestion ("Did you know that the cops arrested the demonstrators because they were violent?") so the chatbot could answer ("The cops were violent? Or the demonstrators? ") they call this conversational humor. it shows, that their system has a precision of 15\% (85\% not funny ambiguities). they name the sparseness of conceptnet data as a main reason for this.}
}

@article{taylorReverseEngineeringHumor,
  title = {Reverse {{Engineering Humor}}},
  copyright = {T},
  abstract = {Reverse Engineering Humor},
  language = {en},
  journal = {csjarchive.cogsci.rpi.edu},
  author = {Taylor, Julia M.},
  file = {/Users/miriamamin/Documents/Zotero/storage/GLWW8S2J/Taylor_Reverse Engineering Humor.pdf;/Users/miriamamin/Documents/Zotero/storage/G2K9T3GH/Reverse_Engineering_Humor.html}
}

@misc{wintersJokeJudger,
  title = {{{JokeJudger}}},
  abstract = {Create and rate jokes},
  language = {en-GB},
  howpublished = {http://www.jokejudger.com},
  author = {Winters, Thomas},
  file = {/Users/miriamamin/Documents/Zotero/storage/83VXDBPQ/jokejudger.herokuapp.com.html}
}

@phdthesis{wintersAutomaticJokeGeneration2017,
  title = {Automatic {{Joke Generation}}: {{Learning Humour}} from {{Examples}}},
  copyright = {GENER},
  language = {en},
  school = {KU Leuven},
  author = {Winters, Thomas},
  year = {2017},
  file = {/Users/miriamamin/Documents/Zotero/storage/TYPDWJIS/Winters - Automatic Joke Generation Learning Humour from Ex.pdf},
  annote = {adds some properties and measurements to the I like my X, Y Z approach to improve the funniness (p. 26 ff)}
}

@misc{wintersAnonymisedDataJokeJudger2018,
  title = {Anonymised Data from the {{JokeJudger}} Platform, Containing Jokes Using the "{{I}} like My {{X}} like {{I}} like My {{Y}}, {{Z}}" Template and Ratings for These Jokes.: Twinters/Jokejudger-Data},
  shorttitle = {Anonymised Data from the {{JokeJudger}} Platform, Containing Jokes Using the "{{I}} like My {{X}} like {{I}} like My {{Y}}, {{Z}}" Template and Ratings for These Jokes.},
  author = {Winters, Thomas},
  month = mar,
  year = {2018}
}

@inproceedings{raskinSemanticMechanismsHumor1985,
  title = {Semantic {{Mechanisms}} of {{Humor}}},
  volume = {5},
  isbn = {978-90-277-1821-1},
  abstract = {Proceedings of the Fifth Annual Meeting of the Berkeley Linguistics Society (1979), pp. 325-335},
  booktitle = {Proceedings of the {{Fifth Annual Meeting}} of the {{Berkeley Linguistics Society}} (1979)},
  doi = {10.3765/bls.v5i0.2164},
  author = {Raskin, Victor},
  month = jan,
  year = {1985},
  pages = {pp. 325-335},
  file = {/Users/miriamamin/Documents/Zotero/storage/KUMG4PQU/Raskin_1985_Semantic Mechanisms of Humor.pdf}
}

@inproceedings{binstedImplementedModelPunning1994,
  address = {{Menlo Park, CA, USA}},
  title = {An Implemented Model of Punning Riddles},
  volume = {1},
  copyright = {GENER},
  abstract = {In this paper, we discuss a model of simple question-answer punning, implemented in a program, JAPE, which generates riddles from humour-independent lexical entries. The model uses two main types of structure: schemata, which determine the relationships between key words in a joke, and templates, which produce the surface form of the joke. JAPE succeeds in generating pieces of text that are recognizably jokes, but some of them are not very good jokes. We mention some potential improvements and extensions, including post-production heuristics for ordering the jokes according to quality.},
  booktitle = {Procs {{12thNational Conf}}. on {{AI}}},
  publisher = {{AAAI Press}},
  author = {Binsted, Kim and Ritchie, Graeme},
  month = jul,
  year = {1994},
  pages = {633-638},
  file = {/Users/miriamamin/Documents/Zotero/storage/C22NJEYB/Binsted_Ritchie_1994_An implemented model of punning riddles.pdf}
}

@article{binstedComputationalRulesGenerating1997,
  title = {Computational Rules for Generating Punning Riddles},
  volume = {10},
  copyright = {GENER},
  issn = {1613-3722(Electronic),0933-1719(Print)},
  abstract = {Riddles based on simple puns can be classified according to the patterns of word, syllable, or phrase similarity they depend upon. This article presents a formal model of the semantic and syntactic regularities underlying some of the simpler types of punning riddles. This preliminary theory is implemented in a computer program which can generate riddles from a lexicon containing general data about words and phrases; that is, the lexicon content is not customized to produce jokes. An informal, formative evaluation of the performance of this program suggests that its output, although poor, is not significantly worse than that produced by human composers of such riddles. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  number = {1},
  journal = {Humor: International Journal of Humor Research},
  doi = {10.1515/humr.1997.10.1.25},
  author = {Binsted, Kim and Ritchie, Graeme},
  year = {1997},
  keywords = {Semantics,Computer Applications,Computer Software,Humor,Models,Syntax},
  pages = {25-76},
  file = {/Users/miriamamin/Documents/Zotero/storage/5KKZHP7J/Binsted_Ritchie_1997_Computational rules for generating punning riddles.pdf;/Users/miriamamin/Documents/Zotero/storage/AVE6ZJ6E/1997-08013-001.html},
  annote = {they propose to classify a computer generated joke as successfull when people cannot tell them apart from a human created joke (funniness left aside)}
}

@article{woolfPythonPackageEasily2019,
  title = {Python Package to Easily Retrain {{OpenAI}}'s {{GPT}}-2 Text-Generating Model on New Texts: Minimaxir/Gpt-2-Simple},
  copyright = {View license},
  shorttitle = {Python Package to Easily Retrain {{OpenAI}}'s {{GPT}}-2 Text-Generating Model on New Texts},
  journal = {GitHub repository, https://github.com/minimaxir/gpt-2-simple},
  author = {Woolf, Max},
  month = jun,
  year = {2019},
  note = {https://github.com/minimaxir/gpt-2-simple}
}

@book{hirschWitzableiterOderSchule2005,
  address = {{M{\"u}nchen}},
  edition = {3.},
  title = {{Der Witzableiter oder Schule des Lachens}},
  isbn = {978-3-406-47560-3},
  language = {Deutsch},
  publisher = {{C.H.Beck}},
  author = {Hirsch, Eike Christian},
  month = sep,
  year = {2005}
}

@misc{RoutledgeHandbookLanguage,
  type = {Text},
  title = {The {{Routledge Handbook}} of {{Language}} and {{Humor}}: 1st {{Edition}} ({{Hardback}}) - {{Routledge}}},
  shorttitle = {The {{Routledge Handbook}} of {{Language}} and {{Humor}}},
  abstract = {The Routledge Handbook of Language and Humor presents the first ever comprehensive, in-depth treatment of all the sub-fields of the linguistics of humor, broadly conceived as the intersection of the study of language and humor. The reader will find a\ldots{}},
  language = {en},
  journal = {Routledge.com},
  howpublished = {https://www.routledge.com/The-Routledge-Handbook-of-Language-and-Humor-1st-Edition/Attardo/p/book/9781138843066},
  file = {/Users/miriamamin/Documents/Zotero/storage/KV8D5ZLA/9781138843066.html}
}

@incollection{taylorComputationalTreatmentsHumor2017,
  title = {Computational Treatments of Humor.},
  copyright = {X},
  isbn = {978-1-317-55116-4 978-1-317-55115-7},
  abstract = {The Routledge Handbook ofLanguage andHumor presents the first ever comprehensive, in-depth treatment of all the sub-fields of the linguistics of humor, broadly conceived as the intersection of the study of language and humor. The reader will find a thorough historical, terminological, and theoretical introduction to the field, as well as detailed treatments of the various approaches to language and humor. Deliberately comprehensive and wide-ranging, the handbook includes chapter-long treatments on the traditional topics covered by language and humor (e.g., teasing, laughter, irony, psycholinguistics, discourse analysis, the major linguistic theories of humor, translation) but also cutting-edge treatments of internet humor, cognitive linguistics, relevance theoretic, and corpus-assisted models of language and humor. Some chapters, such as the variationist sociolinguistcs, stylistics, and politeness are the first-ever syntheses of that particular subfield. Clusters of related chapters, such as conversation analysis, discourse analysis and corpus-assisted analysis allow multiple perspectives on complex trans-disciplinary phenomena. This handbook is an indispensable reference work for all researchers interested in the interplay of language and humor, within linguistics, broadly conceived, but also in neighboring disciplines such as literary studies, psychology, sociology, anthropology, etc. The authors are among the most distinguished scholars in their fields.},
  language = {English},
  booktitle = {The {{Routledge}} Handbook of Language and Humor},
  author = {Taylor, Julia M.},
  editor = {Attardo, Salvatore},
  year = {2017},
  pages = {456-471},
  file = {/Users/miriamamin/Documents/Zotero/storage/L2QG3XBG/Attardo - The Routledge Handbook of Language and Humor.pdf},
  note = {OCLC: 973222890},
  annote = {also proposes a classification of computational humor research: generation vs detection/visual vs text/autonomous vs manual. also asks the question about how much of the creational work should be done by the computer in order to call it computer-generated (gives no answer). defines requirements a CH system should satisfy (understand language, represent knowledge about the world, reason about this knowledge, know grammar, understand what can be funny) (no explanation given about what the author means by "understand" "reason" ans "know" when talking about an algorithm"). she proposes that GVTH could be verified by having an clustering algorithm cluster jokes into the GVTH's KRs (thats what Jing et al did in 2018).}
}

@article{attardoRoutledgeHandbookLanguage,
  title = {The {{Routledge Handbook}} of {{Language}} and {{Humor}}},
  language = {en},
  author = {Attardo, Salvatore},
  pages = {556}
}

@inproceedings{mihalceaCharacterizingHumourExploration2007,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Characterizing {{Humour}}: {{An Exploration}} of {{Features}} in {{Humorous Texts}}},
  copyright = {X},
  isbn = {978-3-540-70939-8},
  shorttitle = {Characterizing {{Humour}}},
  abstract = {This paper investigates the problem of automatic humour recognition, and provides and in-depth analysis of two of the most frequently observed features of humorous text: human-centeredness and negative polarity. Through experiments performed on two collections of humorous texts, we show that these properties of verbal humour are consistent across different data sets.},
  language = {en},
  booktitle = {Computational {{Linguistics}} and {{Intelligent Text Processing}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Mihalcea, Rada and Pulman, Stephen},
  editor = {Gelbukh, Alexander},
  year = {2007},
  keywords = {News Article,Personal Pronoun,Polarity Orientation,Sentiment Analysis,Support Vector Machine},
  pages = {337-347},
  file = {/Users/miriamamin/Documents/Zotero/storage/S5VG7IVZ/Mihalcea_Pulman_2007_Characterizing Humour.pdf},
  annote = {the authors~ 1. distinguish humorous texts (one-liners and funny news articles) from their non-humorous counterparts using machine learning techniques for text classification (Naive Bayes and SVM)~ and 2. identify the distinct features of humor from the data. In contrast to their prevoius work, they focus on semantic features rather than stylistic. they show that humorous texts can be separated from non-humorous (accuray between 80\% and 96\%). they manually identify the following semantic classes as discriminative humor features: human-centric vocabulary, negation, negative orientation, professional commuities, human weakness. they clsuter these classes into two super classes: human centeredness and polarity orientation. and prove the existance of these classes computationally using wordnet and sentiment analysis.}
}

@inproceedings{mihalceaComputationalLaughingAutomatic2005,
  title = {Computational {{Laughing}}: {{Automatic Recognition}} of {{Humorous One}}-Liners},
  copyright = {RECOG},
  shorttitle = {Computational {{Laughing}}},
  abstract = {Humor is one of the most interesting and puzzling as- pects of human behavior. Despite the attention it has received in elds such as philosophy, linguistics, and psychology, there have been only few attempts to cre- ate computational models for humor recognition or gen- eration. In this paper, we bring empirical evidence that computational approaches can be successfully ap- plied to the task of humor recognition. Through ex- periments performed on very large data sets, we show that automatic classication techniques can be eec- tively used to distinguish between humorous and non- humorous texts, with signican t improvements observed over apriori known baselines.},
  booktitle = {Proc. 27th {{Ann}}. {{Conf}}. {{Cognitive Science Soc}}.},
  author = {Mihalcea, Rada and Strapparava, Carlo},
  month = jan,
  year = {2005},
  pages = {pp. 1513-1518},
  file = {/Users/miriamamin/Documents/Zotero/storage/56MF4Q6N/Mihalcea_Strapparava_2005_Computational Laughing.pdf}
}

@inproceedings{sjoberghRecognizingHumorRecognizing2007,
  title = {Recognizing {{Humor Without Recognizing Meaning}}},
  volume = {4578},
  copyright = {X},
  abstract = {We present a machine learning approach for classifying sentences as one-liner jokes or normal sentences. We use no deep analysis
of the meaning to try to see if it is humorous, instead we rely on a combination of simple features to see if these are enough to detect humor.
Features such as word overlap with other jokes, presence of words common in jokes, ambiguity and word overlap with common idioms turn out
to be useful. When training and testing on equal amounts of jokes and sentences from the British National Corpus, a classification accuracy of 85\% is achieved.},
  doi = {10.1007/978-3-540-73400-0_59},
  author = {Sj{\"o}bergh, Jonas and Araki, Kenji},
  month = jul,
  year = {2007},
  pages = {469-476},
  file = {/Users/miriamamin/Documents/Zotero/storage/VH48ELWU/Sjöbergh_Araki_2007_Recognizing Humor Without Recognizing Meaning.pdf},
  annote = {the authors present an algorithm to classify sentences as one-liner joke or normal sentence. They only rely on superficial features like presence of typical joke words and phrases, presence of ambiguous words, dirty and human centered words (following mihalcevas study),rimes ,alliteration, wird repetition and idioms. They found out that the presence of joke words was the strongest prediction feature. They achieved 85\% accuracy (which is better than mihalceva)}
}

@article{radevHumorCollectiveDiscourse2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1506.08126},
  primaryClass = {cs, stat},
  title = {Humor in {{Collective Discourse}}: {{Unsupervised Funniness Detection}} in the {{New Yorker Cartoon Caption Contest}}},
  copyright = {RECOG},
  shorttitle = {Humor in {{Collective Discourse}}},
  abstract = {The New Yorker publishes a weekly captionless cartoon. More than 5,000 readers submit captions for it. The editors select three of them and ask the readers to pick the funniest one. We describe an experiment that compares a dozen automatic methods for selecting the funniest caption. We show that negative sentiment, human-centeredness, and lexical centrality most strongly match the funniest captions, followed by positive sentiment. These results are useful for understanding humor and also in the design of more engaging conversational agents in text and multimodal (vision+text) systems. As part of this work, a large set of cartoons and captions is being made available to the community.},
  journal = {arXiv:1506.08126 [cs, stat]},
  author = {Radev, Dragomir and Stent, Amanda and Tetreault, Joel and Pappu, Aasish and Iliakopoulou, Aikaterini and Chanfreau, Agustin and {de Juan}, Paloma and Vallmitjana, Jordi and Jaimes, Alejandro and Jha, Rahul and Mankoff, Bob},
  month = jun,
  year = {2015},
  keywords = {Computer Science - Computation and Language,Computer Science - Artificial Intelligence,Computer Science - Multimedia,Statistics - Machine Learning},
  file = {/Users/miriamamin/Documents/Zotero/storage/337D8GTJ/Radev et al_2015_Humor in Collective Discourse.pdf;/Users/miriamamin/Documents/Zotero/storage/UU6TPZ5R/1506.html},
  annote = {Comment: 10 pages, in submission}
}

@article{attardoScriptOppositionsLogical2002,
  title = {Script Oppositions and Logical Mechanisms: {{Modeling}} Incongruities and Their Resolutions},
  volume = {15},
  copyright = {1},
  shorttitle = {Script Oppositions and Logical Mechanisms},
  abstract = {The paper presents a survey of all known logical mechanisms (defined as the resolution of the incongruity of a joke) and a first attempt at a taxonomy. It then explores the possibility of representing several concept of the General Theory of Verbal Humor (GTVH) using first set theory and eventually graph theory when it becomes apparent that sets are insufficiently powerful to do so. Since script theory was originally formulated in terms of graphs, this (partial) formalization of the GTVH is of some interest, since it shows that at least some concepts of the GTVH can be represented formally. Specifically, we show (a) that script overlapping and opposition can be modeled using set and graph theory, and (b) that there exists a class of logical mechanisms that can be modeled using mappings between subgraphs.},
  journal = {Humor-international Journal of Humor Research - HUMOR},
  doi = {10.1515/humr.2002.004},
  author = {Attardo, Salvatore and Hempelmann, Christian and Di Maio, Sara},
  month = jan,
  year = {2002},
  pages = {3-46},
  file = {/Users/miriamamin/Documents/Zotero/storage/NYW8IQ63/Attardo et al_2002_Script oppositions and logical mechanisms.pdf}
}

@inproceedings{labutovHumorCircuitsSemantic2012,
  title = {Humor as {{Circuits}} in {{Semantic Networks}}},
  copyright = {X},
  abstract = {This work presents a first step to a general implementation of the Semantic-Script Theory of Humor (SSTH). Of the scarce amount of research in computational humor, no research had focused on humor generation beyond simple puns and punning riddles. We propose an algorithm for mining simple humorous scripts from a semantic network (ConceptNet) by specifically searching for dual scripts that jointly maximize overlap and incongruity metrics in line with Raskin's Semantic-Script Theory of Humor. Initial results show that a more relaxed constraint of this form is capable of generating humor of deeper semantic content than wordplay riddles. We evaluate the said metrics through a user-assessed quality of the generated two-liners.},
  booktitle = {Proceedings of {{ACL}} ({{Short Papers}})},
  author = {Labutov, Igor and Lipson, Hod},
  year = {2012},
  keywords = {Computational humor,Algorithm,Open Mind Common Sense,Script theory,Semantic network},
  file = {/Users/miriamamin/Documents/Zotero/storage/8Q6HN44Z/Labutov_Lipson_2012_Humor as Circuits in Semantic Networks.pdf},
  annote = {the author present the first implementation of the SSTH. they use ConceptNet as knowledge source for script generation. they assume that multiple paths between two nodes in the knowledge graph represent overlapping scripts (script compatibility in SSTH). in particular, they're looking for circuits in the semantic network (two paths p1 and p2 that have the same root A and the same end B). they're representing these circuits as question/answer jokes (2(?) QA-template with 5 slots to fill). They come up with some good jokes. from observation they state that it would be possible to produce more complex narratives from ConceptNet.}
}

@book{raskinScriptBasedSemanticOntological2017,
  title = {Script-{{Based Semantic}} and {{Ontological Semantic Theories}} of {{Humor}}},
  isbn = {978-1-138-84306-6 978-1-315-73116-2},
  abstract = {The Routledge Handbook of\&nbsp;Language and\&nbsp;Humor presents the first ever comprehensive, in-depth treatment of all the sub-fields of the linguistics of humor, broadly conceived as the intersection of the study of language and humor. The reader will find a thorough historical, terminological, and theoretical introduction to the field, as well as detailed treatments of the various approaches to language and humor. Deliberately comprehensive and wide-ranging, the handbook includes chapter-long treatments on the traditional topics covered by language and humor (e.g., teasing, laughter, irony, psycholinguistics, discourse analysis, the major linguistic theories of humor, translation) but also cutting-edge treatments of internet humor, cognitive linguistics, relevance theoretic, and corpus-assisted models of language and humor. Some chapters, such as the variationist sociolinguistcs, stylistics, and politeness are the first-ever syntheses of that particular subfield. Clusters of related chapters, such as conversation analysis, discourse analysis and corpus-assisted analysis allow multiple perspectives on complex trans-disciplinary phenomena. This handbook is an indispensable reference work for all researchers interested in the interplay of language and humor, within linguistics, broadly conceived, but also in neighboring disciplines such as literary studies, psychology, sociology, anthropology, etc. The authors are among the most distinguished scholars in their fields.},
  language = {en},
  publisher = {{Routledge Handbooks Online}},
  doi = {10.4324/9781315731162.ch9},
  author = {Raskin, Victor},
  month = feb,
  year = {2017},
  file = {/Users/miriamamin/Documents/Zotero/storage/TSU9TAZR/9781315731162.html}
}

@article{mihalceaLearningLaughAutomatically2006a,
  title = {Learning to {{Laugh}} (Automatically): {{Computational Models}} for {{Humor Recognition}}},
  volume = {22},
  copyright = {X},
  shorttitle = {Learning to {{Laugh}} (Automatically)},
  abstract = {Humor is one of the most interesting and puzzling aspects of human behavior. Despite the attention it has received in fields such as philosophy, linguistics, and psychology, there have been only few attempts to create computational models for humor recognition or generation. In this article, we bring empirical evidence that computational approaches can be successfully applied to the task of humor recognition. Through experiments performed on very large data sets, we show that automatic classification techniques can be effectively used to distinguish between humorous and non-humorous texts, with significant improvements observed over a priori known baselines.},
  journal = {Computational Intelligence},
  doi = {10.1111/j.1467-8640.2006.00278.x},
  author = {Mihalcea, Rada and Strapparava, Carlo},
  year = {2006},
  keywords = {Computational humor,Text corpus,Computational linguistics,Natural language,Baseline (configuration management),Commonsense knowledge (artificial intelligence),Computation,Computational model,Computer simulation,Document classification,Experiment,Finite-state machine,One-liner program,Semantic similarity},
  pages = {126-142},
  annote = {The authors use automatic classification algorithms to distinguish between humorous and non-humorous texts. For humorous data, they restrict their investigations on one-liners and use news titles, proverbs, sentences from the British national corpus and commonsense statements as unhumorous data. They use three methods for classification: 1. Using stylistic features, 2. Using content-based features, 3. Using a combination of stylistic and content based features.as stylistic features they use the presence of alliteration, antonomies and adult slang (referencing linguistic humor theories). For content-based learning they compare two classifiers: Na{\"i}ve Bayes and Support Vector Machine. They score 64\% accuracy for stylistic features, 78\% for Na{\"i}ve Bayes and 79\% vor SVM. For combined features, the score is even better. They also examined the most discriminative content-based features and suggest theat they can be useful for humor generation: human-centric vocabulary, negation, negative orientation, professional communities, human weakness.}
}

@article{taylorNaturalLanguageCognition2013a,
  title = {Natural Language Cognition of Humor by Humans and Computers: {{A}} Computational Semantic Approach},
  copyright = {T},
  shorttitle = {Natural Language Cognition of Humor by Humans and Computers},
  abstract = {This paper deals with a contribution of computational analysis of verbal humor to natural language cognition. After a brief introduction to the growing area of computational humor and of its roots in humor theories, it describes and compares the results of a human-subject and computer experiment. The specific interest is to compare how well the computer, equipped with the resources and methodologies of the Ontological Semantic Technology, a comprehensive meaning access approach to natural language processing, can model several aspects of the cognitive behaviors of humans processing jokes from the Internet.},
  journal = {2013 IEEE 12th International Conference on Cognitive Informatics and Cognitive Computing},
  doi = {10.1109/ICCI-CC.2013.6622227},
  author = {Taylor, Julia M. and Raskin, Victor},
  year = {2013},
  keywords = {Computational humor,Natural language processing,Cognition,Computation,Computer experiment,Information processing,Social computing,Theory},
  pages = {68-75},
  file = {/Users/miriamamin/Documents/Zotero/storage/3D6F5VF4/Taylor_Raskin_2013_Natural language cognition of humor by humans and computers.pdf},
  annote = {The author just ignores all approaches to CH that do nt consider humor theory. their research is very hard to understand but i think they did the follwoing: they gave test persons dofferent versions of a joke and asked them whch keywords they would use to search for a similar joke in google. then they made a very complex metalanguage and graph representation of the joke using their ontological semantic technology and retrieved the keywords from there. then they compared the overlap between the human and he computers keywords. in the end they said that the numbers are insufficient to draw any statistically significant conclusion. to be honest, for me it looks like thir using an overcomplex theory/technology to do something computer science algorithms could do more efficient (key word extraction)}
}

@inproceedings{wenOMGURFunny2015,
  title = {{{OMG UR Funny}}! {{Computer}}-{{Aided Humor}} with an {{Application}} to {{Chat}}},
  copyright = {X GENER},
  abstract = {In this paper we explore Computer-Aided Humor (CAH), where a computer and a human collaborate to be humorous. CAH systems support people's natural desire to be funny by helping them express their own idiosyncratic sense of humor. Artificial intelligence research has tried for years to create systems that are funny, but found the problem to be extremely hard. We show that by combining the strengths of a computer and a human, CAH can foster humor better than either alone. We present CAHOOTS, an online chat system that suggests humorous images to its users to include in the conversation. We compare CAHOOTS to a regular chat system, and to a system that automatically inserts funny images using an artificial humor-bot. Users report that CAHOOTS made their conversations more enjoyable and funny, and helped them to express their personal senses of humor. Computer-Aided Humor offers an example of how systems can algorithmically augment human intelligence to create rich, creative experiences.},
  booktitle = {{{ICCC}}},
  author = {Wen, Miaomiao and Baym, Nancy and Tamuz, Omer and Teevan, Jaime and Dumais, Susan T. and Kalai, Adam Tauman},
  year = {2015},
  keywords = {Algorithm,Artificial intelligence,Experience,Online chat,Ur; Ur/Web},
  file = {/Users/miriamamin/Documents/Zotero/storage/Q6PPKAB6/Wen et al_2015_OMG UR Funny.pdf},
  annote = {The authors present a system for computer-aided humor (CAH). the systems suggets different funny images according to the keywords identified from the last three utterances in a chat. the user can pick one image to post it to the chat. it uses different types, among others: emojis and reaction gifs, images from bing image search, memes. to retrieve the funny images they perform bing searches of the form "funny" + keywords. the memes are generated by using the last utterance as the caption for a popular meme template. the template is chosen by classifier trained to find the most suitable template based on the keywords. the choice of the images from which the user can select is based on a ranking determined by a reinformcement learning algorithm. they authors evaluate the CAH-system against a plain chat without images and a system that automatoically posts the top ramked image (rather than letting the user choose).

the authors tested their system with mechanical turk workers, who reported, among other things how funny the conversazion was. they found out, that users had most fun using the image-suggestian system, followed by the automatical choice system.}
}

@misc{dawnordoom-purdueuniversityWhatCanWe,
  title = {What {{Can We Learn From Computers}} ({{NOT}}) {{Understanding Humor}} - {{Julia Taylor Rayz}}},
  author = {{Dawn or Doom - Purdue University}}
}

@misc{TheoryOfRedditWhyDoes,
  title = {R/{{TheoryOfReddit}} - {{Why}} Does r/Jokes Lean More towards "Boomer"-Style Jokes?},
  abstract = {225 votes and 47 comments so far on Reddit},
  language = {en},
  journal = {reddit},
  howpublished = {https://www.reddit.com/r/TheoryOfReddit/comments/c2pklf/why\_does\_rjokes\_lean\_more\_towards\_boomerstyle/},
  file = {/Users/miriamamin/Documents/Zotero/storage/W8EKC89F/why_does_rjokes_lean_more_towards_boomerstyle.html}
}

@inproceedings{mihalceaMakingComputersLaugh2005,
  title = {Making {{Computers Laugh}}: {{Investigations}} in {{Automatic Humor Recognition}}},
  copyright = {RECOG},
  shorttitle = {Making {{Computers Laugh}}},
  language = {en-us},
  booktitle = {Proceedings of {{Human Language Technology Conference}} and {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Mihalcea, Rada and Strapparava, Carlo},
  month = oct,
  year = {2005},
  pages = {531-538},
  file = {/Users/miriamamin/Documents/Zotero/storage/A6VCQPD4/Mihalcea_Strapparava_2005_Making Computers Laugh.pdf;/Users/miriamamin/Documents/Zotero/storage/8AIXA4IZ/H05-1067.html}
}

@book{nirenburgOntologicalSemantics2004,
  title = {Ontological {{Semantics}}},
  isbn = {978-0-262-14086-7},
  author = {Nirenburg, Sergei and Raskin, Victor},
  month = jan,
  year = {2004},
  file = {/Users/miriamamin/Documents/Zotero/storage/7LWMM7V5/Nirenburg_Raskin_2004_Ontological Semantics.pdf}
}

@misc{suslovHowRealize2007,
  title = {How to Realize},
  abstract = {Computer model of a ''sense of humour'' suggested previously [1 \textendash{} 3] is raised to the level of a realistic algorithm.},
  language = {en},
  journal = {undefined},
  howpublished = {/paper/How-to-realize-\%22a-sense-of-humour\%22-in-computers-Suslov/aa29ccdf0aac4450359517952897c445020a6947},
  author = {Suslov, I. M.},
  year = {2007},
  file = {/Users/miriamamin/Documents/Zotero/storage/R4MNKHNU/aa29ccdf0aac4450359517952897c445020a6947.html}
}

@article{hempelmannFormalHumorLogic2012,
  title = {Formal Humor Logic beyond Second-Most Plausible Reasoning},
  copyright = {T},
  abstract = {Humor employs an essential false logic which masks the incongruity of two central meanings that are brought into overlap. Formalizing this false logic - if it exists, exists intersubjectively, and is indeed essential for humor - to a degree that is sufficient for computational detection and generation of humor has been a vexing problem for computational humor research. This paper will outline several such logics, in addition to the default of reasoning in a way that is one degree more implausibly than the most common-sense logic that can connect two meanings. The results are not least influenced by a pilot study asking participants to explain different types of jokes. Copyright \textcopyright{} 2012, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
  journal = {AAAI Fall Symposium - Technical Report},
  author = {Hempelmann, Christian},
  month = jan,
  year = {2012},
  pages = {14-17},
  file = {/Users/miriamamin/Documents/Zotero/storage/HT56YU93/Hempelmann_2012_Formal humor logic beyond second-most plausible reasoning.pdf}
}

@inproceedings{oaksPossibleGenerativeApproach2012,
  title = {On a {{Possible Generative Approach}} to {{Structurally Ambiguous Humor}}},
  copyright = {MODEL 1},
  booktitle = {{{AAAI Fall Symposium}}: {{Artificial Intelligence}} of {{Humor}}},
  author = {Oaks, Dallin D.},
  year = {2012},
  file = {/Users/miriamamin/Documents/Zotero/storage/2HDUJRHS/Oaks - On a Possible Generative Approach to Structurally .pdf}
}

@article{simonComputationalHumorPromises2012,
  title = {Computational Humor: {{Promises}} and Pitfalls},
  copyright = {T},
  shorttitle = {Computational Humor},
  abstract = {Creating an AI device that is both easy to control and comfortable to interact with will likely require algorithms for accurately interpreting conversational speech. Homonyms and homophones represent a particular challenge in this regard, thus the study of puns and other forms of humorous wordplay can be informative. Moving beyond the simple resolution of word uncertainty to an understanding of humor is, however, problematic. The Mutual Vulnerability Theory of Laughter identifies numerous variables involved in our differentiating humorous and nonhumorous stimuli. These include available information, type and degree of relationship with others, personal history, culture, and even mood. It also suggests there will be potential liabilities for AI users, retailers, and developers resulting from even successful attempts to identify, respond to, and create humor, as all require the highlighting of vulnerabilities. Copyright \textcopyright{} 2012, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
  journal = {AAAI Fall Symposium - Technical Report},
  author = {Simon, J.C.},
  month = jan,
  year = {2012},
  pages = {84-87},
  file = {/Users/miriamamin/Documents/Zotero/storage/2YJVQGEA/Simon_2012_Computational humor.pdf}
}

@misc{PDFJokesHave,
  title = {[{{PDF}}] {{Do Jokes Have}} to {{Be Funny}}: {{Analysis}} of 50 "{{Theoretically Jokes}}" - {{Semantic Scholar}}},
  howpublished = {https://www.semanticscholar.org/paper/Do-Jokes-Have-to-Be-Funny\%3A-Analysis-of-50-Jokes\%22-Taylor/a41572a651f0bcac1450693778756c945db9e90c},
  file = {/Users/miriamamin/Documents/Zotero/storage/XNICAWYK/a41572a651f0bcac1450693778756c945db9e90c.html}
}

@inproceedings{taylorJokesHaveBe2012,
  title = {Do {{Jokes Have}} to {{Be Funny}}: {{Analysis}} of 50 "{{Theoretically Jokes}}"},
  copyright = {T},
  shorttitle = {Do {{Jokes Have}} to {{Be Funny}}},
  abstract = {This talk will analyze responses to funniness of five versions of 10 different jokes. The responses of one of them will then be compared to theoretical analysis and representation of the same joke based on Script-based Semantics Theory of Humor, General Theory of Verbal Humor, and Ontological Semantic Theory of Humor.},
  booktitle = {{{AAAI Fall Symposium}}: {{Artificial Intelligence}} of {{Humor}}},
  author = {Taylor, Julia M.},
  year = {2012},
  file = {/Users/miriamamin/Documents/Zotero/storage/7DDKZ9B5/Taylor_2012_Do Jokes Have to Be Funny.pdf}
}

@article{m.suslovHowRealizeSense2007,
  title = {How to Realize "a Sense of Humour" in Computers ?},
  abstract = {Computer model of a "sense of humour" suggested previously [arXiv:0711.2058, 0711.2061, 0711.2270] is raised to the level of a realistic algorithm.},
  author = {M. Suslov, I},
  month = dec,
  year = {2007}
}

@article{suslovHowRealizeSense,
  title = {How to Realize ''a Sense of Humour'' in Computers ?},
  copyright = {MODEL},
  abstract = {Computer model of a ''sense of humour'' suggested previously [1 \textendash{} 3] is raised to the level of a realistic algorithm.},
  language = {en},
  author = {Suslov, I M},
  pages = {12},
  file = {/Users/miriamamin/Documents/Zotero/storage/HBH6TDRV/Suslov - How to realize ”a sense of humour” in computers .PDF}
}

@article{oaksPossibleGenerativeApproach,
  title = {On a {{Possible Generative Approach}} to {{Structurally Ambiguous Humor}}},
  copyright = {M 1},
  abstract = {This paper outlines a generative approach for creating structurally ambiguous humor. The approach builds upon a lexical set that has been derived through a script associated with a given situation. Each of these lexical entries would also contain one or more specified SAPs (``structural ambiguity potentials''), which serve to match the lexical item to designated formulas for creating structural ambiguity. As part of the approach, an additional phonological and morphological component would serve to generate additional lexical forms with their own SAPs and related formulas. The paper also illustrates how the resulting structural ambiguities can then be systematically integrated into a humorous context.},
  language = {en},
  author = {Oaks, Dallin D},
  pages = {5}
}

@article{suslovComputerModelSense2007,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {0711.2061},
  primaryClass = {cs, q-bio},
  title = {Computer {{Model}} of a "{{Sense}} of {{Humour}}". {{II}}. {{Realization}} in {{Neural Networks}}},
  copyright = {MODEL},
  abstract = {The computer realization of a "sense of humour" requires the creation of an algorithm for solving the "linguistic problem", i.e. the problem of recognizing a continuous sequence of polysemantic images. Such algorithm may be realized in the Hopfield model of a neural network after its proper modification.},
  journal = {arXiv:0711.2061 [cs, q-bio]},
  author = {Suslov, I. M.},
  month = nov,
  year = {2007},
  keywords = {Computer Science - Artificial Intelligence,Quantitative Biology - Neurons and Cognition},
  file = {/Users/miriamamin/Documents/Zotero/storage/6UE2S46M/Suslov_2007_Computer Model of a Sense of Humour.pdf;/Users/miriamamin/Documents/Zotero/storage/4XF6FC2U/0711.html},
  annote = {Comment: 13 pages, 5 figures included; continuation of this series to appear}
}

@article{suslovComputerModelSense2007a,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {0711.2058},
  primaryClass = {cs, q-bio},
  title = {Computer {{Model}} of a "{{Sense}} of {{Humour}}". {{I}}. {{General Algorithm}}},
  copyright = {MODEL},
  abstract = {A computer model of a "sense of humour" is proposed. The humorous effect is interpreted as a specific malfunction in the course of information processing due to the need for the rapid deletion of the false version transmitted into consciousness. The biological function of a sense of humour consists in speeding up the bringing of information into consciousness and in fuller use of the resources of the brain.},
  journal = {arXiv:0711.2058 [cs, q-bio]},
  author = {Suslov, I. M.},
  month = nov,
  year = {2007},
  keywords = {Computer Science - Artificial Intelligence,Quantitative Biology - Neurons and Cognition},
  file = {/Users/miriamamin/Documents/Zotero/storage/MPBI4GTL/Suslov_2007_Computer Model of a Sense of Humour.pdf;/Users/miriamamin/Documents/Zotero/storage/WBPD8ZRE/0711.html},
  annote = {Comment: 10 pages, 3 figures included; continuation of this series to appear}
}

@inproceedings{mihalceaMultidisciplinaryFacetsResearch2007,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {The {{Multidisciplinary Facets}} of {{Research}} on {{Humour}}},
  isbn = {978-3-540-73400-0},
  abstract = {Humour is one of the most interesting and puzzling aspects of human behaviour, and it has been rightfully argued that it plays an important role in an individual's development, as well as in interpersonal communication. Research on this topic has received a significant amount of attention from fields as diverse as linguistics, philosophy, psychology and sociology, and recent years have also seen attempts to build computational models for humour generation and recognition.},
  language = {en},
  booktitle = {Applications of {{Fuzzy Sets Theory}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Mihalcea, Rada},
  editor = {Masulli, Francesco and Mitra, Sushmita and Pasi, Gabriella},
  year = {2007},
  keywords = {Computational Linguistics,Humour Appreciation,Knowledge Resource,Linguistic Theory,Syntactic Ambiguity},
  pages = {412-421}
}

@inproceedings{augelloHumoristBotBringing2008,
  title = {Humorist {{Bot}}: {{Bringing Computational Humour}} in a {{Chat}}-{{Bot System}}},
  copyright = {X GENER},
  shorttitle = {Humorist {{Bot}}},
  abstract = {A conversational agent, capable to have a ldquosense of humourrdquo is presented. The agent can both generate humorous sentences and recognize humoristic expressions introduced by the user during the dialogue. Humorist Bot makes use of well founded techniques of computational humor and it has been implemented using the ALICE framework embedded into an Yahoo! Messenger client. It includes also an avatar that changes the face expression according to humoristic content of the dialogue.},
  booktitle = {2008 {{International Conference}} on {{Complex}}, {{Intelligent}} and {{Software Intensive Systems}}},
  doi = {10.1109/CISIS.2008.117},
  author = {Augello, A. and Saccone, G. and Gaglio, S. and Pilato, G.},
  month = mar,
  year = {2008},
  keywords = {Feature extraction,Computers,ALICE framework,Avatars,chat-bot system,Computational Humor,computational humour,conversational agent,Conversational Agents,electronic messaging,Face,face expression,Humorist Bot,humoristic expressions,humorous sentences,Knowledge based systems,Pattern matching,Text recognition,user interfaces,Yahoo! Messenger client},
  pages = {703-708},
  file = {/Users/miriamamin/Documents/Zotero/storage/CITEQFYB/Augello et al_2008_Humorist Bot.pdf;/Users/miriamamin/Documents/Zotero/storage/H9GRE2X5/4606756.html},
  annote = {The authors present a AIML-based chatbot that detects a user's use of humor and also tells jokes on demand. humor recognition is based on the stilistic and content based features proposed by Mihalcea and Strapparava. They only evaluate alliteration, antonomy and adult slang and yield 66\% accuracy. It does not become clear how the features are processed. The humor 'generation' as stated in the abstract is a pattern-based selection of jokes according to a topic of the user's choice.}
}

@inproceedings{reyesAnalysisImpactAmbiguity2009,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {An {{Analysis}} of the {{Impact}} of {{Ambiguity}} on {{Automatic Humour Recognition}}},
  copyright = {RECOG},
  isbn = {978-3-642-04208-9},
  abstract = {One of the most amazing characteristics that defines the human being is humour. Its analysis implies a set of subjective and fuzzy factors, such as the linguistic, psychological or sociological variables that produce it. This is one of the reasons why its automatic processing seems to be not straightforward. However, recent researches in the Natural Language Processing area have shown that humour can automatically be generated and recognised with success. On the basis of those achievements, in this study we present the experiments we have carried out on a collection of Italian texts in order to investigate how to characterize humour through the study of the ambiguity, especially with respect to morphosyntactic and syntactic ambiguity. The results we have obtained show that it is possible to differentiate humorous from non humorous data through features like perplexity or sentence complexity.},
  language = {en},
  booktitle = {Text, {{Speech}} and {{Dialogue}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Reyes, Antonio and Buscaldi, Davide and Rosso, Paolo},
  editor = {Matou{\v s}ek, V{\'a}clav and Mautner, Pavel},
  year = {2009},
  keywords = {Syntactic Ambiguity,Phonological Similarity,Recent Research Work,Semantic Ambiguity,Sentence Complexity},
  pages = {162-169}
}

@inproceedings{reyesImpactSemanticMorphosyntactic2010,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {The {{Impact}} of {{Semantic}} and {{Morphosyntactic Ambiguity}} on {{Automatic Humour Recognition}}},
  copyright = {RECOG},
  isbn = {978-3-642-12550-8},
  abstract = {Humour is one of the most amazing characteristics that defines us as human beings and social entities. Its study supposes a deep insight into several areas such as linguistics, psychology or philosophy. From the Natural Language Processing (NLP) perspective, recent researches have shown that humour can be automatically generated and recognized with some success. In this work we present a study carried out on a collection of English texts in order to investigate whether or not semantic and morphosyntactic ambiguities may be employed as features in the automatic humour recognition task. The results we have obtained show that it is possible to discriminate humorous from non humorous sentences through features like perplexity or sense dispersion.},
  language = {en},
  booktitle = {Natural {{Language Processing}} and {{Information Systems}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Reyes, Antonio and Buscaldi, Davide and Rosso, Paolo},
  editor = {Horacek, Helmut and M{\'e}tais, Elisabeth and Mu{\~n}oz, Rafael and Wolska, Magdalena},
  year = {2010},
  keywords = {Phonological Similarity,Sentence Complexity,Idiomatic Expression,Natural Language Processing,Syntactic Structure},
  pages = {130-141}
}

@inproceedings{reyesAnalysisImpactAmbiguity2009a,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {An {{Analysis}} of the {{Impact}} of {{Ambiguity}} on {{Automatic Humour Recognition}}},
  isbn = {978-3-642-04208-9},
  abstract = {One of the most amazing characteristics that defines the human being is humour. Its analysis implies a set of subjective and fuzzy factors, such as the linguistic, psychological or sociological variables that produce it. This is one of the reasons why its automatic processing seems to be not straightforward. However, recent researches in the Natural Language Processing area have shown that humour can automatically be generated and recognised with success. On the basis of those achievements, in this study we present the experiments we have carried out on a collection of Italian texts in order to investigate how to characterize humour through the study of the ambiguity, especially with respect to morphosyntactic and syntactic ambiguity. The results we have obtained show that it is possible to differentiate humorous from non humorous data through features like perplexity or sentence complexity.},
  language = {en},
  booktitle = {Text, {{Speech}} and {{Dialogue}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Reyes, Antonio and Buscaldi, Davide and Rosso, Paolo},
  editor = {Matou{\v s}ek, V{\'a}clav and Mautner, Pavel},
  year = {2009},
  keywords = {Syntactic Ambiguity,Phonological Similarity,Recent Research Work,Semantic Ambiguity,Sentence Complexity},
  pages = {162-169}
}

@article{dynelJokeTypesConversational2009,
  title = {Beyond a {{Joke}}: {{Types}} of {{Conversational Humour}}},
  volume = {3},
  copyright = {\textcopyright{} 2009 The Author. Journal Compilation \textcopyright{} 2009 Blackwell Publishing Ltd},
  issn = {1749-818X},
  shorttitle = {Beyond a {{Joke}}},
  abstract = {The main objective of this article is to list and briefly characterise several semantic and pragmatic types of verbal humour, primarily those which cannot be reduced to (canned) jokes. First of all, a distinction is drawn between jokes and conversational humour, an umbrella term covering a variety of semantic and pragmatic types of humour, which recur in interpersonal communication, whether real-life (everyday conversations or TV programmes) or fictional (film and book dialogues). On a different axis representing formal structure, stylistic figures are distinguished, such as irony, puns and allusions.},
  language = {en},
  number = {5},
  journal = {Language and Linguistics Compass},
  doi = {10.1111/j.1749-818X.2009.00152.x},
  author = {Dynel, Marta},
  year = {2009},
  pages = {1284-1299},
  file = {/Users/miriamamin/Documents/Zotero/storage/4Y6WH333/Dynel_2009_Beyond a Joke.pdf;/Users/miriamamin/Documents/Zotero/storage/XAXCHW6X/j.1749-818X.2009.00152.html}
}

@inproceedings{reyesEvaluatingHumourFeatures2010,
  title = {Evaluating {{Humour Features}} on {{Web Comments}}.},
  copyright = {X ANALY 1},
  abstract = {Research on automatic humor recognition has developed several features which discriminate funny text from ordinary text. The features have been demonstrated to work well when classifying the funniness of single sentences up to entire blogs. In this paper we evaluate whether these features can be applied to the important text type of Web comments as well. Our experiments are preliminary but nonetheless large-scale: on a corpus of 600000 Web comments we investigate the classification accuracy of naive Bayes classifiers, decision trees, and support vector machines.},
  author = {Reyes, Antonio and Potthast, Martin and Rosso, Paolo and Stein, Benno},
  month = jan,
  year = {2010},
  file = {/Users/miriamamin/Documents/Zotero/storage/9IQBYYUA/Reyes et al_2010_Evaluating Humour Features on Web Comments.pdf},
  annote = {the authors present a classifier to distinguish between humorous and non-humorous comments on a website. to do this, they use the humor features that among others Mihalcea and Strapparava or Mihalcea and Pulman proposed. As classifier technologies they tried naive Bayes, decision trees and support vector machines. They found out, that it was not possible to successfully distinguish between humorous and non-humorous comments, while Mihalcea et al showed that ut was possible to distinguish one-liners from news headlines. as reason they mention, that comments, regardless of funny or not are too similar and thus not feasible as training data.}
}

@inproceedings{mihalceaComputationalModelsIncongruity2010,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Computational {{Models}} for {{Incongruity Detection}} in {{Humour}}},
  copyright = {RECOG 1},
  isbn = {978-3-642-12116-6},
  abstract = {Incongruity resolution is one of the most widely accepted theories of humour, suggesting that humour is due to the mixing of two disparate interpretation frames in one statement. In this paper, we explore several computational models for incongruity resolution. We introduce a new data set, consisting of a series of `set-ups' (preparations for a punch line), each of them followed by four possible coherent continuations out of which only one has a comic effect. Using this data set, we redefine the task as the automatic identification of the humorous punch line among all the plausible endings. We explore several measures of semantic relatedness, along with a number of joke-specific features, and try to understand their appropriateness as computational models for incongruity detection.},
  language = {en},
  booktitle = {Computational {{Linguistics}} and {{Intelligent Text Processing}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Mihalcea, Rada and Strapparava, Carlo and Pulman, Stephen},
  editor = {Gelbukh, Alexander},
  year = {2010},
  keywords = {Latent Semantic Analysis,Semantic Relatedness,Semantic Similarity,Singular Value Decomposition,Word Sense Disambiguation},
  pages = {364-374}
}

@inproceedings{barbieriAutomaticDetectionIrony2014,
  title = {Automatic {{Detection}} of {{Irony}} and {{Humour}} in {{Twitter}}},
  copyright = {RECOG},
  abstract = {Irony and humour are just two of many forms of figurative language. Approaches to identify in vast volumes of data such as the internet humorous or ironic statements is important not only from a theoretical view point but also for their potential applicability in social networks or human-computer interactive systems. In this study we investigate the automatic detection of irony and humour in social networks such as Twitter casting it as a classification problem. We propose a rich set of features for text interpretation and representation to train classification procedures. In cross-domain classification experiments our model achieves and improves state-of-the-art},
  booktitle = {{{ICCC}}},
  author = {Barbieri, Francesco and Saggion, Horacio},
  year = {2014},
  keywords = {Text corpus,Experiment,Social network},
  file = {/Users/miriamamin/Documents/Zotero/storage/HMPT5XPS/Barbieri_Saggion_2014_Automatic Detection of Irony and Humour in Twitter.pdf}
}

@article{kadriCyberneticsHumourIntroducing2015,
  title = {The Cybernetics of Humour: Introducing Signature Analysis to Humour Research},
  volume = {44},
  copyright = {MODEL},
  issn = {0368-492X},
  shorttitle = {The Cybernetics of Humour},
  number = {8/9},
  journal = {Kybernetes},
  doi = {10.1108/K-11-2014-0238},
  author = {Kadri, Faisal L},
  month = sep,
  year = {2015},
  keywords = {Artificial intelligence,Behaviour,Cybernetics,Experimental psychology,Mathematical modelling},
  pages = {1274-1283},
  file = {/Users/miriamamin/Documents/Zotero/storage/T28NK3ZX/K-11-2014-0238.html}
}

@article{shahMachineHumourExamples2017,
  title = {Machine Humour: Examples from {{Turing}} Test Experiments},
  volume = {32},
  copyright = {0 ANALY},
  issn = {1435-5655},
  shorttitle = {Machine Humour},
  abstract = {In this paper, we look at the possibility of a machine having a sense of humour. In particular, we focus on actual machine utterances in Turing test discourses. In doing so, we do not consider the Turing test in depth and what this might mean for humanity, rather we merely look at cases in conversations when the output from a machine can be considered to be humorous. We link such outpourings with Turing's ``arguments from various disabilities'' used against the concept of a machine being able to think, taken from his seminal work of 1950. Finally we consider the role that humour might play in adding to the deception, integral to the Turing test, that a machine in practice appears to be a human.},
  language = {en},
  number = {4},
  journal = {AI \& SOCIETY},
  doi = {10.1007/s00146-016-0669-0},
  author = {Shah, Huma and Warwick, Kevin},
  month = nov,
  year = {2017},
  keywords = {Natural language,Chatbots,Deception detection,Machine humour,Turing’s imitation game},
  pages = {553-561},
  file = {/Users/miriamamin/Documents/Zotero/storage/TZ9LCBHB/Shah_Warwick_2017_Machine humour.pdf}
}

@inproceedings{cattleRecognizingHumourUsing2018,
  title = {Recognizing {{Humour}} Using {{Word Associations}} and {{Humour Anchor Extraction}}},
  copyright = {RECOG},
  language = {en-us},
  booktitle = {Proceedings of the 27th {{International Conference}} on {{Computational Linguistics}}},
  author = {Cattle, Andrew and Ma, Xiaojuan},
  month = aug,
  year = {2018},
  pages = {1849-1858},
  file = {/Users/miriamamin/Documents/Zotero/storage/VYZGGHJ6/Cattle_Ma_2018_Recognizing Humour using Word Associations and Humour Anchor Extraction.pdf;/Users/miriamamin/Documents/Zotero/storage/V7EFVA5V/C18-1157.html}
}

@inproceedings{venourComputationalModelLexical2013,
  title = {A Computational Model of Lexical Incongruity in Humorous Text},
  author = {Venour, Chris},
  year = {2013},
  keywords = {Computational model}
}

@inproceedings{taylorSimulationSemanticGeneration2016,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Towards {{Simulation}} of {{Semantic Generation}} and {{Detection}} of {{Humorous Response}}},
  copyright = {GENER},
  isbn = {978-3-319-39862-4},
  abstract = {This paper explores headlines that are so obvious that they are somehow funny. We develop a model that uses ontological representation as the basis for retrieving such obvious information. Using this model, we generate jokes in a narrow domain of fluid dynamics.},
  language = {en},
  booktitle = {Distributed, {{Ambient}} and {{Pervasive Interactions}}},
  publisher = {{Springer International Publishing}},
  author = {Taylor, Julia M. and Rayz, Vitaliy L.},
  editor = {Streitz, Norbert and Markopoulos, Panos},
  year = {2016},
  keywords = {Computational humor,Ontology,Restricted joke modeling},
  pages = {362-369},
  file = {/Users/miriamamin/Documents/Zotero/storage/HPWSRAXT/Taylor_Rayz_2016_Towards Simulation of Semantic Generation and Detection of Humorous Response.pdf}
}

@article{valituttiComputationalGenerationDissection2016,
  title = {Computational Generation and Dissection of Lexical Replacement Humor*},
  volume = {22},
  copyright = {X GENER},
  issn = {1351-3249, 1469-8110},
  abstract = {We consider automated generation of humorous texts by substitution of a single word in a given short text. In this setting, several factors that potentially contribute to the funniness of texts can be integrated into a unified framework as constraints on the lexical substitution. We discuss three types of such constraints: formal constraints concerning the similarity of sounds or spellings between the original word and the substitute, semantic or connotational constraints requiring the substitute to be a taboo word, and contextual constraints concerning the position and context of the replacement. Empirical evidence from extensive user studies using real SMSs as the corpus indicates that taboo constraints are statistically very effective, and so is a constraint requiring that the substitution takes place at the end of the text even though the effect is smaller. The effects of individual constraints are largely cumulative. In addition, connotational taboo words and word position have a strong interaction.},
  language = {en},
  number = {5},
  journal = {Natural Language Engineering},
  doi = {10.1017/S1351324915000145},
  author = {Valitutti, Alessandro and Doucet, Antoine and Toivanen, Jukka M. and Toivonen, Hannu},
  month = sep,
  year = {2016},
  pages = {727-749},
  file = {/Users/miriamamin/Documents/Zotero/storage/WAJJRX8Q/Valitutti et al_2016_Computational generation and dissection of lexical replacement humor.pdf;/Users/miriamamin/Documents/Zotero/storage/EJ2KF6MH/FD150594F61E0289AAD07827AE343FE4.html},
  annote = {The authors generate humorous texts by substituting a single word in a given short text. the use sms~ messages as input texts to be modified. they classify different kind of substitution: by form (similarity in spelling or sound), by semantic (taboo connotation) and by context (position of the replacement close to the end of the text). they presented different combinations of these substitutions to test persons from a crowdsourcing platform. examples: form+connotation: "Hi, come back homo now" (home/homo), form\&context: "Tmr u going to school? I meet u in pool?" (school/pool), "Can sell e book.how much u wan smell?" (sell/smell). they use wordnet and cmu pronounciation dictionary for the form substitution, a collection of taboo words from idfferent websites for the semantic and google n-grams for the context. they showed that each of these substitutuon classes contributes to the total humor of the phrase by a different weight and that the humorous effect cumulated. connnotatonal words and replacement at the end of the phrase produced the highest effect.}
}

@inproceedings{chenPredictingAudienceLaughter2017,
  address = {{Copenhagen, Denmark}},
  title = {Predicting {{Audience}}'s {{Laughter Using Convolutional Neural Network}}},
  copyright = {PREDICT},
  abstract = {For the purpose of automatically evaluating speakers' humor usage, we build a presentation corpus containing humorous utterances based on TED talks. Compared to previous data resources supporting humor recognition research, ours has several advantages, including (a) both positive and negative instances coming from a homogeneous data set, (b) containing a large number of speakers, and (c) being open. Focusing on using lexical cues for humor recognition, we systematically compare a newly emerging text classification method based on Convolutional Neural Networks (CNNs) with a well-established conventional method using linguistic knowledge. The advantages of the CNN method are both getting higher detection accuracies and being able to learn essential features automatically.},
  booktitle = {Proceedings of the 12th {{BEA}}@{{EMNLP}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Chen, Lei and Lee, Chong MIn},
  year = {2017},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/miriamamin/Documents/Zotero/storage/D6J6N798/Chen_Lee_2017_Predicting Audience's Laughter Using Convolutional Neural Network.pdf;/Users/miriamamin/Documents/Zotero/storage/QL97L44A/1702.html},
  annote = {Comment: 5 pages, 1 figure}
}

@inproceedings{potashSemEval2017TaskHashtagWars2017,
  address = {{Vancouver, Canada}},
  title = {{{SemEval}}-2017 {{Task}} 6: \#{{HashtagWars}}: {{Learning}} a {{Sense}} of {{Humor}}},
  copyright = {RECOG},
  shorttitle = {{{SemEval}}-2017 {{Task}} 6},
  abstract = {This paper describes a new shared task for humor understanding that attempts to eschew the ubiquitous binary approach to humor detection and focus on comparative humor ranking instead. The task is based on a new dataset of funny tweets posted in response to shared hashtags, collected from the `Hashtag Wars' segment of the TV show @midnight. The results are evaluated in two subtasks that require the participants to generate either the correct pairwise comparisons of tweets (subtask A), or the correct ranking of the tweets (subtask B) in terms of how funny they are. 7 teams participated in subtask A, and 5 teams participated in subtask B. The best accuracy in subtask A was 0.675. The best (lowest) rank edit distance for subtask B was 0.872.},
  booktitle = {Proceedings of the 11th {{International Workshop}} on {{Semantic Evaluation}} ({{SemEval}}-2017)},
  publisher = {{Association for Computational Linguistics}},
  doi = {10.18653/v1/S17-2004},
  author = {Potash, Peter and Romanov, Alexey and Rumshisky, Anna},
  month = aug,
  year = {2017},
  pages = {49--57},
  file = {/Users/miriamamin/Documents/Zotero/storage/FL8G5XH4/Potash et al_2017_SemEval-2017 Task 6.pdf}
}

@inproceedings{mahajanSVNITSemEval20172017,
  address = {{Vancouver, Canada}},
  title = {{{SVNIT}} @ {{SemEval}} 2017 {{Task}}-6: {{Learning}} a {{Sense}} of {{Humor Using Supervised Approach}}},
  copyright = {RECOG},
  shorttitle = {{{SVNIT}} @ {{SemEval}} 2017 {{Task}}-6},
  abstract = {This paper describes the system devel-oped for SemEval 2017 task 6: \#HashTagWars -Learning a Sense of Hu-mor. Learning to recognize sense of hu-mor is the important task for language understanding applications. Different set of features based on frequency of words, structure of tweets and semantics are used in this system to identify the presence of humor in tweets. Supervised machine learning approaches, Multilayer percep-tron and Na{\"i}ve Bayes are used to classify the tweets in to three level of sense of humor. For given Hashtag, the system finds the funniest tweet and predicts the amount of funniness of all the other tweets. In official submitted runs, we have achieved 0.506 accuracy using mul-tilayer perceptron in subtask-A and 0.938 distance in subtask-B. Using Na{\"i}ve bayes in subtask-B, the system achieved 0.949 distance. Apart from official runs, this system have scored 0.751 accuracy in subtask-A using SVM. But still there is a wide room for improvement in system.},
  booktitle = {Proceedings of the 11th {{International Workshop}} on {{Semantic Evaluation}} ({{SemEval}}-2017)},
  publisher = {{Association for Computational Linguistics}},
  doi = {10.18653/v1/S17-2069},
  author = {Mahajan, Rutal and Zaveri, Mukesh},
  month = aug,
  year = {2017},
  pages = {411--415},
  file = {/Users/miriamamin/Documents/Zotero/storage/2ISZKZBM/Mahajan_Zaveri_2017_SVNIT @ SemEval 2017 Task-6.pdf}
}

@inproceedings{zhangInvestigationsAutomaticHumor2017,
  title = {Investigations in {{Automatic Humor Recognition}}},
  volume = {1},
  copyright = {RECOG},
  abstract = {Humor is an essential but important part of personal communication. It is a great challenge to understand the mechanism of humor in human language and create computational models to recognize and generate humor. In this paper, we define a new concept called Contextual Knowledge. Based on this concept, we design a sample but effective feature which alleviates the lack of contextual knowledge in humor recognition. Furthermore, humor belongs to human cognition, so we design two features from a human centered perspective to capture the emotionality and subjectivity in humorous texts. Experimental results prove the validity of the proposed features. And the accuracy of humor recognition has improved substantially.},
  booktitle = {2017 10th {{International Symposium}} on {{Computational Intelligence}} and {{Design}} ({{ISCID}})},
  doi = {10.1109/ISCID.2017.160},
  author = {Zhang, D. and Song, W. and Liu, L. and Du, C. and Zhao, X.},
  month = dec,
  year = {2017},
  keywords = {Feature extraction,Semantics,humor recognition,Computational modeling,natural language processing,cognition,Cognition,Computers,Text recognition,affective polarity,automatic humor recognition,contextual knowledge,contextual konwledge,emotionality,human centered perspective,human cognition,human language,humor-related features,humorous texts,personal communication,Pragmatics,subjectivity},
  pages = {272-275},
  file = {/Users/miriamamin/Documents/Zotero/storage/7UY2G3EQ/8275768.html}
}

@inproceedings{smigajVisualizingIncongruityResolution2017,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Visualizing {{Incongruity}} and {{Resolution}}: {{Visual Data Mining Strategies}} for {{Modeling Sequential Humor Containing Shifts}} of {{Interpretation}}},
  copyright = {RECOG},
  isbn = {978-3-319-58697-7},
  shorttitle = {Visualizing {{Incongruity}} and {{Resolution}}},
  abstract = {The goal of this paper is to investigate the use of visualization as an approach to modeling humor within text. In particular, we developed algorithmic and automated approaches to visualizing and detecting shifts in interpretation as intelligent agents parse meaning from garden path jokes. Garden path jokes can occur when a reader's initial interpretation of an ambiguous text turns out to be incorrect, leading them down the wrong path to a semantic dead end. Given new information, semantic incongruities arise that require resolution, often triggering a humorous response. This is a work of visual text mining, that is visualizing texts in order to detect patterns and features associated with various text based phenomena such as humor. In this paper we describe three successful approaches to text visualization conducive to identifying distinguishing features given humorous and non humorous texts. These are the use of paired collocated coordinates, heat maps, and two-dimensional Boolean plots. The proposed methodology and tools offer a new approach to testing and generating hypotheses related to theories of humor as well as other phenomena involving incongruity-resolution and shifts in interpretation including non-verbal humor.},
  language = {en},
  booktitle = {Distributed, {{Ambient}} and {{Pervasive Interactions}}},
  publisher = {{Springer International Publishing}},
  author = {Smigaj, Andrew and Kovalerchuk, Boris},
  editor = {Streitz, Norbert and Markopoulos, Panos},
  year = {2017},
  keywords = {Computational humor,Incongruity modeling,Natural language understanding,Visual data mining},
  pages = {660-674}
}

@inproceedings{moralesIdentifyingHumorReviews2017a,
  title = {Identifying {{Humor}} in {{Reviews}} Using {{Background Text Sources}}},
  copyright = {RECOG},
  language = {en-us},
  booktitle = {Proceedings of the 2017 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  doi = {10.18653/v1/D17-1051},
  author = {Morales, Alex and Zhai, ChengXiang},
  month = sep,
  year = {2017},
  pages = {492-501},
  file = {/Users/miriamamin/Documents/Zotero/storage/K38WB4FJ/Morales_Zhai_2017_Identifying Humor in Reviews using Background Text Sources.pdf;/Users/miriamamin/Documents/Zotero/storage/II7RKWBG/D17-1051.html}
}

@article{engelthalerHumorNorms9972017,
  title = {Humor Norms for 4,997 {{English}} Words},
  volume = {50},
  copyright = {DATA},
  abstract = {Humor ratings are provided for 4,997 English words collected from 821 participants using an online crowd-sourcing platform. Each participant rated 211 words on a scale from 1 (humorless) to 5 (humorous). To provide for comparisons across norms, words were chosen from a set common to a number of previously collected norms (e.g., arousal, valence, dominance, concreteness, age of acquisition, and reaction time). The complete dataset provides researchers with a list of humor ratings and includes information on gender, age, and educational differences. Results of analyses show that the ratings have reliability on a par with previous ratings and are not well predicted by existing norms.},
  journal = {Behavior Research Methods},
  doi = {10.3758/s13428-017-0930-6},
  author = {Engelthaler, Tomas and Hills, Thomas},
  month = jul,
  year = {2017},
  file = {/Users/miriamamin/Documents/Zotero/storage/P9MLX67U/Engelthaler_Hills_2017_Humor norms for 4,997 English words.pdf}
}

@article{yoshidaNeuralJokingMachine2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1805.11850},
  primaryClass = {cs},
  title = {Neural {{Joking Machine}} : {{Humorous}} Image Captioning},
  copyright = {X GENER},
  shorttitle = {Neural {{Joking Machine}}},
  abstract = {What is an effective expression that draws laughter from human beings? In the present paper, in order to consider this question from an academic standpoint, we generate an image caption that draws a "laugh" by a computer. A system that outputs funny captions based on the image caption proposed in the computer vision field is constructed. Moreover, we also propose the Funny Score, which flexibly gives weights according to an evaluation database. The Funny Score more effectively brings out "laughter" to optimize a model. In addition, we build a self-collected BoketeDB, which contains a theme (image) and funny caption (text) posted on "Bokete", which is an image Ogiri website. In an experiment, we use BoketeDB to verify the effectiveness of the proposed method by comparing the results obtained using the proposed method and those obtained using MS COCO Pre-trained CNN+LSTM, which is the baseline and idiot created by humans. We refer to the proposed method, which uses the BoketeDB pre-trained model, as the Neural Joking Machine (NJM).},
  journal = {arXiv:1805.11850 [cs]},
  author = {Yoshida, Kota and Minoguchi, Munetaka and Wani, Kenichiro and Nakamura, Akio and Kataoka, Hirokatsu},
  month = may,
  year = {2018},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/miriamamin/Documents/Zotero/storage/42Z288UM/Yoshida et al_2018_Neural Joking Machine.pdf;/Users/miriamamin/Documents/Zotero/storage/AZ5GPJBI/1805.html},
  annote = {The author preset a system to create funny captions for a given image, inspired by a japanese website where people can rate the captions. they use funny images\&captions (selected by number of points) from the website as training data (ca. 1 mio captions for 70.981 images) to train a CNN+LSTM network architecture. they claim to have generated 22.6\% funny captions, according to human evaluation.}
}

@inproceedings{iwakuraBasicStudyGenerating2018,
  title = {A {{Basic Study}} on {{Generating Back}}-{{Channel Humor Phrases}} for {{Chat Dialogue Systems}}},
  copyright = {X GENER},
  abstract = {Research on automatic dialogue systems (chat dialogue systems) has attracted attention, in recent years. Dialogue systems are classified into task-oriented and non-task-oriented ones. In non-task-oriented dialogue systems, it is important that users are willing to continue dialogue over a long period. Conventional studies report that utterances, including humor and back-channel feedback, are effective in improving dialog continuity. This study investigates the generation of back-channel humor phrases for chat dialogue systems.},
  booktitle = {2018 {{Joint}} 10th {{International Conference}} on {{Soft Computing}} and {{Intelligent Systems}} ({{SCIS}}) and 19th {{International Symposium}} on {{Advanced Intelligent Systems}} ({{ISIS}})},
  doi = {10.1109/SCIS-ISIS.2018.00198},
  author = {Iwakura, R. and Yoshikawa, T. and Furuhashi, T.},
  month = dec,
  year = {2018},
  keywords = {Twitter,automatic dialogue systems,back-channel feedback,back-channel humor phrases,Cats,chat dialogue system; generation of humor; back-channel,chat dialogue systems,Data mining,Indexes,Intelligent systems,interactive systems,nontask-oriented dialogue systems,nontask-oriented one,Task analysis,task-oriented one,Toy manufacturing industry},
  pages = {1263-1266},
  file = {/Users/miriamamin/Documents/Zotero/storage/TXW3YS28/Iwakura et al_2018_A Basic Study on Generating Back-Channel Humor Phrases for Chat Dialogue Systems.pdf;/Users/miriamamin/Documents/Zotero/storage/8QC4FBF8/8716119.html},
  annote = {The authors addres the problem of keeping a user's interaction with a dialogue system as long as possible. Assuming the user continues the dialogue longer when the system is funny, they generate a form of humor that consists of a noun and a relative clause closer describing the noun, using a Japanese counterpart of wordnet. the authors try to explain their generation method and i assume that they preselected some nouns and then combined them randomly. results are e.g. "train which is slightly cold". they showed them to test persons and found out that they differed significantally in their ratings to the point where there was no single phrase that all the users found humorous. unfortunately, the authors missed to translate parts of the paper from Japanese, which limits comprehension considerably.}
}

@inproceedings{chenHumorRecognitionUsing2018,
  series = {Short {{Paper}}},
  title = {Humor {{Recognition Using Deep Learning}}},
  volume = {2},
  copyright = {RECOG},
  language = {en-us},
  booktitle = {Proceedings of the 2018 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}},
  doi = {10.18653/v1/N18-2018},
  author = {Chen, Peng-Yu and Soo, Von-Wun},
  year = {2018},
  pages = {113-117},
  file = {/Users/miriamamin/Documents/Zotero/storage/KAHAFJPZ/Chen_Soo_2018_Humor Recognition Using Deep Learning.pdf;/Users/miriamamin/Documents/Zotero/storage/24ISU5LZ/N18-2018.html}
}

@inproceedings{ramakrishnaComputationalModelingConversational2018,
  title = {Computational {{Modeling}} of {{Conversational Humor}} in {{Psychotherapy}}},
  copyright = {RECOG},
  language = {en},
  booktitle = {Interspeech 2018},
  publisher = {{ISCA}},
  doi = {10.21437/Interspeech.2018-1583},
  author = {Ramakrishna, Anil and Greer, Timothy and Atkins, David and Narayanan, Shrikanth},
  month = sep,
  year = {2018},
  pages = {2344-2348},
  file = {/Users/miriamamin/Documents/Zotero/storage/VKKKQ2BR/Ramakrishna et al_2018_Computational Modeling of Conversational Humor in Psychotherapy.pdf}
}

@inproceedings{weberHowShapeHumor2018,
  address = {{New York, NY, USA}},
  series = {{{ICMI}} '18},
  title = {How to {{Shape}} the {{Humor}} of a {{Robot}} - {{Social Behavior Adaptation Based}} on {{Reinforcement Learning}}},
  copyright = {X GENER},
  isbn = {978-1-4503-5692-3},
  abstract = {A shared sense of humor can result in positive feelings associated with amusement, laughter, and moments of bonding. If robotic companions could acquire their human counterparts' sense of humor in an unobtrusive manner, they could improve their skills of engagement. In order to explore this assumption, we have developed a dynamic user modeling approach based on Reinforcement Learning, which allows a robot to analyze a person's reaction while it tells jokes and continuously adapts its sense of humor. We evaluated our approach in a test scenario with a Reeti robot acting as an entertainer and telling different types of jokes. The exemplary adaptation process is accomplished only by using the audience's vocal laughs and visual smiles, but no other form of explicit feedback. We report on results of a user study with 24 participants, comparing our approach to a baseline condition (with a non-learning version of the robot) and conclude by providing limitations and implications of our approach in detail.},
  booktitle = {Proceedings of the 20th {{ACM International Conference}} on {{Multimodal Interaction}}},
  publisher = {{ACM}},
  doi = {10.1145/3242969.3242976},
  author = {Weber, Klaus and Ritschel, Hannes and Aslan, Ilhan and Lingenfelser, Florian and Andr{\'e}, Elisabeth},
  year = {2018},
  keywords = {human-robot-interaction,social adaptation,socially-aware agents},
  pages = {154--162},
  file = {/Users/miriamamin/Documents/Zotero/storage/ZMMZ8QUF/Weber et al_2018_How to Shape the Humor of a Robot - Social Behavior Adaptation Based on.pdf},
  annote = {The authors present a system, that learns a persons humor preferences based on their smile and laughter and adapts performance according to this. the robot could chose from 108 jokes in 3 joke categories among 19 grimaces and 23 sounds. after every human reaction, a weight function that choses the appropriate action is updated using gradient descent, taking into consideration the person's state at the time (amused or not amused). the authors show that the adaption approach yields higher amusement levels in users than a condition in which the jokes were presented randomly.}
}

@inproceedings{liuModelingSentimentAssociation2018,
  title = {Modeling {{Sentiment Association}} in {{Discourse}} for {{Humor Recognition}}},
  copyright = {RECOG},
  language = {en-us},
  booktitle = {Proceedings of the 56th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 2: {{Short Papers}})},
  author = {Liu, Lizhen and Zhang, Donghai and Song, Wei},
  month = jul,
  year = {2018},
  pages = {586-591},
  file = {/Users/miriamamin/Documents/Zotero/storage/XNJHXAZP/Liu et al_2018_Modeling Sentiment Association in Discourse for Humor Recognition.pdf;/Users/miriamamin/Documents/Zotero/storage/URTYXBNK/P18-2093.html}
}

@inproceedings{liuExploitingSyntacticStructures2018,
  title = {Exploiting {{Syntactic Structures}} for {{Humor Recognition}}},
  copyright = {RECOG},
  language = {en-us},
  booktitle = {Proceedings of the 27th {{International Conference}} on {{Computational Linguistics}}},
  author = {Liu, Lizhen and Zhang, Donghai and Song, Wei},
  month = aug,
  year = {2018},
  pages = {1875-1883},
  file = {/Users/miriamamin/Documents/Zotero/storage/9837YI33/Liu et al_2018_Exploiting Syntactic Structures for Humor Recognition.pdf;/Users/miriamamin/Documents/Zotero/storage/ACRVANV5/C18-1159.html}
}

@inproceedings{braslavskiHowEvaluateHumorous2018,
  address = {{New York, NY, USA}},
  series = {{{CHIIR}} '18},
  title = {How to {{Evaluate Humorous Response Generation}}, {{Seriously}}?},
  copyright = {EVAL},
  isbn = {978-1-4503-4925-3},
  abstract = {Nowadays natural language user interfaces, such as chatbots and conversational agents, are very common. A desirable trait of such applications is a sense of humor. It is, therefore, important to be able to measure quality of humorous responses. However, humor evaluation is hard since humor is highly subjective. To address this problem, we conducted an online evaluation of 30 dialog jokes from different sources by almost 300 participants -- volunteers and Mechanical Turk workers. We collected joke ratings along with participants\guillemotright{} age, gender, and language proficiency. Results show that demographics and joke topics can partly explain variation in humor judgments. We expect that these insights will aid humor evaluation and interpretation. The findings can also be of interest for humor generation methods in conversational systems.},
  booktitle = {Proceedings of the 2018 {{Conference}} on {{Human Information Interaction}} \& {{Retrieval}}},
  publisher = {{ACM}},
  doi = {10.1145/3176349.3176879},
  author = {Braslavski, Pavel and Blinov, Vladislav and Bolotova, Valeria and Pertsova, Katya},
  year = {2018},
  keywords = {computational humor,conversational systems,crowdsourcing,evaluation},
  pages = {225--228},
  file = {/Users/miriamamin/Documents/Zotero/storage/AFP9GBB9/Braslavski et al_2018_How to Evaluate Humorous Response Generation, Seriously.pdf}
}

@inproceedings{ahujaWhatMakesUs2018,
  title = {What Makes Us Laugh? {{Investigations}} into {{Automatic Humor Classification}}},
  copyright = {ANALY 1},
  shorttitle = {What Makes Us Laugh?},
  language = {en-us},
  booktitle = {Proceedings of the {{Second Workshop}} on {{Computational Modeling}} of {{People}}'s {{Opinions}}, {{Personality}}, and {{Emotions}} in {{Social Media}}},
  doi = {10.18653/v1/W18-1101},
  author = {Ahuja, Vikram and Bali, Taradheesh and Singh, Navjyoti},
  month = jun,
  year = {2018},
  pages = {1-9},
  file = {/Users/miriamamin/Documents/Zotero/storage/PUPZUFWJ/Ahuja et al_2018_What makes us laugh.pdf;/Users/miriamamin/Documents/Zotero/storage/UAE4N6W2/W18-1101.html}
}

@inproceedings{hossainPresidentVowsCut2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1906.00274},
  title = {"{{President Vows}} to {{Cut}}  {{Hair}}": {{Dataset}} and {{Analysis}} of {{Creative Text Editing}} for {{Humorous Headlines}}},
  copyright = {DATA 1},
  shorttitle = {"{{President Vows}} to {{Cut}}  {{Hair}}"},
  abstract = {We introduce, release, and analyze a new dataset, called Humicroedit, for research in computational humor. Our publicly available data consists of regular English news headlines paired with versions of the same headlines that contain simple replacement edits designed to make them funny. We carefully curated crowdsourced editors to create funny headlines and judges to score a to a total of 15,095 edited headlines, with five judges per headline. The simple edits, usually just a single word replacement, mean we can apply straightforward analysis techniques to determine what makes our edited headlines humorous. We show how the data support classic theories of humor, such as incongruity, superiority, and setup/punchline. Finally, we develop baseline classifiers that can predict whether or not an edited headline is funny, which is a first step toward automatically generating humorous headlines as an approach to creating topical humor.},
  booktitle = {Proceedings of {{NAACL}} 19},
  author = {Hossain, Nabil and Krumm, John and Gamon, Michael},
  month = jun,
  year = {2019},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/miriamamin/Documents/Zotero/storage/GRJ83T98/Hossain et al_2019_President Vows to Cut Taxes Hair.pdf;/Users/miriamamin/Documents/Zotero/storage/L6ZTJTMB/1906.html},
  annote = {Comment: Accepted in NAACL 2019}
}

@article{hasanURFUNNYMultimodalLanguage2019,
  title = {{{UR}}-{{FUNNY}}: {{A Multimodal Language Dataset}} for {{Understanding Humor}}},
  volume = {abs/1904.06618},
  copyright = {DATA},
  shorttitle = {{{UR}}-{{FUNNY}}},
  journal = {CoRR},
  author = {Hasan, Md Kamrul and Rahman, Wasifur and Zadeh, Amir and Zhong, Jianyuan and Tanveer, Md Iftekhar and Morency, Louis-Philippe and Hoque, Mohammed E.},
  year = {2019},
  file = {/Users/miriamamin/Documents/Zotero/storage/3BKQHCGH/Hasan et al_2019_UR-FUNNY.pdf}
}

@inproceedings{gultchinHumorWordEmbeddings2019,
  title = {Humor in {{Word Embeddings}}: {{Cockamamie Gobbledegook}} for {{Nincompoops}}},
  copyright = {ANALY 1},
  shorttitle = {Humor in {{Word Embeddings}}},
  abstract = {While humor is often thought to be beyond the reach of Natural Language Processing, we show that several aspects of single-word humor correlate with simple linear directions in Word Embeddings. In ...},
  language = {en},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Gultchin, Limor and Patterson, Genevieve and Baym, Nancy and Swinger, Nathaniel and Kalai, Adam},
  month = may,
  year = {2019},
  pages = {2474-2483},
  file = {/Users/miriamamin/Documents/Zotero/storage/6H5QI9TZ/Gultchin et al_2019_Humor in Word Embeddings.pdf;/Users/miriamamin/Documents/Zotero/storage/JUZZIF52/gultchin19a.html}
}

@article{venourQuantifyingHumorousLexical2010,
  title = {Quantifying Humorous Lexical Incongruity},
  copyright = {ANALY 1},
  abstract = {Traditional discussions of humorous texts often postulate a notion of "incongruity" as being central, but there is no real formalisation of this notion. We are exploring one particular type of incongruity, in which a clash between the style or register of lexical items leads to humour. This paper describes our construction of a semantic space in which the distance between words reflects a difference in their style or tone. The model was constructed by computing profiles of words in terms of their frequencies within various corpora, using these features as a multidimensional space into which words can be plotted and experimenting with various distance metrics to see which measure best approximates differences in tone.},
  journal = {Proceedings of the International Conference on Computational Creativity, ICCC-10},
  author = {Venour, C and Ritchie, G and Mellish, C},
  month = jan,
  year = {2010},
  pages = {104-116},
  file = {/Users/miriamamin/Documents/Zotero/storage/EQ7XI9WF/Venour et al_2010_Quantifying humorous lexical incongruity.pdf}
}

@book{venourComputationalModelLexical2013a,
  title = {A {{Computational Model}} of {{Lexical Incongruity}} in {{Humorous Text}}},
  copyright = {GENER 1},
  abstract = {Many theories of humour claim that incongruity is an essential ingredient of humour. How- ever this idea is poorly understood and little work has been done in computational humour to quantify it. For example classifiers which attempt to distinguish jokes from regular texts tend to look for secondary features of humorous texts rather than for incongruity. Similarly most joke generators attempt to recreate structural patterns found in example jokes but do not deliberately endeavour to create incongruity. As in previous research, this thesis develops classifiers and a joke generator which attempt to automatically recognize and generate a type of humour. However the systems described here differ from previous programs because they implement a model of a certain type of humorous incongruity. We focus on a type of register humour we call lexical register jokes in which the tones of individual words are in conflict with each other. Our goal is to create a semantic space that reflects the kind of tone at play in lexical register jokes so that words that are far apart in the space are not simply different but exhibit the kinds of incongruities seen in lexical jokes. This thesis attempts to develop such a space and various classifiers are implemented to use it to distinguish lexical register jokes from regular texts. The best of these classifiers achieved high levels of accuracy when distinguishing between a test set of lexical register jokes and 4 different kinds of regular text. A joke generator which makes use of the semantic space to create original lexical register jokes is also implemented and described in this thesis. In a test of the generator, texts that were generated by the system were evaluated by volunteers who considered them not as humorous as human-made lexical register jokes but significantly more humorous than a set of control (i.e.non- joke) texts. This was an encouraging result which suggests that the vector space is somewhat successful in discovering lexical differences in tone and in modelling lexical register jokes.},
  language = {en},
  publisher = {{Aberdeen University}},
  author = {Venour, Chris},
  year = {2013},
  file = {/Users/miriamamin/Documents/Zotero/storage/WDSVU5Y6/Venour et al_2010_Quantifying humorous lexical incongruity.pdf},
  googlebooks = {DICKngEACAAJ}
}

@article{devlinBERTPretrainingDeep2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1810.04805},
  primaryClass = {cs},
  title = {{{BERT}}: {{Pre}}-Training of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  journal = {arXiv:1810.04805 [cs]},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  month = oct,
  year = {2018},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/miriamamin/Documents/Zotero/storage/SWLYJ9B7/Devlin et al_2018_BERT.pdf;/Users/miriamamin/Documents/Zotero/storage/W99K4ZZC/1810.html}
}

@book{valituttiLetEverythingTurn2013,
  title = {``{{Let Everything Turn Well}} in {{Your Wife}}'': {{Generation}} of {{Adult Humor Using Lexical Constraints}}},
  copyright = {X GENER},
  shorttitle = {``{{Let Everything Turn Well}} in {{Your Wife}}''},
  abstract = {We propose a method for automated generation of adult humor by lexical replacement and present empirical evaluation results of the obtained humor. We propose three types of lexical constraints as building blocks of humorous word substitution: constraints concerning the similarity of sounds or spellings of the original word and the substitute, a constraint requiring the substitute to be a taboo word, and constraints concerning the position and context of the replacement. Empirical evidence from extensive user studies indicates that these constraints can increase the effectiveness of humor generation significantly. 1},
  author = {Valitutti, Alessandro and Doucet, Antoine and Toivonen, Hannu and Toivanen, Jukka M.},
  year = {2013},
  file = {/Users/miriamamin/Documents/Zotero/storage/47LHZKP8/Valitutti et al_“Let Everything Turn Well in Your Wife”.pdf;/Users/miriamamin/Documents/Zotero/storage/ZCS9SPXV/summary.html},
  annote = {basically the same as valitutti et al 2016}
}

@misc{PDFHumorModeling,
  title = {({{PDF}}) {{Humor}} Modeling in the Interface | {{Anton Nijholt}} Und {{Alan Dix}} - {{Academia}}.Edu},
  howpublished = {https://www.academia.edu/11668798/Humor\_modeling\_in\_the\_interface},
  file = {/Users/miriamamin/Documents/Zotero/storage/TFTTXUSZ/Humor_modeling_in_the_interface.html}
}

@article{PasswordSwordfishVerbal2006,
  title = {Password Swordfish: {{Verbal}} Humor in the Interface},
  volume = {16},
  issn = {1613-3722},
  shorttitle = {Password Swordfish},
  number = {3},
  journal = {Humor - International Journal of Humor Research},
  doi = {10.1515/humr.2003.015},
  year = {2006},
  pages = {281--295}
}

@article{stockPasswordSwordfishVerbal,
  title = {Password {{Swordfish}}: {{Verbal Humour}} in the {{Interface}}},
  abstract = {Humour will be a necessity in future interfaces, especially in the area at the crossroads of entertainment and education, the so called edutainment. Some considerations on the state of the art in natural langauge processing and on computational humour prospects are presented, as well as some ideas for the introduction of certain types of computational humour in seductive interfaces. In doing that, reference is made to some of the sparkling exchanges of the Marx Brothers.1.},
  language = {en},
  author = {Stock, Oliviero},
  pages = {6},
  file = {/Users/miriamamin/Documents/Zotero/storage/U86X7JTX/Stock - Password Swordfish Verbal Humour in the Interface.pdf}
}

@article{raskinHowUnderstandAssess2009,
  title = {How to Understand and Assess a Theory: {{The}} Evolution of the {{SSTH}} into the {{GTVH}} and Now into the {{OSTH}}},
  volume = {3},
  shorttitle = {How to Understand and Assess a Theory},
  abstract = {The main thrust of this paper is to present to an important adjacent scholarly community of literary scholars how humor can be treated by the current strand of contemporary linguistics, or \textendash{} more specifically \textendash{} by linguistic semantics. In the process, we will show how a major theory of humor, the Semantic Script-based Theory of Humor (Raskin, Semantic Mechanisms of Humor, 325\textendash{}335, 1979a, Semantic Mechanisms of Humor, 1985; Attardo, Linguistic Theories of Humor, 1994) first evolved into the General Theory of Verbal Humor (Attardo/Raskin, HUMOR \textendash{} International Journal of Humor Research 4: 293\textendash{}347, 1991; Attardo, Linguistic Theories of Humor, 1994), and now into the Ontological Semantic Theory of Humor (Raskin/Triezenberg, Ontological Semantics of Humor: Pre-Conference Tutorial, Youngstown State University, 2005; Raskin, From SSTH to GTVH to OSTH, Finally, University of California, 2009; Hempelmann, From SSTH to GTVH to OSTH: The LM in OSTH, University of California, 2009; Taylor, SO in OSTH: Ontological Semantic View of Script Overlap/Oppositeness Support, University of California, 2009, Journal of Ambient Intelligence and Humanized Computing 1: 3, 2010).},
  journal = {Journal of Literary Theory},
  doi = {10.1515/JLT.2009.016},
  author = {Raskin, Victor and Hempelmann, Christian and Rayz, Julia},
  month = dec,
  year = {2009},
  file = {/Users/miriamamin/Documents/Zotero/storage/RVNP8K3E/How to Understand and Assess a Theory The Evoluti.pdf}
}

@inproceedings{raskinAlgorithmicDiscoveryComputational2015,
  title = {On {{Algorithmic Discovery}} and {{Computational Implementation}} of the {{Opposing Scripts Forming}} a {{Joke}}},
  volume = {9189},
  isbn = {978-3-319-20803-9},
  abstract = {The paper deals with the notion of `script'. Scripts have been essential for the dominant formal theories of verbal humor since their inception in the late 1970s, and the formal theories gave rise to meaningful computational humor a decade or so later. Recent developments in computational semantics and computational humor have required a tighter definition of `script' as a computational entity.},
  doi = {10.1007/978-3-319-20804-6_61},
  author = {Raskin, Victor},
  month = aug,
  year = {2015},
  pages = {671-679}
}

@inproceedings{rayzPursuitHumanfriendlyInteraction2017,
  title = {In Pursuit of Human-Friendly Interaction with a Computational System: {{Computational}} Humor},
  shorttitle = {In Pursuit of Human-Friendly Interaction with a Computational System},
  abstract = {With AI celebrating its 60 th anniversary, questions arise of when (not even if) a computational system will be able to understand humor. These questions open up interesting opportunities, but point out areas of research that yet are insufficient for informal human computer communication. This paper looks at computational humor as a way of verifying computational understanding of text (written or verbal). In particular, we treat ontology as a knowledge representation mechanism and natural language as a vehicle delivering this knowledge. A true ontology should provide a world model for the described domain, identifying its main concepts and tying them together with all relevant contentful properties. The question is how to get this model from text accurately? Assuming, as we do, that there is an accurate and unambiguous way of getting explicitly stated information from text, a lot of information is, in fact, implicit and yet crucial to the world model that we are creating. This implicit information has to be made explicit at the reasoning stage if we hope to come up with the results similar to human reasoning or understanding. In this paper, we will look at various ways, requiring optimal human-computer hybrid collaboration, in which ontology helps text understanding for humor processing, and text helps with dynamic ontology development. We hypothesize that such communication will be helpful for interaction with any computational system in a human-friendly way in general, and for robots in particular.},
  doi = {10.1109/SAMI.2017.7880297},
  author = {Rayz, Julia},
  month = jan,
  year = {2017},
  pages = {000015-000020}
}

@article{rayzComputationalHumorChristie2017,
  title = {Computational Humor and {{Christie Davies}}' Basis for Joke Comparison},
  volume = {5},
  abstract = {While historically computational humor paid very little attention to sociology and mostly took into account subparts of linguistics and some psychology, Christie Davies wrote a number of papers that should affect the study of computational humor directly. This paper will look at one paper to illustrate this point, namely Christie's chapter in the Primer of Humor Research. With the advancements in computational processing and big data analysis/analytics, it is becoming possible to look at a large collection of humorous texts that are available on the web. In particular, older texts, including joke materials, that are being scanned from previously published printed versions. Most of the approaches within computational humor concentrated on comparison of present/existing jokes, without taking into account classes of jokes that are absent in a given setting. While the absence of a class is unlikely to affect classification \textendash{} something that researchers in computational humor seem to be interested in \textendash{} it does come into light when features of various classes are compared and conclusions are being made. This paper will describe existing approaches and how they could be enhanced, thanks to Davies's contributions and the advancements in data processing.},
  journal = {The European Journal of Humour Research},
  doi = {10.7592/EJHR2017.5.4.rayz},
  author = {Rayz, Julia},
  month = dec,
  year = {2017},
  pages = {169},
  file = {/Users/miriamamin/Documents/Zotero/storage/JLA93MV4/Rayz_2017_Computational humor and Christie Davies’ basis for joke comparison.pdf}
}

@article{taylorComputationalHumor2010,
  title = {On {{Computational Humor}}},
  volume = {29},
  issn = {0278-6648},
  abstract = {Humor is everywhere, as long as you are willing to see it, both accidental and intentional. Computers have evolved from simple calculating machines to playing chess, controlling air and space flights, and talking to humans. They are increasingly used to informally gather information from humans using human language. The paper mentions that will a computer ever understand humor as well as we do? Some people believe that humor is artificial intelligence-complete. In other words, humor is one of the most difficult problems in AI.},
  number = {6},
  journal = {IEEE Potentials},
  doi = {10.1109/MPOT.2010.938150},
  author = {Taylor, Julia M. and Mazlack, L. J.},
  month = nov,
  year = {2010},
  keywords = {artificial intelligence,Semantics,computational humor,Computers,Natural languages,Humans,Ontologies,human language,Dictionaries,Distance measurement},
  pages = {9-12},
  file = {/Users/miriamamin/Documents/Zotero/storage/2C966HM7/Taylor_Mazlack_2010_On Computational Humor.pdf;/Users/miriamamin/Documents/Zotero/storage/JNYB92HP/5620863.html}
}

@inproceedings{nijholtComputationalHumor20122012,
  title = {Computational {{Humor}} 2012: Extended Abstacts of the (3rd International) {{Workshop}} on {{Computational Humor}}},
  shorttitle = {Computational {{Humor}} 2012},
  language = {English},
  booktitle = {3rd {{International Workshop}} on {{Computational Humor}} 2012},
  publisher = {{Centre for Telematics and Information Technology (CTIT)}},
  author = {Nijholt, Anton},
  month = jun,
  year = {2012},
  file = {/Users/miriamamin/Documents/Zotero/storage/RBR8PVZW/Nijholt_2012_Computational Humor 2012.pdf;/Users/miriamamin/Documents/Zotero/storage/I6KCWCKQ/computational-humor-2012-extended-abstacts-of-the-3rd-internation.html}
}

@book{nijholtComputationalHumor20122012a,
  title = {Computational {{Humor}} 2012. {{Proceedings}} 3rd {{International Workshop}} on {{Computational Humor}}},
  abstract = {Like its predecessors in 1996 (University of Twente, the Netherlands) and 2002 (ITC-irst, Trento, Italy), this Third International Workshop on Computational Humor (IWCH 2012) focusses on the possibility to find algorithms that allow understanding and generation of humor. There is the general aim of modeling humor, and if we can do that, it will provide us with lots of information about our cognitive abilities in general, such as reasoning, remembering, understanding situations, and understanding conversational partners. But it also provides us with information about being creative, making associations, storytelling and language use. Many more subtleties in face-to-face and multiparty interaction can be added, such as using humor to persuade and dominate, to soften or avoid a face threatening act, to ease a tense situation or to establish a friendly or romantic relationship. One issue to consider is: when is a humorous act appropriate?},
  author = {Nijholt, Anton},
  month = jun,
  year = {2012},
  file = {/Users/miriamamin/Documents/Zotero/storage/YRVQEH28/Nijholt_2012_Computational Humor 2012.pdf}
}

@inproceedings{raskinTheoryHumorComputation2012,
  title = {Theory of {{Humor Computation}}},
  shorttitle = {Computational {{Humor}} 2012},
  language = {English},
  booktitle = {3rd {{International Workshop}} on {{Computational Humor}} 2012},
  publisher = {{Centre for Telematics and Information Technology (CTIT)}},
  author = {Raskin, Victor},
  month = jun,
  year = {2012}
}

@inproceedings{valituttiMakingFunFailures2017,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Making {{Fun}} of {{Failures Computationally}}},
  isbn = {978-3-319-58697-7},
  abstract = {We discuss ideas and propose resources on humor facilitation, as an extension of previous work on this topic. Specifically, we describe a method for achieving humor facilitation as the combination of event detection and generation of funny comments. We focus on user's mistakes as the preferred unexpected and potentially humorous events. Moreover, we implemented an online testbed consisting of a humor facilitator and two interactive environments: a text editor and a video game. The system is meant to provide a tool for empirical evaluation of the proposed framework.},
  language = {en},
  booktitle = {Distributed, {{Ambient}} and {{Pervasive Interactions}}},
  publisher = {{Springer International Publishing}},
  author = {Valitutti, Alessandro},
  editor = {Streitz, Norbert and Markopoulos, Panos},
  year = {2017},
  keywords = {Computational humor,Humor facilitation,Humorous agents,Humorous mistakes,Interactive humor},
  pages = {684-695}
}

@article{valituttiAmbiguousLexicalResources2012,
  title = {Ambiguous Lexical Resources for Computational Humor Generation},
  volume = {1},
  copyright = {X DATA},
  abstract = {The ongoing work presented here is aimed to investigate to what extent it is possible to perform a feasible use of ambiguous texts in computational humor generation. The first core of a lexical database was developed in order to collect ambiguous terms in the English lexicon. Then an exploratory use of the resource for computational humor generation was performed. Finally, three existing prototypes of humor generator were simulated in order to generate different form of humorous messages from the same lexical resource.},
  author = {Valitutti, Alessandro},
  month = jan,
  year = {2012},
  pages = {532-535},
  file = {/Users/miriamamin/Documents/Zotero/storage/KA8H25HK/Valitutti_2012_Ambiguous lexical resources for computational humor generation.pdf},
  annote = {creates a ressource for lexical amgubuity for later use in automatic joke generation. he collects words of three kinds of ambiguity: homophonie, homonymie, idioms (menaing of compund can not be inferred by collective menaing of its parts)}
}

@misc{britzAttentionMemoryDeep2016,
  title = {Attention and {{Memory}} in {{Deep Learning}} and {{NLP}}},
  abstract = {A recent trend in Deep Learning are Attention Mechanisms. In an interview, Ilya Sutskever, now the research director of OpenAI, mentioned that Attention Mechanisms are one of the most exciting adva\ldots{}},
  language = {en-US},
  journal = {WildML},
  author = {Britz, Denny},
  month = jan,
  year = {2016},
  file = {/Users/miriamamin/Documents/Zotero/storage/MNYZJY9E/attention-and-memory-in-deep-learning-and-nlp.html}
}

@book{morettiDistantReading2013,
  title = {Distant {{Reading}}},
  isbn = {978-1-78168-333-0},
  abstract = {WINNER OF THE NATIONAL BOOK CRITICS CIRCLE AWARD~How does a literary historian end up thinking in terms of z-scores, principal component analysis, and clustering coefficients? The essays in Distant Reading led to a new and often contested paradigm of literary analysis. In presenting them here Franco Moretti reconstructs his intellectual trajectory, the theoretical influences over his work, and explores the polemics that have often developed around his positions.From the evolutionary model of ``Modern European Literature,'' through the geo-cultural insights of ``Conjectures of World Literature'' and ``Planet Hollywood,'' to the quantitative findings of ``Style, inc.'' and the abstract patterns of ``Network Theory, Plot Analysis,'' the book follows two decades of conceptual development, organizing them around the metaphor of ``distant reading,'' that has come to define\textemdash{}well beyond the wildest expectations of its author\textemdash{}a growing field of unorthodox literary studies.},
  language = {en},
  publisher = {{Verso Books}},
  author = {Moretti, Franco},
  month = jun,
  year = {2013},
  keywords = {Literary Collections / Essays,Literary Criticism / Comparative Literature,Literary Criticism / Semiotics \& Theory},
  googlebooks = {Wo4110IdRLMC}
}

@article{janickeCloseDistantReading2015,
  title = {On {{Close}} and {{Distant Reading}} in {{Digital Humanities}}: {{A Survey}} and {{Future Challenges}}},
  shorttitle = {On {{Close}} and {{Distant Reading}} in {{Digital Humanities}}},
  abstract = {We present an overview of the last ten years of research on visualizations that support close and distant reading of textual data in the digital humanities. We look at various works published within both the visualization and digital humanities communities. We provide a taxonomy of applied methods for close and distant reading, and illustrate approaches that combine both reading techniques to provide a multifaceted view of the data. Furthermore, we list toolkits and potentially beneficial visualization approaches for research in the digital humanities. Finally, we summarize collaboration experiences when developing visualizations for close and distant reading, and give an outlook on future challenges in that research area.},
  language = {en},
  doi = {10.2312/eurovisstar.20151113},
  author = {J{\"a}nicke, Stefan and Franzini, Greta and Cheema, Muhammad Faisal and Scheuermann, Gerik},
  year = {2015},
  file = {/Users/miriamamin/Documents/Zotero/storage/R79HD4A2/eurovisstar.20151113.html}
}

@misc{zotero-687,
  howpublished = {https://www.etrap.eu/},
  file = {/Users/miriamamin/Documents/Zotero/storage/7RFFHY8R/www.etrap.eu.html}
}

@misc{WhyDataCitation,
  title = {Why {{Data Citation Is}} a {{Computational Problem}} | {{September}} 2016 | {{Communications}} of the {{ACM}}},
  howpublished = {https://cacm.acm.org/magazines/2016/9/206243-why-data-citation-is-a-computational-problem/fulltext},
  file = {/Users/miriamamin/Documents/Zotero/storage/VEI3FMI3/fulltext.html}
}

@article{bunemanWhyDataCitation2016,
  title = {Why {{Data Citation}} Is a {{Computational Problem}}},
  volume = {59},
  issn = {0001-0782},
  abstract = {Using database views to define citable units is the key to specifying and generating citations to data.},
  number = {9},
  journal = {Commun. ACM},
  doi = {10.1145/2893181},
  author = {Buneman, Peter and Davidson, Susan and Frew, James},
  month = aug,
  year = {2016},
  pages = {50--57},
  file = {/Users/miriamamin/Documents/Zotero/storage/46ZA2BQA/Buneman et al_2016_Why Data Citation is a Computational Problem.pdf}
}

@article{tiepmarOverviewCanonicalText2017,
  title = {An {{Overview}} of {{Canonical Text Services}}},
  volume = {5},
  abstract = {This paper provides a comprehensive overview of Canonical Text Services (CTS) and the surrounding tools that were developed on the basis of a MySQL based implementation. As such it covers a broad set of topics including a general explanation of CTS, various software tools and a wide array of text mining techniques. The goal is to compile the relatively widespread and potentially confusing amount of information into one document that focuses on the practical aspects and implications for researchers that work with text data. More technically focused aspects are discussed in the two papers that accompany this implementation ([20] and [21]) and the official CTS specifications. Additionally this paper introduces a licensing mechanism, a CTS based citation analysis workflow, a real time text alignment method and set of management tools including a central namespace resolver for CTS URNs.},
  journal = {Linguistics and Literature Studies},
  doi = {10.13189/lls.2017.050209},
  author = {Tiepmar, Jochen and Heyer, Gerhard},
  month = mar,
  year = {2017},
  pages = {132-148},
  file = {/Users/miriamamin/Documents/Zotero/storage/4B4VW85V/Tiepmar_Heyer_2017_An Overview of Canonical Text Services.pdf}
}

@inproceedings{smithApplyingDomainKnowledge2009,
  title = {Applying {{Domain Knowledge}} from {{Structured Citation Formats}} to {{Text}} and {{Data Mining}}: {{Examples Using}} the {{CITE Architecture}}},
  shorttitle = {Applying {{Domain Knowledge}} from {{Structured Citation Formats}} to {{Text}} and {{Data Mining}}},
  abstract = {Abstract. Domain knowledge expressed in structured citation formats can be exploited in data mining. We propose four structural proper-ties of canonically cited texts, then look at to two classic problems in the study of the scholia, or ancient scholarly commentary, found in the manuscripts of the Iliad. We cluster citations of scholia to analyze their distribution in different manuscripts; this leads to a revised view of how the manuscripts ' scribes drew on their source material. Correlated fre-quencies of named entities suggest that one group of manuscripts had access to material more closely based on the work of the greatest Hel-lenistic editor of Homer, Aristarchus of Samothrace. 1},
  booktitle = {In {{Text Mining Services}}},
  author = {Smith, D. Neel and Weaver, Gabriel A.},
  year = {2009},
  pages = {129},
  file = {/Users/miriamamin/Documents/Zotero/storage/92YCI37Q/Smith_Weaver_2009_Applying Domain Knowledge from Structured Citation Formats to Text and Data.pdf;/Users/miriamamin/Documents/Zotero/storage/5W5DF9HU/summary.html}
}

@misc{UniformResourceNames,
  title = {Uniform {{Resource Names}} (Urn) -},
  howpublished = {https://datatracker.ietf.org/wg/urn/charter/},
  file = {/Users/miriamamin/Documents/Zotero/storage/QVMKYBLS/charter.html}
}

@misc{klensinUniformResourceNames2017,
  title = {Uniform {{Resource Names}} ({{URNs}})},
  language = {en},
  journal = {IETF},
  howpublished = {https://tools.ietf.org/html/rfc8141},
  author = {Klensin, John and {Saint-Andre}, Peter},
  year = {2017},
  file = {/Users/miriamamin/Documents/Zotero/storage/ZXBL3F8G/rfc8141.html}
}

@misc{SpecificationCanonicalText2018,
  title = {Specification of the {{Canonical Text Services}} Protocol ({{CTS}}): Cite-Architecture/Cts\_spec},
  shorttitle = {Specification of the {{Canonical Text Services}} Protocol ({{CTS}})},
  howpublished = {cite-architecture},
  month = jan,
  year = {2018}
}

@misc{christopherblackwellCTSURNSpecification2014,
  title = {The {{CTS URN}} Specification},
  journal = {Homer Multitext Project},
  howpublished = {http://www.homermultitext.org/hmt-docs/specifications/ctsurn/},
  author = {{Christopher Blackwell} and {Neel Smith}},
  year = {2014},
  file = {/Users/miriamamin/Documents/Zotero/storage/YKLDUS63/ctsurn.html}
}

@article{tiepmarImplementationEvaluationCanonical2018,
  title = {{Implementation and Evaluation of the Canonical Text Service Protocol as Part of a Research Infrastructure in the Digital Humanities}},
  abstract = {Einer der bestimmenden Faktoren moderner Gesellschaften ist die fortlaufende Digitalisierung von Informationen und Resourcen. Dieser Trend spiegelt sich in heutiger Forschung wider und hat starken Einfluss auf akademische und industrielle Projekte. Es ist nahezu unm{\"o}glich, ein modernes Projekt aufzusetzen, welches keinerlei digitale Aspekte beinhaltet und viele Projekte werden mit dem alleinigen Zweck der Digitalisierung eines Teils der Welt ins Leben gerufen. Dieser Trend f{\"u}hrt zur Entstehung neuer Forschungsfelder an den Schnittstellen zwischen der analogen Welt -- beispielsweise den Geisteswissenschaften -- und der Digitalen -- beispielsweise der Informatik. Eine davon ist das f{\"u}r diese Arbeit interessante Gebiet der Digital Humanities. Dabei werden komplexe Forschungsfragen, -techniken und -prinzipien verbunden, die sich unabh{\"a}ngig voneinander entwickelten. Viel M{\"u}he ist n{\"o}tig, um die Kommunikation zwischen deren Konzepte zu definieren um Missverst{\"a}ndnisse und Fehleinsch{\"a}tzungen zu vermeiden. Dieser Prozess der Br{\"u}ckenbildung ist eine zentrale Aufgabe der neu entstehenden Forschungsfelder. Diese Arbeit schl{\"a}gt eine solche Br{\"u}cke f{\"u}r die textorientierten Digital Humanities vor. Diese L{\"o}sung basiert auf einem Referenzsystem f{\"u}r digitalen Text, welches in den Geisteswissenschaften spezifiziert und im Rahmen dieser Arbeit zu einem Datenkommunikationsprotokoll f{\"u}r die Informatik uminterpretiert wurde: dem Canonical Text Service (CTS) Protokoll.},
  language = {de},
  author = {Tiepmar, Jochen},
  month = may,
  year = {2018},
  file = {/Users/miriamamin/Documents/Zotero/storage/LMPIXZ2K/Tiepmar_2018_Implementation and Evaluation of the Canonical Text Service Protocol as Part of.pdf;/Users/miriamamin/Documents/Zotero/storage/JCXQVIC8/landing-page.html}
}

@article{ritchiePracticalApplicationComputational2007,
  title = {A Practical Application of Computational Humour},
  abstract = {The past 15 years has seen the development of a number of programs which perform tasks in the area of humour, but these have been exploratory research prototypes, usually on a very small scale, and none of them interacted with users. Amongst those which actually created humorous texts, the JAPE program was probably the most substantial, but even it was far from being useful for any practical pur-pose. We have developed a fully engineered riddle genera-tor, inspired by the ideas in the JAPE system, which uses a large-scale multimedia lexicon and a set of symbolic rules to generate jokes. It has an interactive user interface, spe-cially designed for children with complex communication needs (CCN), so that users can make choices to guide the riddle generator. The software is robust, stable, and re-sponds sufficiently promptly that naive users can interact without difficulty. It has been tested over with real users (children with CCN), with highly positive results, and is publicly available for free download.},
  journal = {Proceedings of the 4th International Joint Workshop on Computational Creativity},
  author = {Ritchie, Graeme and Manurung, Ruli and Pain, Helen and Waller, Annalu and Black, Rolf and O Mara, Dave},
  month = jan,
  year = {2007},
  file = {/Users/miriamamin/Documents/Zotero/storage/NTSXQ6DW/Ritchie et al_2007_A practical application of computational humour.pdf}
}

@inproceedings{sjoberghCompleteModestlyFunny2008,
  address = {{Manchester, UK}},
  title = {A {{Complete}} and {{Modestly Funny System}} for {{Generating}} and {{Performing Japanese Stand}}-{{Up Comedy}}.},
  copyright = {X GENER},
  abstract = {We present a complete system that generates Japanese stand-up comedy. Different modules generating different types of jokes are tied together into a performance where all jokes are connected in some way to the other jokes. The script is converted to speech and two robots perform the comedy routine. Evaluations show that the performances are perceived as funny by many, almost half the evaluation scores for the total impression were 4 or 5 (top score).},
  booktitle = {Coling 2008: {{Companion}} Volume: {{Posters}}},
  publisher = {{Coling 2008 Organizing Committee}},
  author = {Sj{\"o}bergh, Jonas and Araki, Kenji},
  month = aug,
  year = {2008},
  pages = {111-114},
  file = {/Users/miriamamin/Documents/Zotero/storage/5LV6CVJG/Sjöbergh_Araki_2008_A Complete and Modestly Funny System for Generating and Performing Japanese.pdf;/Users/miriamamin/Documents/Zotero/storage/TRS4CVK7/Sjöbergh_Araki_A Complete and Modestly Funny System for Generating and Performing Japanese.pdf;/Users/miriamamin/Documents/Zotero/storage/WJ223FVF/summary.html}
}

@misc{kehlerLectureLanguageConzeptualization2001,
  title = {Lecture in '{{Language}} and {{Conzeptualization}}'},
  publisher = {{UC San Diego}},
  author = {Kehler, Andrew},
  year = {Spring term 2001},
  file = {/Users/miriamamin/Documents/Zotero/storage/FIT6GVCV/Andrew Kehler_2001_Lecture in 'Language and Conzeptualization'.pdf}
}

@book{goldbergConstructionsConstructionGrammar1995,
  title = {Constructions: {{A Construction Grammar Approach}} to {{Argument Structure}}},
  isbn = {978-0-226-30086-3},
  shorttitle = {Constructions},
  abstract = {Drawing on work in linguistics, language acquisition, and computer science, Adele E. Goldberg proposes that grammatical constructions play a central role in the relation between the form and meaning of simple sentences. She demonstrates that the syntactic patterns associated with simple sentences are imbued with meaning\textemdash{}that the constructions themselves carry meaning independently of the words in a sentence.  Goldberg provides a comprehensive account of the relation between verbs and constructions, offering ways to relate verb and constructional meaning, and to capture relations among constructions and generalizations over constructions. Prototypes, frame semantics, and metaphor are shown to play crucial roles. In addition, Goldberg presents specific analyses of several constructions, including the ditransitive and the resultative constructions, revealing systematic semantic generalizations.  Through a comparison with other current approaches to argument structure phenomena, this book narrows the gap between generative and cognitive theories of language.},
  language = {en},
  publisher = {{University of Chicago Press}},
  author = {Goldberg, Adele E.},
  month = mar,
  year = {1995},
  keywords = {Language Arts \& Disciplines / General,Language Arts \& Disciplines / Grammar \& Punctuation},
  file = {/Users/miriamamin/Documents/Zotero/storage/5Y5CGFFX/Goldberg_1995_Constructions.pdf},
  googlebooks = {HzmGM0qCKtIC},
  annote = {Abschnitt {\"u}ber Alternation bei spray/load Verben p- 176 ff}
}

@misc{VerbSemanticClasses,
  title = {Verb {{Semantic Classes}}},
  howpublished = {http://www.ilc.cnr.it/EAGLES96/rep2/node10.html},
  file = {/Users/miriamamin/Documents/Zotero/storage/ZF7LR3D4/node10.html}
}

@article{margettsAudioVideoRecording2011,
  title = {Audio and {{Video Recording Techniques}} for {{Linguistic Research}}},
  abstract = {This article gives an account of practical issues with audio and video recordings in a fieldwork setting, based on real-life experiences. In addition to some standard recommendations, it includes points learned through mistakes, happy accidents, and trial and error. Comments about specific equipment will be out of date by the time this volume is published. Nevertheless this article gives specifications for at least some items in the hope that this will help to identify types of equipment that have been found to be worthwhile. This article first addresses some general points about what to record in a field situation, outlines the workflow of data processing, and provides notes on managing equipment. It then discusses audio and video recordings and raises the question of energy supply and useful auxiliary equipment. The appendix provides suggestions for a basic field equipment kit. This article also elaborates upon what to record for linguistic analysis followed by the workflow that would allow some of the data to be fully processed during the fieldtrip.},
  language = {en},
  journal = {The Oxford Handbook of Linguistic Fieldwork},
  doi = {10.1093/oxfordhb/9780199571888.013.0002},
  author = {Margetts, Anna and Margetts, Andrew},
  month = nov,
  year = {2011},
  file = {/Users/miriamamin/Documents/Zotero/storage/9D9VSTND/Margetts_Margetts_2011_Audio and Video Recording Techniques for Linguistic Research.pdf;/Users/miriamamin/Documents/Zotero/storage/HHZFQ5HJ/oxfordhb-9780199571888-e-2.html}
}

@incollection{gastComparativeLexicologyTypology2014,
  address = {{D{\"u}sseldorf}},
  title = {{Comparative lexicology and the typology of event descriptions: a programmatic study}},
  volume = {1},
  isbn = {978-3-943460-64-3},
  shorttitle = {{Comparative lexicology and the typology of event descriptions}},
  language = {de},
  booktitle = {{Meaning and Grammar of Nouns and Verbs}},
  publisher = {{d{\"u}sseldorf university press}},
  author = {Gast, Volker and K{\"o}nig, Ekkehard and {Moyse-Faurie}, Claire},
  editor = {Gerland, Doris and Horn, Christian and Latrouite, Anja and Ortmann, Albert},
  month = apr,
  year = {2014},
  pages = {145-183},
  file = {/Users/miriamamin/Documents/Zotero/storage/6TVUVLW6/Gast et al. - 2014 - Comparative lexicology and the typology of event d.pdf;/Users/miriamamin/Documents/Zotero/storage/UYDMH8ZP/12.html}
}

@book{popescuParadigmComparativeLexicology2018,
  title = {A {{Paradigm}} of {{Comparative Lexicology}}},
  isbn = {978-1-5275-1808-7},
  abstract = {This book draws a parallel between the English and Romanian vocabularies. The view considers both elements of their macro- and micro-structural representations. Different in their culture and history as the English and Romanians are, their languages reveal numerous similarities in terms of word formations, foreignisms and word relationships. Each of these are described in several chapters. It is a book which, even if not specifically emphasized, celebrates 100 years since the making of modern Romania.},
  author = {Popescu, Floriana},
  month = dec,
  year = {2018}
}

@book{popescuParadigmComparativeLexicology2018a,
  title = {A {{Paradigm}} of {{Comparative Lexicology}}},
  isbn = {978-1-5275-2107-0},
  abstract = {Intended to bridge the gap between two languages of the Indo-European family, this is the first comprehensive bifocal approach to lexicological aspects. Through its theoretical distinctions and applications, the book recommends itself to language professionals and to any reader interested in learning more about words. It starts with a brief theoretical account of overlapping terms, which are given crystal-clear disambiguations. The book then focuses on structural representations of word formations and word relationships, outlining their hierarchicalness and branching directions and revealing various levels of materialization entailed by lexical productivity and frequency of occurrence. Each of these hierarchies defines its related techniques and explains lexical creations, adaptations or adoptions and interrelationships. The approach adopted here proves English to be consistent with formative and sense-related hierarchies, and shows it to have reached a climax in language evolution with its status of a global language, making it the standard in comparative linguistics.},
  language = {en},
  publisher = {{Cambridge Scholars Publishing}},
  author = {Popescu, Floriana},
  month = nov,
  year = {2018},
  keywords = {Language Arts \& Disciplines / General,Foreign Language Study / English as a Second Language,Philosophy / Language},
  file = {/Users/miriamamin/Documents/Zotero/storage/EATDKD2K/Popescu - 2018 - A Paradigm of Comparative Lexicology.pdf},
  googlebooks = {VzJ3DwAAQBAJ}
}

@article{wunderlichCauseStructureVerbs1997,
  title = {Cause and the {{Structure}} of {{Verbs}}},
  volume = {28},
  issn = {0024-3892},
  abstract = {Lexical Decomposition Grammar is proposed as a new framework to account for argument structure and argument structure alternations. It is based on Semantic Form (SF), a grammatical level at which complex verbs are minimally decomposed into more basic predicates. L-command relations in SF constrain the possible structural arguments. Argument linking follows from the hierarchy of \texttheta{}-roles that results from {$\lambda$}-abstraction (possibly augmented by lexical features). The article discusses the role of "cause" and "become" in the decomposition of verbs, and it shows that causatives and resultatives constitute two fundamentally different options for expressing causal relationships in verbs, both already attested in simple verbs.},
  number = {1},
  journal = {Linguistic Inquiry},
  author = {Wunderlich, Dieter},
  year = {1997},
  pages = {27-68}
}

@misc{levinLexicalSemanticsVerbs2009,
  title = {Lexical {{Semantics}} of {{Verbs II}}: {{The Structure}} of {{Event Structure}}},
  publisher = {{UC Berkeley}},
  author = {Levin, Beth},
  year = {2009},
  file = {/Users/miriamamin/Documents/Zotero/storage/9CM9G9HF/Beth Levin - 2009 - Lexical Semantics of Verbs II The Structure of Ev.pdf}
}

@book{levinEnglishVerbClasses1993,
  title = {English {{Verb Classes}} and {{Alternations}}: {{A Preliminary Investigation}}},
  isbn = {978-0-226-47533-2},
  shorttitle = {English {{Verb Classes}} and {{Alternations}}},
  abstract = {In this rich reference work, Beth Levin classifies over 3,000 English verbs according to shared meaning and behavior. Levin starts with the hypothesis that a verb's meaning influences its syntactic behavior and develops it into a powerful tool for studying the English verb lexicon. She shows how identifying verbs with similar syntactic behavior provides an effective means of distinguishing semantically coherent verb classes, and isolates these classes by examining verb behavior with respect to a wide range of syntactic alternations that reflect verb meaning.  The first part of the book sets out alternate ways in which verbs can express their arguments. The second presents classes of verbs that share a kernel of meaning and explores in detail the behavior of each class, drawing on the alternations in the first part. Levin's discussion of each class and alternation includes lists of relevant verbs, illustrative examples, comments on noteworthy properties, and bibliographic references. The result is an original, systematic picture of the organization of the verb inventory.  Easy to use, English Verb Classes and Alternations sets the stage for further explorations of the interface between lexical semantics and syntax. It will prove indispensable for theoretical and computational linguists, psycholinguists, cognitive scientists, lexicographers, and teachers of English as a second language.},
  language = {en},
  publisher = {{University of Chicago Press}},
  author = {Levin, Beth},
  month = sep,
  year = {1993},
  keywords = {Language Arts \& Disciplines / General,Language Arts \& Disciplines / Grammar \& Punctuation},
  file = {/Users/miriamamin/Documents/Zotero/storage/9WX7KVZC/Levin - 1993 - English Verb Classes and Alternations A Prelimina.pdf},
  googlebooks = {6wIZWOrcBf8C}
}

@book{pinkerLearnabilityCognitionAcquisition1989,
  address = {{Cambridge, Mass.}},
  edition = {Reprint},
  title = {{Learnability and Cognition: The Acquisition of Argument Structure}},
  isbn = {978-0-262-66073-0},
  shorttitle = {{Learnability and Cognition}},
  abstract = {When children learn a language, they soon are able to make surprisingly subtle distinctions: "donate them a book" sounds odd, for example, even though "give them a book" is perfectly natural. How can this happen, given that children do not confine themselves to the sentence types they hear, and are usually not corrected when they speak ungrammatically? Steven Pinker resolves this paradox in a detailed theory of how children acquire argument structure.In tackling a learning paradox that has challenged scholars for more than a decade, Pinker synthesizes a vast literature in linguistics and psycholinguistics and outlines explicit theories of the mental representation, learning, and development of verb meaning and verb syntax. The new theory that he describes has some surprising implications for the relation between language and thought.Pinker's solution provides insight into such key questions as, When do children generalize and when do they stick with what they hear? What is the rationale behind linguistic constraints? How is the syntax of predicates and arguments related to their semantics? What is a possible word meaning? Do languages force their speakers to construe the world in certain ways? Why does children's language seem different from that of adults? Learnability and Cognition is included in the series Learning, Development, and Conceptual Change, edited by Lila Gleitman, Susan Carey, Elissa Newport, and Elizabeth Spelke.  A Bradford Book},
  language = {Englisch},
  publisher = {{MIT Press Ltd}},
  author = {Pinker, Steven},
  year = {1989},
  file = {/Users/miriamamin/Documents/Zotero/storage/TYJTDPEC/Pinker - 1991 - Learnability and Cognition The Acquisition of Arg.pdf}
}

@incollection{talmyHowLanguageStructures1983,
  address = {{Boston, MA}},
  title = {How {{Language Structures Space}}},
  isbn = {978-1-4615-9325-6},
  abstract = {This chapter is concerned with the structure that is ascribed to space and the objects within it by linguistic ``fine structure,'' that subdivision of language which provides a fundamental conceptual framework. The primary aim of the chapter is to characterize the general properties of this structuring and the linguistic-cognitive system in which it participates.},
  language = {en},
  booktitle = {Spatial {{Orientation}}: {{Theory}}, {{Research}}, and {{Application}}},
  publisher = {{Springer US}},
  doi = {10.1007/978-1-4615-9325-6_11},
  author = {Talmy, Leonard},
  editor = {Pick, Herbert L. and Acredolo, Linda P.},
  year = {1983},
  keywords = {Linear Figure,Reference Object,Semantic Domain,Spatial Configuration,Specific Term},
  pages = {225-282},
  file = {/Users/miriamamin/Documents/Zotero/storage/T3DL8RWS/Talmy - 1983 - How Language Structures Space.pdf}
}

@book{hovavLexicalSemanticsSyntax2010,
  address = {{Oxford, New York}},
  series = {Oxford {{Studies}} in {{Theoretical Linguistics}}},
  title = {Lexical {{Semantics}}, {{Syntax}}, and {{Event Structure}}},
  isbn = {978-0-19-954432-5},
  abstract = {This book focuses on the linguistic representation of temporality in the verbal domain and its interaction with the syntax and semantics of verbs, arguments, and modifiers. Leading scholars explore the division of labour between syntax, compositional semantics, and lexical semantics in the encoding of event structure, encompassing event participants and the temporal properties associated with events. They examine the interface between event structure and the systems with which it interacts, including the interface between event structure and the syntactic realization of arguments and modifiers. Deploying a variety of frameworks and theoretical perspectives they consider central issues and questions in the field, among them whether argument-structure is specified in the lexical entries of verbs or syntactically constructed so that syntactic position determines thematic status; whether the hierarchical structure evidenced in argument structure find parallels in sign language; should the relation between members of an alternation pair, such as the causative-inchoative alternation, be understood lexically or derivationally; and the role of syntactic category in determining the configuration of argument structure.},
  publisher = {{Oxford University Press}},
  author = {Hovav, Malka Rappaport and Doron, Edit and Sichel, Ivy},
  month = feb,
  year = {2010},
  file = {/Users/miriamamin/Documents/Zotero/storage/H2K9LF9N/Hovav et al. - 2010 - Lexical Semantics, Syntax, and Event Structure.pdf;/Users/miriamamin/Documents/Zotero/storage/UKW7URBZ/lexical-semantics-syntax-and-event-structure-9780199544325.html}
}

@book{iwataLocativeAlternation2008,
  title = {Locative {{Alternation}}},
  isbn = {978-90-272-1828-5},
  language = {English},
  publisher = {{John Benjamins Publishing Company}},
  author = {Iwata, Seizi},
  year = {2008},
  file = {/Users/miriamamin/Documents/Zotero/storage/G7PTVR2N/cal.html}
}

@misc{PhraseFinder,
  title = {{{PhraseFinder}}},
  howpublished = {https://phrasefinder.io/api},
  file = {/Users/miriamamin/Documents/Zotero/storage/HUG88FWW/api.html}
}

@misc{webberWhenDidCranfield2009,
  title = {When Did the {{Cranfield}} Tests Become the ``{{Cranfield}} Paradigm''? \guillemotleft{} {{Evaluating E}}-{{Discovery}}},
  shorttitle = {When Did the {{Cranfield}} Tests Become the ``{{Cranfield}} Paradigm''?},
  language = {en-US},
  author = {Webber, William},
  year = {2009},
  file = {/Users/miriamamin/Documents/Zotero/storage/UJXTBLLF/when-did-the-cranfield-tests-become-the-cranfield-paradigm.html}
}

@misc{stackexchangeinc.StackExchange2019,
  title = {About - {{Stack Exchange}}},
  howpublished = {https://stackexchange.com/about},
  author = {{Stack Exchange Inc.}},
  year = {2019},
  file = {/Users/miriamamin/Documents/Zotero/storage/CFJUD4UU/about.html}
}

@misc{stackexchangecommunitywikiHowShouldDuplicate2017,
  title = {How Should Duplicate Questions Be Handled?},
  journal = {Meta Stack Exchange},
  howpublished = {https://meta.stackexchange.com/questions/10841/how-should-duplicate-questions-be-handled},
  author = {{Stack Exchange Community Wiki}},
  year = {2017},
  file = {/Users/miriamamin/Documents/Zotero/storage/BX969XC8/how-should-duplicate-questions-be-handled.html}
}

@misc{stackoverflowhelpcenterHowAskGood2019,
  title = {How Do {{I}} Ask a Good Question?},
  shorttitle = {How Do {{I}} Ask a Good Question?},
  journal = {Stack Overflow},
  howpublished = {https://stackoverflow.com/help/how-to-ask},
  author = {{Stack Overflow Help Center}},
  year = {2019},
  file = {/Users/miriamamin/Documents/Zotero/storage/8T5F69MF/how-to-ask.html}
}

@misc{LifehacksStackExchange,
  title = {Lifehacks {{Stack Exchange}}},
  abstract = {Q\&A for people looking to bypass life's everyday problems with simple tricks},
  journal = {Lifehacks Stack Exchange},
  howpublished = {https://lifehacks.stackexchange.com/},
  file = {/Users/miriamamin/Documents/Zotero/storage/PJF39B32/lifehacks.stackexchange.com.html}
}

@misc{lucasfijenSearchEngineStack2017,
  title = {A {{Search Engine}} for {{Stack Exchange}} Based on {{ElasticSearch}}},
  shorttitle = {A {{Search Engine}} for {{Stack Exchange}} Based on {{ElasticSearch}}},
  howpublished = {https://github.com/lucasfijen/Search\_it\_like\_its\_hot},
  author = {{Lucas Fijen}},
  year = {2017}
}

@misc{SimilarityModuleElasticsearch,
  type = {Learn/{{Docs}}/{{Elasticsearch}}/{{Reference}}/7.3},
  title = {Similarity Module | {{Elasticsearch Reference}} [7.3] | {{Elastic}}},
  abstract = {Get started with the documentation for Elasticsearch, Kibana, Logstash, Beats, X-Pack, Elastic Cloud, Elasticsearch for Apache Hadoop, and our language clients.,},
  language = {en-us},
  howpublished = {https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-similarity.html},
  file = {/Users/miriamamin/Documents/Zotero/storage/A88U7WPR/index-modules-similarity.html}
}

@misc{saucierWhatLifehack2014,
  title = {What Is a Lifehack?},
  journal = {Lifehacks Meta Stack Exchange},
  howpublished = {https://lifehacks.meta.stackexchange.com/questions/8/what-is-a-lifehack},
  author = {Saucier, Zach},
  month = dec,
  year = {2014},
  file = {/Users/miriamamin/Documents/Zotero/storage/ZM47K3XN/what-is-a-lifehack.html}
}

@incollection{rayzOntologicalSemanticTheory2017,
  title = {Ontological {{Semantic Theory}} of {{Humor}} in a Context of Humorous Discourse},
  isbn = {978-1-5015-0710-6},
  booktitle = {Humorous {{Discourse}}},
  doi = {10.1515/9781501507106-010},
  author = {Rayz, Julia},
  month = jan,
  year = {2017},
  file = {/Users/miriamamin/Documents/Zotero/storage/UPVWR5VE/Rayz - 2017 - Ontological Semantic Theory of Humor in a context .pdf}
}

@inproceedings{raskinAlgorithmicDiscoveryComputational2015a,
  title = {On {{Algorithmic Discovery}} and {{Computational Implementation}} of the {{Opposing Scripts Forming}} a {{Joke}}},
  volume = {9189},
  isbn = {978-3-319-20803-9},
  abstract = {The paper deals with the notion of `script'. Scripts have been essential for the dominant formal theories of verbal humor since their inception in the late 1970s, and the formal theories gave rise to meaningful computational humor a decade or so later. Recent developments in computational semantics and computational humor have required a tighter definition of `script' as a computational entity.},
  doi = {10.1007/978-3-319-20804-6_61},
  author = {Raskin, Victor},
  month = aug,
  year = {2015},
  pages = {671-679}
}

@book{raskinScriptBasedSemanticOntological2017a,
  title = {Script-{{Based Semantic}} and {{Ontological Semantic Theories}} of {{Humor}}},
  isbn = {978-1-138-84306-6 978-1-315-73116-2},
  abstract = {The Routledge Handbook of\&nbsp;Language and\&nbsp;Humor presents the first ever comprehensive, in-depth treatment of all the sub-fields of the linguistics of humor, broadly conceived as the intersection of the study of language and humor. The reader will find a thorough historical, terminological, and theoretical introduction to the field, as well as detailed treatments of the various approaches to language and humor. Deliberately comprehensive and wide-ranging, the handbook includes chapter-long treatments on the traditional topics covered by language and humor (e.g., teasing, laughter, irony, psycholinguistics, discourse analysis, the major linguistic theories of humor, translation) but also cutting-edge treatments of internet humor, cognitive linguistics, relevance theoretic, and corpus-assisted models of language and humor. Some chapters, such as the variationist sociolinguistcs, stylistics, and politeness are the first-ever syntheses of that particular subfield. Clusters of related chapters, such as conversation analysis, discourse analysis and corpus-assisted analysis allow multiple perspectives on complex trans-disciplinary phenomena. This handbook is an indispensable reference work for all researchers interested in the interplay of language and humor, within linguistics, broadly conceived, but also in neighboring disciplines such as literary studies, psychology, sociology, anthropology, etc. The authors are among the most distinguished scholars in their fields.},
  language = {en},
  publisher = {{Routledge Handbooks Online}},
  doi = {10.4324/9781315731162.ch9},
  author = {Raskin, Victor},
  month = feb,
  year = {2017},
  file = {/Users/miriamamin/Documents/Zotero/storage/YG8FI8NA/Raskin - 2017 - Script-Based Semantic and Ontological Semantic The.pdf;/Users/miriamamin/Documents/Zotero/storage/H58LB8WK/9781315731162.html}
}

@inproceedings{goldhahnBuildingLargeMonolingual2012,
  address = {{Istanbul, Turkey}},
  title = {Building {{Large Monolingual Dictionaries}} at the {{Leipzig Corpora Collection}}: {{From}} 100 to 200 {{Languages}}},
  shorttitle = {Building {{Large Monolingual Dictionaries}} at the {{Leipzig Corpora Collection}}},
  abstract = {The Leipzig Corpora Collection offers free online access to 136 monolingual dictionaries enriched with statistical information. In this paper we describe current advances of the project in collecting and processing text data automatically for a large number of languages. Our main interest lies in languages of "low density", where only few text data exists online. The aim of this approach is to create monolingual dictionaries and statistical information for a high number of new languages and to expand the existing dictionaries, opening up new possibilities for linguistic typology and other research. Focus of this paper will be set on the infrastructure for the automatic acquisition of large amounts of monolingual text in many languages from various sources. Preliminary results of the collection of text data will be presented. The mainly language-independent framework for preprocessing, cleaning and creating the corpora and computing the necessary statistics will also be depicted.},
  booktitle = {Proceedings of the {{Eighth International Conference}} on {{Language Resources}} and {{Evaluation}}},
  author = {Goldhahn, Dirk and Eckart, Thomas and Quasthoff, Uwe},
  month = may,
  year = {2012},
  pages = {759-765},
  file = {/Users/miriamamin/Documents/Zotero/storage/CNVFBZD3/Format_Download_File-deu.pdf;/Users/miriamamin/Documents/Zotero/storage/ITLTKY43/Goldhahn et al. - 2012 - Building Large Monolingual Dictionaries at the Lei.pdf}
}

@inproceedings{ritchieDevelopingIncongruityResolutionTheory1999,
  address = {{Edinburgh, Scotland}},
  title = {Developing the {{Incongruity}}-{{Resolution Theory}}},
  abstract = {The idea of incongruity-resolution has frequently been suggested as an account of many types of joke. However, there is no precise statement either of this "theory" nor of its main concepts (incongruity and resolution), and different authors may disagree on details. We concentrate on two particular variants and attempt to clarify what would be needed to make these into computational models.},
  booktitle = {Proceedings of the {{AISB Symposium}} on {{Creative Language}}: {{Stories}} and {{Humour}}},
  author = {Ritchie, G.},
  year = {1999},
  keywords = {Computation,Computational model,Resolution (logic)},
  pages = {pp 78-85},
  file = {/Users/miriamamin/Documents/Zotero/storage/6RA8CUXM/Ritchie - 1999 - Developing the Incongruity-Resolution Theory.pdf}
}

@misc{DigitalHumanities,
  title = {Digital Humanities},
  howpublished = {http://librarycatalog.mef.edu.tr/client/en\_US/defaulteng/search/detailnonmodal/ent:\$002f\$002fSD\_ILS\$002f0\$002fSD\_ILS:1868880/ada?qu=Information+sociale.\&qf=LANGUAGE\%09Language\%09ENG\%09English\&ps=1000},
  file = {/Users/miriamamin/Documents/Zotero/storage/3I4NJQHB/ada.html}
}

@book{anneburdickDigitalHumanities2012,
  title = {Digital {{Humanities}}},
  copyright = {http://creativecommons.org/licenses/by-nc-nd/3.0/},
  abstract = {Digital\_Humanities~is a compact, game-changing report on the state of contemporary knowledge production. Answering the question ``What~is~digital humanities?,'' it provides an in-depth examination of an emerging field. This collaboratively authored and visually compelling volume explores methodologies and techniques unfamiliar to traditional modes of humanistic inquiry\textemdash{}including geospatial analysis, data mining, corpus linguistics, visualization, and simulation\textemdash{}to show their relevance for contemporary culture. Written by five leading practitioner-theorists whose varied backgrounds embody the intellectual and creative diversity of the field,~Digital\_Humanities~is a vision statement for the future, an invitation to engage, and a critical tool for understanding the shape of new scholarship.
Authors:~Anne Burdick, Johanna Drucker, Peter Lunenfeld, Todd Presner and Jeffrey Schnapp.
This is an open access title from MIT Press:~https://mitpress.mit.edu/books/digitalhumanities},
  language = {eng},
  publisher = {{MIT Press}},
  author = {{Anne Burdick}},
  collaborator = {{Johanna Drucker} and {Peter Lunenfeld} and {Todd Presner} and {Jeffrey Schnapp}},
  year = {2012},
  keywords = {Digital humanities}
}

@misc{matthewsMeronymy2007,
  title = {Meronymy},
  volume = {3},
  isbn = {978-0-19-920272-0},
  abstract = {Fully revised and updated for the second edition, this invaluable work is the most authoritative dictionary of linguistics of its kind available.The dictionary covers every aspect of this multidisciplinary field, including sociolinguistics, language theory and history, language families, and major languages from all over the world (including major national/regional dialects), phonetics, formal semantics, and key figures and ideas in linguistics.With over 150 new entries, the dictionary now boasts greatly enhanced coverage of sociolinguistics, new entries on notable recent theorists in the field, such as Del Hymes and Peter Trudgill, and expanded coverage of regional dialects, such as Estuary English. Wide-ranging and accessible, this dictionary is an ideal reference for undergraduate students and teachers in language-related courses, and a great introduction to linguistics for the general reader with an interest in the theory and structure of language.},
  language = {en\_US},
  journal = {The Concise Oxford Dictionary of Linguistics},
  publisher = {{Oxford University Press}},
  author = {Matthews, P. H.},
  month = jan,
  year = {2007},
  keywords = {Linguistics},
  file = {/Users/miriamamin/Documents/Zotero/storage/RQS75XZG/acref-9780199202720.html}
}

@misc{bussmannHomonymy1998,
  address = {{London}},
  edition = {2},
  title = {{Homonymy}},
  isbn = {978-0-415-20319-7},
  abstract = {In over 2,500 entries, this Dictionary provides an exhaustive survey of the key terminology and languages of more than thirty sub-disciplines of linguistics.},
  language = {Englisch},
  journal = {Routledge Dictionary of Language and Linguistics},
  publisher = {{Routledge}},
  author = {Bussmann, Hadumod and Trauth, Gregory and Kazzazi, Kerstin},
  month = mar,
  year = {1998},
  file = {/Users/miriamamin/Documents/Zotero/storage/5IRHN6RJ/Bussmann et al_1998_Routledge Dictionary of Language and Linguistics.pdf}
}

@misc{bussmannHyponymy1998,
  address = {{London}},
  edition = {2},
  title = {{Hyponymy}},
  isbn = {978-0-415-20319-7},
  abstract = {In over 2,500 entries, this Dictionary provides an exhaustive survey of the key terminology and languages of more than thirty sub-disciplines of linguistics.},
  language = {Englisch},
  journal = {Routledge Dictionary of Language and Linguistics},
  publisher = {{Routledge}},
  author = {Bussmann, Hadumod and Trauth, Gregory and Kazzazi, Kerstin},
  month = mar,
  year = {1998}
}

@misc{speerCommonsenseConceptnet52019,
  title = {Commonsense/Conceptnet5},
  abstract = {Code for building ConceptNet from raw data. Contribute to commonsense/conceptnet5 development by creating an account on GitHub.},
  language = {en},
  journal = {GitHub},
  howpublished = {https://github.com/commonsense/conceptnet5},
  author = {Speer, Robyn},
  year = {2019},
  file = {/Users/miriamamin/Documents/Zotero/storage/W2RNDUV7/wiki.html}
}

@misc{googlesearchappliancehelpCountNumberSearch2019,
  title = {The Count of the Number of Search Results Is Incorrect},
  howpublished = {https://support.google.com/gsa/answer/2672285?hl=en},
  author = {{Google Search Appliance Help}},
  year = {2019},
  file = {/Users/miriamamin/Documents/Zotero/storage/86GI7NW7/2672285.html}
}

@inproceedings{radfordLanguageModelsAre2019,
  title = {Language {{Models}} Are {{Unsupervised Multitask Learners}}},
  abstract = {Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.},
  booktitle = {Technical {{Report OpenAi}}},
  author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year = {2019},
  keywords = {Language model,Text corpus,Machine learning,Natural language processing,Baseline (configuration management),Acute Motor Axonal Neuropathy,Arabic numeral 0,Coherence (physics),Computer multitasking,Handling (Psychology),Hypertext,Log-linear model,Machine translation,Open reading frame,paragraphs,Perplexity,Protein Truncation Abnormality,Question answering,Robustness (computer science),Sampling (signal processing),Supervised learning,Test set,Transformer,While,Zak McKracken and the Alien Mindbenders},
  file = {/Users/miriamamin/Documents/Zotero/storage/RKI76ZHN/Radford et al_2019_Language Models are Unsupervised Multitask Learners.pdf}
}

@misc{ghelaniWordEmbeddingsPretrained2019,
  title = {From {{Word Embeddings}} to {{Pretrained Language Models}} \textemdash{} {{A New Age}} in {{NLP}} \textemdash{} {{Part}} 1},
  abstract = {For words to be processed by machine learning models, they need some form of numeric representation that models can use in their\ldots{}},
  language = {en},
  journal = {Medium},
  howpublished = {https://towardsdatascience.com/from-word-embeddings-to-pretrained-language-models-a-new-age-in-nlp-part-1-7ed0c7f3dfc5},
  author = {Ghelani, Shreya},
  month = may,
  year = {2019},
  file = {/Users/miriamamin/Documents/Zotero/storage/3BEUL2YS/from-word-embeddings-to-pretrained-language-models-a-new-age-in-nlp-part-1-7ed0c7f3dfc5.html}
}

@misc{ghelaniWordEmbeddingsPretrained2019a,
  title = {From {{Word Embeddings}} to {{Pretrained Language Models}} \textemdash{} {{A New Age}} in {{NLP}} \textemdash{} {{Part}} 2},
  abstract = {For words to be processed by machine learning models, they need some form of numeric representation that models can use in their\ldots{}},
  language = {en},
  journal = {Medium},
  howpublished = {https://towardsdatascience.com/from-word-embeddings-to-pretrained-language-models-a-new-age-in-nlp-part-2-e9af9a0bdcd9},
  author = {Ghelani, Shreya},
  month = may,
  year = {2019},
  file = {/Users/miriamamin/Documents/Zotero/storage/XY8KZQYI/from-word-embeddings-to-pretrained-language-models-a-new-age-in-nlp-part-2-e9af9a0bdcd9.html}
}

@misc{woolfHowMakeCustom2019,
  title = {How {{To Make Custom AI}}-{{Generated Text With GPT}}-2},
  abstract = {Thanks to gpt-2-simple and this Colaboratory Notebook, you can easily finetune GPT-2 on your own dataset!},
  language = {en-us},
  journal = {Max Woolf's Blog},
  howpublished = {https://minimaxir.com/2019/09/howto-gpt2/},
  author = {Woolf, Max},
  month = sep,
  year = {2019},
  file = {/Users/miriamamin/Documents/Zotero/storage/7NFYNE4G/howto-gpt2.html}
}

@article{woolfMinimaxirGpt2simple2019,
  title = {Minimaxir/Gpt-2-Simple},
  abstract = {Python package to easily retrain OpenAI's GPT-2 text-generating model on new texts},
  journal = {GitHub repository},
  author = {Woolf, Max},
  month = sep,
  year = {2019},
  keywords = {openai,tensorflow,text-generation,textgenrnn},
  note = {https://github.com/minimaxir/gpt-2-simple}
}

@article{michelQuantitativeAnalysisCulture2011,
  title = {Quantitative {{Analysis}} of {{Culture Using Millions}} of {{Digitized Books}}},
  volume = {331},
  abstract = {We constructed a corpus of digitized texts containing about 4\% of all books ever printed. Analysis of this corpus enables
us to investigate cultural trends quantitatively. We survey the vast terrain of `culturomics,' focusing on linguistic and
cultural phenomena that were reflected in the English language between 1800 and 2000. We show how this approach can provide
insights about fields as diverse as lexicography, the evolution of grammar, collective memory, the adoption of technology,
the pursuit of fame, censorship, and historical epidemiology. Culturomics extends the boundaries of rigorous quantitative
inquiry to a wide array of new phenomena spanning the social sciences and the humanities.},
  journal = {Science (New York, N.Y.)},
  doi = {10.1126/science.1199644},
  author = {Michel, Jean-Baptiste and Shen, Yuan and Aiden, Aviva and Veres, Adrian and Gray, Matthew and Pickett, Joseph and Hoiberg, Dale and Clancy, Dan and Norvig, Peter and Orwant, Jon and Pinker, Steven and Nowak, Martin and Aiden, Erez},
  month = jan,
  year = {2011},
  pages = {176-82},
  file = {/Users/miriamamin/Documents/Zotero/storage/QCEUMD7A/Michel et al_2011_Quantitative Analysis of Culture Using Millions of Digitized Books.pdf}
}

@inproceedings{linSyntacticAnnotationsGoogle2012,
  address = {{Stroudsburg, PA, USA}},
  series = {{{ACL}} '12},
  title = {Syntactic {{Annotations}} for the {{Google Books Ngram Corpus}}},
  abstract = {We present a new edition of the Google Books Ngram Corpus, which describes how often words and phrases were used over a period of five centuries, in eight languages; it reflects 6\% of all books ever published. This new edition introduces syntactic annotations: words are tagged with their part-of-speech, and head-modifier relationships are recorded. The annotations are produced automatically with statistical models that are specifically adapted to historical text. The corpus will facilitate the study of linguistic trends, especially those related to the evolution of syntax.},
  booktitle = {Proceedings of the {{ACL}} 2012 {{System Demonstrations}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Lin, Yuri and Michel, Jean-Baptiste and Aiden, Erez Lieberman and Orwant, Jon and Brockman, Will and Petrov, Slav},
  year = {2012},
  pages = {169--174},
  file = {/Users/miriamamin/Documents/Zotero/storage/LU5IFPZX/Lin et al_2012_Syntactic Annotations for the Google Books Ngram Corpus.pdf}
}

@misc{googleGoogleNgramViewer2013,
  title = {Google {{Ngram Viewer}}},
  howpublished = {http://storage.googleapis.com/books/ngrams/books/datasetsv2.html},
  author = {{Google}},
  year = {2013},
  file = {/Users/miriamamin/Documents/Zotero/storage/2MCCGALV/datasetsv2.html}
}

@misc{henrydevalenceFunGoogleNgrams2014,
  title = {Fun with {{Google}} N-Grams Data (Part 1)},
  author = {{Henry de Valence}},
  month = may,
  year = {2014},
  file = {/Users/miriamamin/Documents/Zotero/storage/JGSKVYBQ/2014-02-05-fun-with-the-google-ngrams-data.html}
}

@inproceedings{petrovicUnsupervisedJokeGeneration2013,
  address = {{Sofia, Bulgaria}},
  title = {Unsupervised Joke Generation from Big Data},
  booktitle = {Proceedings of the 51st {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 2: {{Short Papers}})},
  publisher = {{Association for Computational Linguistics}},
  author = {Petrovi{\'c}, Sa{\v s}a and Matthews, David},
  month = aug,
  year = {2013},
  keywords = {humor generation,rule driven},
  pages = {228--232},
  file = {/Users/miriamamin/Documents/Zotero/storage/AXRNQY9G/Petrović_Matthews_2013_Unsupervised joke generation from big data.pdf;/Users/miriamamin/Documents/Zotero/storage/QRZ6JUFW/Petrovic_Matthews_2013_Unsupervised joke generation from big data.pdf},
  annote = {Petrovic and Matthews generate joke of the pattern ,I like my X like I like my Y, Z` by encoding the semantic relationships between the variables as functions and finding the best fitting words in the Google n-gram corpus algorithmically. Besides the precondition that X and Y are nouns, and Z is an adjective, the model is based on the following assumptions: 1. The adjective should be relevant for both of the nouns. The model calculates the co-occurrence probability from the Google2-gram corpus (ignoring 2-grams with less than 1000 occurrences). 2. The less common the attribute Z, the funnier the joke. This is encoded as the reciprocal frequency of Z in the corpus. 3. The more ambiguous the attribute, the funnier the joke. The authors represent this as the reciprocal of the number of senses of Z., retrieved from WordNet. 4. The more dissimilar the nouns are, the funnier the joke. To measure the similarity, the model calculates the cosine of the angle between the two nouns, represented as vectors of all attributes used to describe them in the corpus. Dissimilarity is represented as the reciprocal similarity of X and Y. Overall they assume, that a joke is funnier, the higher the product of all factors, i.e. the funniness probability, given a triple (X, Y, Z), normalized over all triples. For joke calculation, the authors fix one of the nouns because of limitations in computing capacity. Examples of the generated jokes are: `I like my relationship like I like my source, open.' or ` I like my coffe like I like my war, cold.' For human evaluation, they present the 30 most probable jokes for a given X as well as human generated jokes of this pattern to test persons. The evaluation showed that their model produced 16.3 \% funny jokes, whereas the humans produced 33 \% funny jokes. The assumption, that joke funniness is equal to the product of all factor was later challenged by Winters et al.. They used the same factor representation, but used machine learning to adjust the weights to which the single factors contribute to the overall funniness (see section humor adaption).}
}

@book{birdNaturalLanguageProcessing2009,
  address = {{Beijing ; Cambridge [Mass.]}},
  edition = {1st ed},
  title = {Natural Language Processing with {{Python}}},
  isbn = {978-0-596-51649-9},
  lccn = {QA76.73.P98 B57 2009},
  abstract = {This is an introduction to natural language processing, which supports a variety of language technologies, from predictive text and email filtering to automatic summarization and translation},
  publisher = {{O'Reilly}},
  author = {Bird, Steven and Klein, Ewan and Loper, Edward},
  year = {2009},
  keywords = {Natural language processing (Computer science),Python (Computer program language),Python <Programmiersprache>,Sprachverarbeitung},
  note = {OCLC: ocn301885973},
  annote = {"Analyzing text with the natural language toolkit"--Cover}
}

@misc{cognitivesciencelaboratoryprincetonnjWordNetCDROMApple1998,
  title = {{{WordNet}} 1.6 {{CD}}-{{ROM}} for {{Apple Macintosh Computer}} and {{Windows}} 3.1, {{Windows}} 95, {{Windows NT}}},
  language = {English},
  publisher = {{MIT Press}},
  author = {{Cognitive Science Laboratory (Princeton NJ)}},
  year = {1998},
  note = {OCLC: 174556501}
}

@misc{princetonuniversityWordNet2010,
  title = {About {{WordNet}}.},
  howpublished = {https://wordnet.princeton.edu/},
  author = {{Princeton University}},
  year = {2010},
  file = {/Users/miriamamin/Documents/Zotero/storage/GZADEWCK/wordnet.princeton.edu.html}
}

@misc{guptaOverviewTextSimilarity2019,
  title = {Overview of {{Text Similarity Metrics}} in {{Python}}},
  abstract = {While working on natural language models for search engines, I have frequently asked questions ``How similar are these two words?'', ``How\ldots{}},
  language = {en},
  journal = {Medium},
  howpublished = {https://towardsdatascience.com/overview-of-text-similarity-metrics-3397c4601f50},
  author = {Gupta, Sanket},
  month = jun,
  year = {2019},
  file = {/Users/miriamamin/Documents/Zotero/storage/3T3ZVIWB/overview-of-text-similarity-metrics-3397c4601f50.html}
}

@inproceedings{mckinneyDataStructuresStatistical2010,
  title = {Data {{Structures}} for {{Statistical Computing}} in {{Python}}},
  booktitle = {Proceedings of the 9th {{Python}} in {{Science Conference}}},
  author = {McKinney, Wes},
  year = {2010},
  pages = {51-56},
  file = {/Users/miriamamin/Documents/Zotero/storage/CLA9QYTB/McKinney_2010_Data Structures for Statistical Computing in Python.pdf;/Users/miriamamin/Documents/Zotero/storage/JQPVKYIM/mckinney.html}
}

@book{oliphantGuideNumPy2015,
  address = {{Austin, Tex.}},
  title = {Guide to {{NumPy}}},
  isbn = {978-1-5173-0007-4},
  language = {English},
  publisher = {{Continuum Press}},
  author = {Oliphant, Travis E},
  year = {2015},
  note = {OCLC: 982090469}
}

@article{pedregosaScikitlearnMachineLearning2011,
  title = {Scikit-Learn: {{Machine Learning}} in {{Python}}},
  volume = {12},
  issn = {1533-7928},
  shorttitle = {Scikit-Learn},
  abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language.  Emphasis is put on ease of use, performance, documentation, and API consistency.  It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings.  Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
  journal = {Journal of Machine Learning Research},
  author = {Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, {\'E}douard},
  month = oct,
  year = {2011},
  pages = {2825-2830},
  file = {/Users/miriamamin/Documents/Zotero/storage/MEJYF93Z/Pedregosa et al_2011_Scikit-learn.pdf}
}

@unpublished{radfordImprovingLanguageUnderstanding2018,
  type = {Unpublished Paper.},
  title = {Improving {{Language Understanding}} by {{Generative Pre}}-{{Training}}},
  author = {Radford, Alec and Narasimhan, Karthik and Saliman, Tim and Sutskever, Ilya},
  year = {2018},
  file = {/Users/miriamamin/Documents/Zotero/storage/ABYWADRE/Radford et al. - Improving Language Understanding by Generative Pre.pdf}
}

@misc{170603762Attention,
  title = {[1706.03762] {{Attention Is All You Need}}},
  howpublished = {https://arxiv.org/abs/1706.03762},
  file = {/Users/miriamamin/Documents/Zotero/storage/WFBGIKP2/1706.html}
}

@inproceedings{vaswaniAttentionAllYou2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1706.03762},
  address = {{Vancouver, Canada}},
  title = {Attention {{Is All You Need}}},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  booktitle = {Proceedings of the {{The Sixth International Conference}} on {{Learning Representations}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  month = jun,
  year = {2017},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/miriamamin/Documents/Zotero/storage/PYT25A2M/Vaswani et al. - 2017 - Attention Is All You Need.pdf;/Users/miriamamin/Documents/Zotero/storage/SFS6Z76L/1706.html},
  annote = {Comment: 15 pages, 5 figures}
}

@misc{allardWhatTransformer2019,
  title = {What Is a {{Transformer}}?},
  abstract = {An Introduction to Transformers and Sequence-to-Sequence Learning for Machine Learning},
  language = {en},
  journal = {Medium},
  howpublished = {https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04},
  author = {Allard, Maxime},
  month = jul,
  year = {2019},
  file = {/Users/miriamamin/Documents/Zotero/storage/LHWD93SF/what-is-a-transformer-d07dd1fbec04.html}
}

@misc{nicholsonBeginnerGuideAttention,
  title = {A {{Beginner}}'s {{Guide}} to {{Attention Mechanisms}} and {{Memory Networks}}},
  abstract = {Attention mechanisms are components of memory networks, which focus their attention on external memory storage rather than a sequence of hidden states in an RNN.},
  language = {en},
  journal = {Skymind},
  howpublished = {http://skymind.ai/wiki/attention-mechanism-memory-network},
  author = {Nicholson, Chris},
  file = {/Users/miriamamin/Documents/Zotero/storage/QKHZNK3W/attention-mechanism-memory-network.html}
}

@misc{radfordBetterLanguageModels2019,
  title = {Better {{Language Models}} and {{Their Implications}}},
  abstract = {We've trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization.},
  language = {en},
  journal = {OpenAI},
  author = {Radford, Alec and Wu, Jeffrey and Amodei, Dario and Amodei, Daniela and Clark, Jack and Brundage, Miles and Sutskever, Ilya},
  month = feb,
  year = {2019},
  file = {/Users/miriamamin/Documents/Zotero/storage/AR8FZBLD/better-language-models.html}
}

@misc{woolfGoogleColaboratoryTrain2019,
  title = {Google {{Colaboratory}} | {{Train}} a {{GPT}}-2 {{Text}}-{{Generating Model}} w/ {{GPU For Free}}},
  language = {en},
  howpublished = {https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce},
  author = {Woolf, Max},
  month = aug,
  year = {2019},
  file = {/Users/miriamamin/Documents/Zotero/storage/LBKPYLGA/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce.html}
}

@misc{GoogleColaboratoryWelcome,
  title = {Google {{Colaboratory}} | {{Welcome}} to {{Colaboratory}}!},
  language = {en},
  howpublished = {https://colab.research.google.com/notebooks/welcome.ipynb\#scrollTo=-Rh3-Vt9Nev9},
  file = {/Users/miriamamin/Documents/Zotero/storage/6NLL5TPB/welcome.html}
}

@misc{googleColaboratoryGoogle,
  title = {Colaboratory \textendash{} {{Google}}},
  howpublished = {https://research.google.com/colaboratory/faq.html},
  author = {{Google}},
  file = {/Users/miriamamin/Documents/Zotero/storage/BWSYPZ3H/faq.html}
}

@article{pungasDatasetEnglishPlaintext2017,
  title = {A Dataset of {{English}} Plaintext Jokes.},
  journal = {GitHub repository},
  author = {Pungas, Taivo},
  year = {2017},
  note = {https://github.com/taivop/joke-dataset}
}

@article{roznovjakQuestionAnswerJokes2017,
  title = {Question-{{Answer Jokes}}},
  abstract = {Jokes of the question-answer form from Reddit's r/jokes},
  journal = {Kaggle},
  author = {Roznovjak, Jiri},
  year = {2017},
  file = {/Users/miriamamin/Documents/Zotero/storage/Y39H5KGJ/qa-jokes.html},
  note = {https://kaggle.com/jiriroz/qa-jokes}
}

@book{manningIntroductionInformationRetrieval2008,
  address = {{New York}},
  title = {Introduction to Information Retrieval},
  isbn = {978-0-521-86571-5},
  lccn = {QA76.9.T48 M26 2008},
  publisher = {{Cambridge University Press}},
  author = {Manning, Christopher D. and Raghavan, Prabhakar and Sch{\"u}tze, Hinrich},
  year = {2008},
  keywords = {Document clustering,Information retrieval,Semantic Web,Text processing (Computer science)},
  note = {OCLC: ocn190786122}
}

@book{shiblesHumorReferenceGuide1998,
  title = {Humor {{Reference Guide}}: {{A Comprehensive Classification}} and {{Analysis}}},
  isbn = {978-0-8093-2097-4},
  shorttitle = {Humor {{Reference Guide}}},
  language = {English},
  publisher = {{Southern Illinois Univ Pr}},
  author = {Shibles, Warren A.},
  month = mar,
  year = {1998},
  note = {accessible online at https://web.archive.org/web/20070928195929/http://facstaff.uww.edu/shiblesw/humorbook/}
}

@misc{matthewsPerlocutionary2014,
  title = {Perlocutionary},
  isbn = {978-0-19-967512-8},
  abstract = {Term applied in the theory of *speech acts to the effect brought about by an utterance in the particular circumstances in which it is uttered. ......},
  language = {en},
  journal = {The Concise Oxford Dictionary of Linguistics},
  publisher = {{Oxford University Press}},
  author = {Matthews, P. H.},
  month = may,
  year = {2014},
  file = {/Users/miriamamin/Documents/Zotero/storage/SI6PRIV3/acref-9780199675128-e-2503.html}
}

@incollection{sulsTwoStageModelAppreciation1972,
  title = {A {{Two}}-{{Stage Model}} for the {{Appreciation}} of {{Jokes}} and {{Cartoons}}: {{An Information}}-{{Processing Analysis}}},
  isbn = {978-0-12-288950-9},
  shorttitle = {A {{Two}}-{{Stage Model}} for the {{Appreciation}} of {{Jokes}} and {{Cartoons}}},
  language = {en},
  booktitle = {The {{Psychology}} of {{Humor}}},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-0-12-288950-9.50010-9},
  author = {Suls, Jerry M.},
  year = {1972},
  pages = {81-100}
}

@incollection{minskyJokesLogicCognitive1984,
  address = {{Dordrecht}},
  series = {Synthese {{Language Library}}},
  title = {Jokes and the {{Logic}} of the {{Cognitive Unconscious}}},
  isbn = {978-94-010-9188-6},
  abstract = {Freud's theory of jokes explains how they overcome the mental ``censors'' that make it hard for us to think ``forbidden'' thoughts. But his theory did not work so well for humorous nonsense as for other comical subjects. In this essay I argue that the different forms of humor can be seen as much more similar, once we recognize the importance of knowledge about knowledge and, particularly, aspects of thinking concerned with recognizing and suppressing bugs \textemdash{} ineffective or destructive thought processes. When seen in this light, much humor that at first seems pointless, or mysterious, becomes more understandable.},
  language = {en},
  booktitle = {Cognitive {{Constraints}} on {{Communication}}: {{Representations}} and {{Processes}}},
  publisher = {{Springer Netherlands}},
  doi = {10.1007/978-94-010-9188-6_10},
  author = {Minsky, Marvin},
  editor = {Vaina, Lucia and Hintikka, Jaakko},
  year = {1984},
  keywords = {Faulty Reasoning,Mental Society,Mystical Experience,Truth Maintenance System,Yield Truth},
  pages = {175-200},
  file = {/Users/miriamamin/Documents/Zotero/storage/3GV74E5N/Minsky - 1984 - Jokes and the Logic of the Cognitive Unconscious.pdf}
}

@article{shultzDevelopmentAppreciationRiddles1974,
  title = {Development of the {{Appreciation}} of {{Riddles}}},
  volume = {45},
  issn = {0009-3920},
  abstract = {A study of the development of children's appreciation of riddles was conducted within the framework of the incongruity and resolution theory of humor. Children of 6, 8, 10, and 12 years of age were presented with a series of original, resolution-removed, and incongruity-removed riddles of various resolution types. Measures of the child's appreciation and comprehension of each riddle were obtained. As in previous research with jokes, the results indicated that children of 8 years and older appreciated the resolvable nature of incongruities, while 6-year-olds did not. This was considered as evidence for a developmental theory of humor which postulates an early stage characterized by the appreciation of pure incongruity and a later stage characterized by a differential preference for resolvable incongruity. The results also revealed certain differences between the appreciation of jokes and riddles which were interpreted in terms of the problem-solving nature of riddles.},
  number = {1},
  journal = {Child Development},
  doi = {10.2307/1127755},
  author = {Shultz, Thomas R.},
  year = {1974},
  pages = {100-105}
}

@book{freedmanHowManyZen1980,
  address = {{New York}},
  title = {How {{Many Zen Buddhists Does It Take}} to {{Screw}} in a {{Lightbulb}}?},
  isbn = {978-0-312-39527-8},
  abstract = {In the humorous tradition of simplistic elephant jokes and Helen Keller jibes, this collection mercilessly spoofs politics, religion, and ethnic cultures in the newest fad of light bulb jokes},
  language = {English},
  publisher = {{St Martins Pr}},
  author = {Freedman, Matt},
  month = sep,
  year = {1980}
}

@book{esarHumorHumorArt1952,
  address = {{New York}},
  title = {The {{Humor}} of {{Humor}}: {{The Art}} and {{Techiques}} of {{Popular Comedy Illustrated}} by {{Comic Sayings}}, {{Funny Stories}}, and {{Jocular Traditions}}, {{Through}} the {{Centuries}}},
  shorttitle = {The {{Humor}} of {{Humor}}},
  publisher = {{The Horizon Press}},
  author = {Esar, Evan},
  year = {1952},
  note = {Quantity Available: 1}
}

@article{clementsTypesPolackJoke1973,
  series = {3},
  title = {The {{Types}} of the {{Polack Joke}}},
  abstract = {Revised edition, with a Foreward and Introduction by the series editors.},
  language = {en\_US},
  journal = {Folklore Forum Bibliographic and Special Series},
  author = {Clements, William M.},
  year = {1973},
  file = {/Users/miriamamin/Documents/Zotero/storage/FWEH5G6I/Clements - 1973 - The Types of the Polack Joke.pdf;/Users/miriamamin/Documents/Zotero/storage/XSMMWP8Q/2646.html}
}

@article{gwenackermanRobotSingsEurovision2019,
  title = {Robot {{Sings Eurovision Kitsch Composed}} by {{Oracle AI}}, {{Israelis}}},
  abstract = {What do you get when you cross a computer with some corny lyrics? A Eurovision song, apparently.},
  language = {en},
  journal = {Bloomberg.com},
  author = {{Gwen Ackerman}},
  month = may,
  year = {2019},
  keywords = {United States,Americas,Artificial Intelligence,Emerging Markets,Israel,Middle East,ORACLE CORP,Software Company,technology,Tel Aviv,Youtube},
  file = {/Users/miriamamin/Documents/Zotero/storage/29D8BML5/robot-sings-eurovision-kitsch-composed-by-oracle-ai-israelis.html}
}

@misc{drakeBlueJeansBloody2019,
  title = {Blue {{Jeans}} and {{Bloody Tears}}},
  abstract = {Hear how Oracle created a Eurovision style song with AI},
  journal = {Oracle UK},
  author = {Drake, James},
  month = may,
  year = {2019},
  file = {/Users/miriamamin/Documents/Zotero/storage/LKHBF35X/blue-jeans-and-bloody-tears.html}
}

@inproceedings{blinovLargeDatasetLanguage2019,
  address = {{Florence, Italy}},
  title = {Large {{Dataset}} and {{Language Model Fun}}-{{Tuning}} for {{Humor Recognition}}},
  abstract = {The task of humor recognition has attracted a lot of attention recently due to the urge to process large amounts of user-generated texts and rise of conversational agents. We collected a dataset of jokes and funny dialogues in Russian from various online resources and complemented them carefully with unfunny texts with similar lexical properties. The dataset comprises of more than 300,000 short texts, which is significantly larger than any previous humor-related corpus. Manual annotation of 2,000 items proved the reliability of the corpus construction approach. Further, we applied language model fine-tuning for text classification and obtained an F1 score of 0.91 on a test set, which constitutes a considerable gain over baseline methods. The dataset is freely available for research community.},
  booktitle = {Proceedings of the 57th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  publisher = {{Association for Computational Linguistics}},
  doi = {10.18653/v1/P19-1394},
  author = {Blinov, Vladislav and {Bolotova-Baranova}, Valeria and Braslavski, Pavel},
  month = jul,
  year = {2019},
  pages = {4027--4032},
  file = {/Users/miriamamin/Documents/Zotero/storage/PVV49HPR/Blinov et al. - 2019 - Large Dataset and Language Model Fun-Tuning for Hu.pdf}
}

@book{raskinSemanticMechanismsHumor1984,
  address = {{Dordrecht}},
  title = {Semantic {{Mechanisms}} of {{Humor}}},
  isbn = {978-94-009-6472-3},
  abstract = {GOAL This is the funniest book I have ever written - and the ambiguity here is deliberate. Much of this book is about deliberate ambiguity, described as unambiguously as possible, so the previous sentence is probably the fIrst, last, and only deliberately ambiguous sentence in the book. Deliberate ambiguity will be shown to underlie much, if not all, of verbal humor. Some of its forms are simple enough to be perceived as deliberately ambiguous on the surface; in others, the ambiguity results from a deep semantic analysis. Deep semantic analysis is the core of this approach to humor. The book is the fIrst ever application of modem linguistic theory to the study of humor and it puts forward a formal semantic theory of verbal humor. The goal of the theory is to formulate the necessary and sufficient conditions, in purely semantic terms, for a text to be funny. In other words, if a formal semantic analysis of a text yields a certain set of semantic proptrties which the text possesses, then the text is recognized as a joke. As any modem linguistic theory, this semantic theory of humor attempts to match a natural intuitive ability which the native speaker has, in this particular case, the ability to perceive a text as funny, i. e., to distinguish a joke from a non-joke.},
  language = {English},
  publisher = {{Springer Netherlands}},
  author = {Raskin, Victor},
  year = {1984},
  note = {OCLC: 851368534}
}

@book{songOxfordHandbookLinguistic2013,
  address = {{Oxford}},
  edition = {Reprint},
  title = {{The Oxford Handbook of Linguistic Typology}},
  isbn = {978-0-19-965840-4},
  abstract = {This handbook provides a critical state-of-the-art overview of work in linguistic typology. It examines the directions and challenges of current research and shows how these reflect and inform work on the development of linguistic theory. It describes what typologists have revealed about language in general and discovered (and continue to discover) about the richly various ways in which meaning and expression are achieved in the world's languages. Typological research extends across all branches of linguistics. The degree to which the characteristics of language are universal or particular is crucial to the understanding of language and its relation to human nature and culture. This book is an essential source of reference for linguists of all theoretical persuasions. It is a vital companion for all those working in linguistic typology or undertaking linguistic fieldwork on one or more languages.},
  language = {Englisch},
  publisher = {{Oxford University Press}},
  author = {Song, Jae Jung},
  month = may,
  year = {2013},
  file = {/Users/miriamamin/Documents/Zotero/storage/TXYXM7CZ/[Jae_Jung_Song]_The_Oxford_Handbook_of_Linguistic_(z-lib.org).pdf}
}

@incollection{evansSemanticTypology2010,
  title = {Semantic {{Typology}}},
  booktitle = {The {{Oxford Handbook}} of {{Linguistic Typology}}},
  publisher = {{Oxford University Press}},
  doi = {10.1093/oxfordhb/9780199281251.013.0024},
  author = {Evans, Nicholas},
  editor = {Song, Jae Jung},
  month = nov,
  year = {2010},
  file = {/Users/miriamamin/Documents/Zotero/storage/8J9EQFTG/[Jae_Jung_Song]_The_Oxford_Handbook_of_Linguistic_(z-lib.org).pdf}
}

@incollection{koptjevskaja-tammApproachingLexicalTypology2008,
  title = {Approaching Lexical Typology},
  abstract = {The paper aims at situating the research direction presented in the volume within the larger domain of typological research in general. It gives a short summary of what is meant by typological research, discusses the relation between semantic and lexical typology and the general premises for lexical-typological research. The bulk of the paper is devoted to the three main lexical-typological research foci \textendash{} what meanings can(not) be expressed by a single word, what different meanings can be expressed by one and the same lexeme or by words derivationally related to each other, and what cross-linguistic patterns there are in lexicon-grammar interaction. The paper ends up with the general discussion of the urgent methodological problems facing lexical typology as a field.},
  language = {English},
  booktitle = {From {{Polysemy}} to {{Semantic Change}}: {{Towards}} a Typology of Lexical Semantic Associations},
  author = {{Koptjevskaja-Tamm}, Maria},
  editor = {Vanhove, Martine},
  year = {2008},
  pages = {p. 3--52},
  file = {/Users/miriamamin/Documents/Zotero/storage/CYF77X6U/Koptjevskaja-Tamm_Approaching lexical typology.pdf;/Users/miriamamin/Documents/Zotero/storage/IKVVVHQK/slcs.106.html}
}

@article{nerloveSiblingTerminologyCrossSex1967,
  title = {Sibling {{Terminology}} and {{Cross}}-{{Sex Behavior}}},
  volume = {69},
  issn = {0002-7294},
  abstract = {This paper examines variations among sibling terminologies and suggests a functional explanation for selected aspects of the differences among systems. It presents evidence to suggest that behavior that places emphasis on cross-sex relations will tend to produce terminologies in which siblings of the same sex are distinguished from siblings of the opposite sex. A possible typology of kinds of sibling terminologies is given.},
  number = {2},
  journal = {American Anthropologist},
  author = {Nerlove, Sara and Romney, A. Kimball},
  year = {1967},
  pages = {179-187},
  file = {/Users/miriamamin/Documents/Zotero/storage/IZMNHRWY/Nerlove_Romney_1967_Sibling Terminology and Cross-Sex Behavior.pdf}
}

@article{morrillBasicColorTerms1971,
  title = {Basic {{Color Terms}}: {{Their Universality}} and {{Evolution}}.},
  volume = {6},
  issn = {00251496},
  shorttitle = {Basic {{Color Terms}}},
  number = {1},
  journal = {Man},
  doi = {10.2307/2798490},
  author = {Morrill, W. T. and Berlin, Brent and Kay, Paul},
  month = mar,
  year = {1971},
  pages = {151},
  file = {/Users/miriamamin/Documents/Zotero/storage/JDDGC7ZU/Morrill et al_1971_Basic Color Terms.pdf}
}

@article{berlinGeneralPrinciplesClassification1973,
  title = {General {{Principles}} of {{Classification}} and {{Nomenclature}} in {{Folk Biology}}},
  volume = {75},
  issn = {0002-7294, 1548-1433},
  language = {en},
  number = {1},
  journal = {American Anthropologist},
  doi = {10.1525/aa.1973.75.1.02a00140},
  author = {Berlin, Brent and Breedlove, Dennis E. and Raven, Peter H.},
  month = feb,
  year = {1973},
  pages = {214-242},
  file = {/Users/miriamamin/Documents/Zotero/storage/D6IE3X7U/Berlin et al_1973_General Principles of Classification and Nomenclature in Folk Biology.pdf}
}

@article{berlinGeneralPrinciplesClassification1973a,
  title = {General {{Principles}} of {{Classification}} and {{Nomenclature}} in {{Folk Biology}}},
  volume = {75},
  issn = {0002-7294, 1548-1433},
  language = {en},
  number = {1},
  journal = {American Anthropologist},
  doi = {10.1525/aa.1973.75.1.02a00140},
  author = {Berlin, Brent and Breedlove, Dennis E. and Raven, Peter H.},
  month = feb,
  year = {1973},
  pages = {214-242},
  file = {/Users/miriamamin/Documents/Zotero/storage/HBN2WMYS/Berlin et al. - 1973 - General Principles of Classification and Nomenclat.pdf}
}

@incollection{andersenLexicalUniversalsBodyPart1978,
  address = {{Stanford, CA}},
  title = {Lexical {{Universals}} of {{Body}}-{{Part Terminology}}},
  volume = {3},
  booktitle = {Universals of {{Human Language}}},
  publisher = {{Stanford University Press}},
  author = {Andersen, E.},
  editor = {Greenberg, J. H. and Ferguson, C. and Moravcsik, E. A.},
  year = {1978},
  pages = {pp 335-368}
}

@article{morenoSemanticTypologyCausative2004,
  title = {A {{Semantic Typology}} of {{Causative Accomplishment Movement Verbs}} and {{Their Argument}}- {{Adjuncts}} in {{Role}} and {{Reference Grammar}}},
  volume = {26},
  abstract = {Thispaperaccountsforthesemanticfeatureosf inducedmotionverbs.Followingthe approachof ComponentiaAl nalysisa,nd inscribedwithintheframeworokf Role and ReferencGerammart,heseverbsarearrangedintotwogroupsa,ccordingtoa numberof semantivcariablerselatedtotheirargumensttructuraens dtothetypeosflocativearguments theygovernN. ew logicalstructuretshataccountforthisdistinctioanre proposed.This typologiysinlinewitha functionvaliewoflanguagea,ndithighlightths efactthatmeaning isreflecteodn thegrammaticsatlructuroefclauses.},
  language = {en},
  number = {2},
  journal = {Atlantis},
  author = {Moreno, Ana Ib{\'a}{\~n}ez and Pastor, Ana Ortigosa},
  year = {2004},
  pages = {35-49},
  file = {/Users/miriamamin/Documents/Zotero/storage/NQI995LH/Moreno and Pastor - 2004 - A Semantic Typology of Causative Accomplishment Mo.pdf}
}

@misc{lehrerTheoryVocabularyStructure,
  title = {A Theory of Vocabulary Structure},
  language = {English},
  journal = {z.61.21leh},
  howpublished = {https://benjamins.com/catalog/z.61.21leh},
  author = {Lehrer, Adrienne},
  file = {/Users/miriamamin/Documents/Zotero/storage/NPPZ4GIM/z.61.html}
}

@misc{lehrerTheoryVocabularyStructurea,
  title = {A Theory of Vocabulary Structure},
  language = {English},
  journal = {z.61.21leh},
  howpublished = {https://benjamins.com/catalog/z.61.21leh},
  author = {Lehrer, Adrienne},
  file = {/Users/miriamamin/Documents/Zotero/storage/J2TLAJ9B/z.61.html}
}

@incollection{lehrerTheoryVocabularyStructure1992,
  address = {{Amsterdam}},
  title = {A Theory of Vocabulary Structure: {{Retrospectives}} and Prospectives},
  isbn = {978-90-272-2113-1 978-1-55619-462-7 978-90-272-2114-8 978-1-55619-463-4 978-90-272-7403-8},
  shorttitle = {A Theory of Vocabulary Structure},
  language = {en},
  booktitle = {Thirty {{Years}} of {{Linguistic Evolution}}},
  publisher = {{John Benjamins Publishing Company}},
  doi = {10.1075/z.61.21leh},
  author = {Lehrer, Adrienne},
  editor = {P{\"u}tz, Martin},
  year = {1992},
  pages = {243}
}

@book{parsonsEventsSemanticsEnglish1990,
  title = {Events in the {{Semantics}} of {{English}}: {{A Study}} in {{Subatomic Semantics}}},
  isbn = {978-0-212-11072-8},
  shorttitle = {Events in the {{Semantics}} of {{English}}},
  abstract = {This extended investigation of the semantics of event (and state) sentences in their various forms is a major contribution to the semantics of natural language, simultaneously encompassing important issues in linguistics, philosophy, and logic. It develops the view that the logical forms of simple English sentences typically contain quantification over events or states and shows how this view can account for a wide variety of semantic phenomena.  Focusing on the structure of meaning in English sentences at a "subatomic" level\textemdash{}that is, a level below the one most theories accept as basic or "atomic"\textemdash{}Parsons asserts that the semantics of simple English sentences require logical forms somewhat more complex than is normally assumed in natural language semantics. His articulation of underlying event theory explains a wide variety of apparently diverse semantic characteristics of natural language, and his development of the theory shows the importance of seeing the distinction between events and states.  Parsons demonstrates that verbs, also, indicate kinds of actions rather than specific, individual actions. Verb phrases, too, he argues, depend on modifiers to make their function and meaning in a sentence specific. An appendix gives many of the details needed to formalize the theory discussed in the body of the text and provides a series of templates that permit the generation of atomic formulas of English.},
  language = {English},
  publisher = {{The MIT Press}},
  author = {Parsons, Terence},
  month = jan,
  year = {1990}
}

@incollection{hammarstromStandardLebaneseArabic2017,
  address = {{Jena, Germany}},
  title = {Standard {{Lebanese Arabic}}},
  booktitle = {Glottolog 3.0},
  publisher = {{Max Planck Institute for the Science of Human History.}},
  author = {Hammarstr{\"o}m, Harald and Forkel, Robert and Haspelmath, Martin},
  year = {2017}
}

@incollection{hammarstromModernHebrew2017,
  address = {{Jena, Germany}},
  title = {Modern {{Hebrew}}},
  booktitle = {Glottolog 3.0},
  publisher = {{Max Planck Institute for the Science of Human History.}},
  author = {Hammarstr{\"o}m, Harald and Forkel, Robert and Haspelmath, Martin},
  year = {2017}
}

@incollection{hammarstromUrdu2017,
  address = {{Jena, Germany}},
  title = {Urdu},
  booktitle = {Glottolog 3.0},
  publisher = {{Max Planck Institute for the Science of Human History.}},
  author = {Hammarstr{\"o}m, Harald and Forkel, Robert and Haspelmath, Martin},
  year = {2017}
}

@phdthesis{aminComputationalHumorAutomatic2019,
  type = {Bachelor {{Thesis}}},
  title = {Computational Humor - {{Automatic}} Generation of Jokes},
  school = {Leipzig University},
  author = {Amin, Miriam},
  year = {2019}
}

@inproceedings{oliveiraHumorDetectionYelp2015,
  title = {Humor {{Detection}} in {{Yelp}} Reviews},
  abstract = {We utilize the state-of-the-art in deep learning to show that we can learn by example what constitutes humor in the context of a Yelp review. To the best of the authors knowledge, no systematic study of deep learning for humor exists \textendash{} thus, we construct a scaffolded study. First, we use ``shallow'' methods such as Random Forests and Linear Discriminants built on top of bag-of-words and word vector features. Then, we build deep feedforward networks on top of these features \textendash{} in some sense, measuring how much of an effect basic feedforward nets help. Then, we use recurrent neural networks and convolutional neural networks to more accurately model the sequential nature of a review.},
  author = {de Oliveira, Luke and Rodrigo, Alfredo L{\'a}inez},
  year = {2015},
  keywords = {Artificial neural network,Bag-of-words model,Convolutional neural network,Deep learning,Feed forward (control),Feedforward neural network,Neural Network Simulation,Random forest,Recurrent neural network,Review [Publication Type],Word embedding},
  file = {/Users/miriamamin/Documents/Zotero/storage/8P5BKY6N/Oliveira_Rodrigo_2015_Humor Detection in Yelp reviews.pdf}
}

@misc{maheshwariReportTextClassification2018,
  title = {Report on {{Text Classification}} Using {{CNN}}, {{RNN}} \& {{HAN}}},
  abstract = {Experimenting with various neural networks architectures.},
  language = {en},
  journal = {Medium},
  howpublished = {https://medium.com/jatana/report-on-text-classification-using-cnn-rnn-han-f0e887214d5f},
  author = {Maheshwari, Akshat},
  month = jul,
  year = {2018},
  file = {/Users/miriamamin/Documents/Zotero/storage/2A34DT26/report-on-text-classification-using-cnn-rnn-han-f0e887214d5f.html}
}

@misc{StoriesAmericanMovies,
  title = {Stories of {{American}} Movies | {{Kaggle}}},
  howpublished = {https://www.kaggle.com/revanth9/wikipediaplotdata},
  file = {/Users/miriamamin/Documents/Zotero/storage/SBZJ39IL/wikipediaplotdata.html}
}


